{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/raw/submission_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pk</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_info</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>influencer_feedback</th>\n",
       "      <th>decision</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>Label</td>\n",
       "      <td>Bonjour, \\nle track surf sur les codes \"austra...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>Radio</td>\n",
       "      <td>Bonjour, merci pour votre envoi. Le morceau n'...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Le morceau est à lui tout seul une succession ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>Channel</td>\n",
       "      <td>Très bonne pop aux airs de Tame Impala et Pond...</td>\n",
       "      <td>['share it on social media', 'add it to a play...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>Media</td>\n",
       "      <td>La production est assurément excellente, mais ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    pk  track_id track_info  band_id  influencer_id influencer_kind  \\\n",
       "0  7312  7312       324   test tim      303            102           Label   \n",
       "1  7313  7313       324   test tim      303            103           Radio   \n",
       "2  7314  7314       324   test tim      303            104      Journalist   \n",
       "3  7315  7315       324   test tim      303            105         Channel   \n",
       "4  7316  7316       324   test tim      303            106           Media   \n",
       "\n",
       "                                 influencer_feedback  \\\n",
       "0  Bonjour, \\nle track surf sur les codes \"austra...   \n",
       "1  Bonjour, merci pour votre envoi. Le morceau n'...   \n",
       "2  Le morceau est à lui tout seul une succession ...   \n",
       "3  Très bonne pop aux airs de Tame Impala et Pond...   \n",
       "4  La production est assurément excellente, mais ...   \n",
       "\n",
       "                                            decision  score  \n",
       "0                     ['give feedback on your tune']    0.0  \n",
       "1                     ['give feedback on your tune']    0.0  \n",
       "2                     ['give feedback on your tune']    0.0  \n",
       "3  ['share it on social media', 'add it to a play...    1.0  \n",
       "4                     ['give feedback on your tune']    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub.drop(columns=['score', 'influencer_feedback', 'decision'])\n",
    "y = sub.score\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_train_mean = 0.0\n",
    "std_test_mean = 0.0\n",
    "naive_score = 0.0\n",
    "random_score =  0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    std_train_mean += np.std(y_train)\n",
    "    std_test_mean += np.std(y_test)\n",
    "    naive_score += np.sqrt(mean_squared_error([y_train.mean()] * len(y_test), y_test))\n",
    "    random_score += np.sqrt(mean_squared_error(np.random.uniform(0, 1, size=len(y_test)), y_test))\n",
    "\n",
    "std_train_mean /= N_FOLDS\n",
    "std_test_mean /= N_FOLDS\n",
    "naive_score /= N_FOLDS\n",
    "random_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39570093979500703\n",
      "0.39570093963773195\n",
      "0.3957009399899617\n",
      "0.5501003287687661\n"
     ]
    }
   ],
   "source": [
    "print(std_train_mean)\n",
    "print(std_test_mean)\n",
    "print(naive_score)\n",
    "print(random_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = pd.read_csv('./data/raw/band_content.csv')\n",
    "content = pd.read_csv('./data/raw/influencer_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pk</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_info</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>influencer_feedback</th>\n",
       "      <th>decision</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>Label</td>\n",
       "      <td>Bonjour, \\nle track surf sur les codes \"austra...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>Radio</td>\n",
       "      <td>Bonjour, merci pour votre envoi. Le morceau n'...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Le morceau est à lui tout seul une succession ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>Channel</td>\n",
       "      <td>Très bonne pop aux airs de Tame Impala et Pond...</td>\n",
       "      <td>['share it on social media', 'add it to a play...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>Media</td>\n",
       "      <td>La production est assurément excellente, mais ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    pk  track_id track_info  band_id  influencer_id influencer_kind  \\\n",
       "0  7312  7312       324   test tim      303            102           Label   \n",
       "1  7313  7313       324   test tim      303            103           Radio   \n",
       "2  7314  7314       324   test tim      303            104      Journalist   \n",
       "3  7315  7315       324   test tim      303            105         Channel   \n",
       "4  7316  7316       324   test tim      303            106           Media   \n",
       "\n",
       "                                 influencer_feedback  \\\n",
       "0  Bonjour, \\nle track surf sur les codes \"austra...   \n",
       "1  Bonjour, merci pour votre envoi. Le morceau n'...   \n",
       "2  Le morceau est à lui tout seul une succession ...   \n",
       "3  Très bonne pop aux airs de Tame Impala et Pond...   \n",
       "4  La production est assurément excellente, mais ...   \n",
       "\n",
       "                                            decision  score  \n",
       "0                     ['give feedback on your tune']    0.0  \n",
       "1                     ['give feedback on your tune']    0.0  \n",
       "2                     ['give feedback on your tune']    0.0  \n",
       "3  ['share it on social media', 'add it to a play...    1.0  \n",
       "4                     ['give feedback on your tune']    0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>description_fr</th>\n",
       "      <th>description_en</th>\n",
       "      <th>preferences_fr</th>\n",
       "      <th>preferences_en</th>\n",
       "      <th>Acid house</th>\n",
       "      <th>African music</th>\n",
       "      <th>Alternative rock</th>\n",
       "      <th>Ambient</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter</th>\n",
       "      <th>Soul</th>\n",
       "      <th>Surf rock</th>\n",
       "      <th>Synthpop</th>\n",
       "      <th>Synthwave</th>\n",
       "      <th>Techno</th>\n",
       "      <th>Traditional Music</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Trip hop</th>\n",
       "      <th>Variété Française</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Musique Comtemporaine et Jazz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>HIGHLIFE is a music publishing company + Indep...</td>\n",
       "      <td>HIGHLIFE Recordings has a wide open philosophy...</td>\n",
       "      <td>Déjà de la maturité</td>\n",
       "      <td>Already mature and original</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>Nectar est une émission radio musicale et hebd...</td>\n",
       "      <td>Nectar is a weekly music radio program about f...</td>\n",
       "      <td>Folk</td>\n",
       "      <td>Folk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>Ecrit pour Konbini et Noisey (Vice). Défricheu...</td>\n",
       "      <td>Writes for Konbini and Noisey (Vice). Rap, Hip...</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  influencer_id                                     description_fr  \\\n",
       "0   96             96  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1   97             97  Underdog Records is a french alternative label...   \n",
       "2  102            102  HIGHLIFE is a music publishing company + Indep...   \n",
       "3  103            103  Nectar est une émission radio musicale et hebd...   \n",
       "4  104            104  Ecrit pour Konbini et Noisey (Vice). Défricheu...   \n",
       "\n",
       "                                      description_en  \\\n",
       "0  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1  Underdog Records is a french alternative label...   \n",
       "2  HIGHLIFE Recordings has a wide open philosophy...   \n",
       "3  Nectar is a weekly music radio program about f...   \n",
       "4  Writes for Konbini and Noisey (Vice). Rap, Hip...   \n",
       "\n",
       "                            preferences_fr  \\\n",
       "0            Musique Comtemporaine et Jazz   \n",
       "1  Folk, soul, blues, rock&roll, indie pop   \n",
       "2                      Déjà de la maturité   \n",
       "3                                     Folk   \n",
       "4                                      Rap   \n",
       "\n",
       "                            preferences_en  Acid house  African music  \\\n",
       "0                                      NaN           0              0   \n",
       "1  Folk, soul, blues, rock&roll, indie pop           0              0   \n",
       "2              Already mature and original           0              0   \n",
       "3                                     Folk           0              0   \n",
       "4                                      Rap           0              0   \n",
       "\n",
       "   Alternative rock  Ambient  ...  Singer-songwriter  Soul  Surf rock  \\\n",
       "0                 0        0  ...                  0     0          0   \n",
       "1                 0        0  ...                  1     1          0   \n",
       "2                 0        1  ...                  0     0          0   \n",
       "3                 0        0  ...                  0     0          0   \n",
       "4                 0        0  ...                  0     1          0   \n",
       "\n",
       "   Synthpop  Synthwave  Techno  Traditional Music  Trap  Trip hop  \\\n",
       "0         1          0       1                  0     0         0   \n",
       "1         0          0       0                  0     0         0   \n",
       "2         0          0       1                  0     0         1   \n",
       "3         0          0       0                  0     0         0   \n",
       "4         0          0       0                  0     1         0   \n",
       "\n",
       "   Variété Française  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sub[['id', 'track_id', 'band_id', 'influencer_id', 'influencer_kind', 'score']].merge(\n",
    "    band.drop(columns=['id', 'biography_fr', 'biography_en']),\n",
    "    how='left',\n",
    "    on='band_id'\n",
    ").merge(\n",
    "    content.drop(columns=['id', 'description_fr', 'description_en', 'preferences_fr', 'preferences_en']),\n",
    "    how='left',\n",
    "    on='influencer_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'track_id',\n",
       " 'band_id',\n",
       " 'influencer_id',\n",
       " 'influencer_kind',\n",
       " 'score',\n",
       " 'Acid house_x',\n",
       " 'African music_x',\n",
       " 'Alternative rock_x',\n",
       " 'Ambient_x',\n",
       " 'Blues_x',\n",
       " 'Bossa Nova_x',\n",
       " 'Chill-out_x',\n",
       " 'Classical Music_x',\n",
       " 'Coldwave_x',\n",
       " 'Country_x',\n",
       " 'Dance music_x',\n",
       " 'Dance-pop_x',\n",
       " 'Deep house_x',\n",
       " 'Disco_x',\n",
       " 'Dream Pop_x',\n",
       " 'Dub_x',\n",
       " 'Electro swing_x',\n",
       " 'Electronic rock_x',\n",
       " 'Electronica_x',\n",
       " 'Electropop_x',\n",
       " 'Experimental_x',\n",
       " 'Experimental Jazz_x',\n",
       " 'Experimental rock_x',\n",
       " 'Film Music_x',\n",
       " 'French house_x',\n",
       " 'Funk_x',\n",
       " 'Future house_x',\n",
       " 'Garage rock_x',\n",
       " 'Grime_x',\n",
       " 'Hard rock_x',\n",
       " 'Hip hop_x',\n",
       " 'House music_x',\n",
       " 'Indie folk_x',\n",
       " 'Indie pop_x',\n",
       " 'Indie rock_x',\n",
       " 'Instrumental_x',\n",
       " 'International Pop_x',\n",
       " 'Latin music_x',\n",
       " 'Lo-Fi_x',\n",
       " 'Metal_x',\n",
       " 'Minimal_x',\n",
       " 'Modern Jazz_x',\n",
       " 'New wave_x',\n",
       " 'Noise rock_x',\n",
       " 'Nouvelle Scène_x',\n",
       " 'Nu-disco_x',\n",
       " 'Pop rock_x',\n",
       " 'Pop soul_x',\n",
       " 'Post-punk_x',\n",
       " 'Post-rock_x',\n",
       " 'Progressive pop_x',\n",
       " 'Progressive rock_x',\n",
       " 'Psychedelic pop_x',\n",
       " 'Psychedelic rock_x',\n",
       " 'Punk_x',\n",
       " 'R&B_x',\n",
       " 'Rap_x',\n",
       " 'Rap français_x',\n",
       " 'Reggae_x',\n",
       " 'Rock and roll_x',\n",
       " 'Samba_x',\n",
       " 'Singer-songwriter_x',\n",
       " 'Soul_x',\n",
       " 'Surf rock_x',\n",
       " 'Synthpop_x',\n",
       " 'Synthwave_x',\n",
       " 'Techno_x',\n",
       " 'Traditional Music_x',\n",
       " 'Trap_x',\n",
       " 'Trip hop_x',\n",
       " 'Variété Française_x',\n",
       " 'Acid house_y',\n",
       " 'African music_y',\n",
       " 'Alternative rock_y',\n",
       " 'Ambient_y',\n",
       " 'Blues_y',\n",
       " 'Bossa Nova_y',\n",
       " 'Chill-out_y',\n",
       " 'Classical Music_y',\n",
       " 'Coldwave_y',\n",
       " 'Country_y',\n",
       " 'Dance music_y',\n",
       " 'Dance-pop_y',\n",
       " 'Deep house_y',\n",
       " 'Disco_y',\n",
       " 'Dream Pop_y',\n",
       " 'Dub_y',\n",
       " 'Electro swing_y',\n",
       " 'Electronic rock_y',\n",
       " 'Electronica_y',\n",
       " 'Electropop_y',\n",
       " 'Experimental_y',\n",
       " 'Experimental Jazz_y',\n",
       " 'Experimental rock_y',\n",
       " 'Film Music_y',\n",
       " 'French house_y',\n",
       " 'Funk_y',\n",
       " 'Future house_y',\n",
       " 'Garage rock_y',\n",
       " 'Grime_y',\n",
       " 'Hard rock_y',\n",
       " 'Hip hop_y',\n",
       " 'House music_y',\n",
       " 'Indie folk_y',\n",
       " 'Indie pop_y',\n",
       " 'Indie rock_y',\n",
       " 'Instrumental_y',\n",
       " 'International Pop_y',\n",
       " 'Latin music_y',\n",
       " 'Lo-Fi_y',\n",
       " 'Metal_y',\n",
       " 'Minimal_y',\n",
       " 'Modern Jazz_y',\n",
       " 'New wave_y',\n",
       " 'Noise rock_y',\n",
       " 'Nouvelle Scène_y',\n",
       " 'Nu-disco_y',\n",
       " 'Pop rock_y',\n",
       " 'Pop soul_y',\n",
       " 'Post-punk_y',\n",
       " 'Post-rock_y',\n",
       " 'Progressive pop_y',\n",
       " 'Progressive rock_y',\n",
       " 'Psychedelic pop_y',\n",
       " 'Psychedelic rock_y',\n",
       " 'Punk_y',\n",
       " 'R&B_y',\n",
       " 'Rap_y',\n",
       " 'Rap français_y',\n",
       " 'Reggae_y',\n",
       " 'Rock and roll_y',\n",
       " 'Samba_y',\n",
       " 'Singer-songwriter_y',\n",
       " 'Soul_y',\n",
       " 'Surf rock_y',\n",
       " 'Synthpop_y',\n",
       " 'Synthwave_y',\n",
       " 'Techno_y',\n",
       " 'Traditional Music_y',\n",
       " 'Trap_y',\n",
       " 'Trip hop_y',\n",
       " 'Variété Française_y']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media          35288\n",
       "Radio           9872\n",
       "Label           9155\n",
       "Playlist        8501\n",
       "Journalist      4268\n",
       "Channel         4150\n",
       "Booker          3405\n",
       "Mentor          2288\n",
       "Manager         2094\n",
       "Springboard     2087\n",
       "Publisher       1698\n",
       "Supervisor       572\n",
       "Event            328\n",
       "Name: influencer_kind, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.influencer_kind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['influencer_kind'] = le.fit_transform(dataset['influencer_kind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_x</th>\n",
       "      <th>African music_x</th>\n",
       "      <th>Alternative rock_x</th>\n",
       "      <th>Ambient_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_y</th>\n",
       "      <th>Soul_y</th>\n",
       "      <th>Surf rock_y</th>\n",
       "      <th>Synthpop_y</th>\n",
       "      <th>Synthwave_y</th>\n",
       "      <th>Techno_y</th>\n",
       "      <th>Traditional Music_y</th>\n",
       "      <th>Trap_y</th>\n",
       "      <th>Trip hop_y</th>\n",
       "      <th>Variété Française_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_x  African music_x  Alternative rock_x  Ambient_x  ...  \\\n",
       "0             0                0                   0          0  ...   \n",
       "1             0                0                   0          0  ...   \n",
       "2             0                0                   0          0  ...   \n",
       "3             0                0                   0          0  ...   \n",
       "4             0                0                   0          0  ...   \n",
       "\n",
       "   Singer-songwriter_y  Soul_y  Surf rock_y  Synthpop_y  Synthwave_y  \\\n",
       "0                    0       0            0           0            0   \n",
       "1                    0       0            0           0            0   \n",
       "2                    0       1            0           0            0   \n",
       "3                    0       0            1           0            0   \n",
       "4                    0       0            1           0            0   \n",
       "\n",
       "   Techno_y  Traditional Music_y  Trap_y  Trip hop_y  Variété Française_y  \n",
       "0         1                    0       0           1                    0  \n",
       "1         0                    0       0           0                    0  \n",
       "2         0                    0       1           0                    1  \n",
       "3         0                    0       0           0                    0  \n",
       "4         0                    0       0           0                    0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_x': 'Variete Francaise_x', 'Variété Française_y': 'Variete Francaise_y'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.102588\n",
      "[200]\tvalid_0's l2: 0.0920579\n",
      "[300]\tvalid_0's l2: 0.0889158\n",
      "[400]\tvalid_0's l2: 0.0874495\n",
      "[500]\tvalid_0's l2: 0.086519\n",
      "[600]\tvalid_0's l2: 0.0858807\n",
      "[700]\tvalid_0's l2: 0.0854668\n",
      "[800]\tvalid_0's l2: 0.0851732\n",
      "[900]\tvalid_0's l2: 0.0849352\n",
      "[1000]\tvalid_0's l2: 0.0847728\n",
      "[1100]\tvalid_0's l2: 0.0846168\n",
      "[1200]\tvalid_0's l2: 0.0845244\n",
      "[1300]\tvalid_0's l2: 0.0844236\n",
      "[1400]\tvalid_0's l2: 0.0843611\n",
      "[1500]\tvalid_0's l2: 0.0843134\n",
      "[1600]\tvalid_0's l2: 0.0842582\n",
      "[1700]\tvalid_0's l2: 0.0842047\n",
      "[1800]\tvalid_0's l2: 0.0841595\n",
      "[1900]\tvalid_0's l2: 0.0841402\n",
      "Early stopping, best iteration is:\n",
      "[1860]\tvalid_0's l2: 0.0841402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.10309\n",
      "[200]\tvalid_0's l2: 0.0930311\n",
      "[300]\tvalid_0's l2: 0.0901051\n",
      "[400]\tvalid_0's l2: 0.0888514\n",
      "[500]\tvalid_0's l2: 0.0880205\n",
      "[600]\tvalid_0's l2: 0.0874837\n",
      "[700]\tvalid_0's l2: 0.0870172\n",
      "[800]\tvalid_0's l2: 0.0866848\n",
      "[900]\tvalid_0's l2: 0.0864419\n",
      "[1000]\tvalid_0's l2: 0.0862694\n",
      "[1100]\tvalid_0's l2: 0.0861148\n",
      "[1200]\tvalid_0's l2: 0.0860122\n",
      "[1300]\tvalid_0's l2: 0.0859248\n",
      "[1400]\tvalid_0's l2: 0.0858729\n",
      "[1500]\tvalid_0's l2: 0.085835\n",
      "[1600]\tvalid_0's l2: 0.0857861\n",
      "[1700]\tvalid_0's l2: 0.0857544\n",
      "[1800]\tvalid_0's l2: 0.0857485\n",
      "Early stopping, best iteration is:\n",
      "[1748]\tvalid_0's l2: 0.0857409\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.103579\n",
      "[200]\tvalid_0's l2: 0.0929935\n",
      "[300]\tvalid_0's l2: 0.0900592\n",
      "[400]\tvalid_0's l2: 0.08864\n",
      "[500]\tvalid_0's l2: 0.0877949\n",
      "[600]\tvalid_0's l2: 0.0871404\n",
      "[700]\tvalid_0's l2: 0.0867148\n",
      "[800]\tvalid_0's l2: 0.0863706\n",
      "[900]\tvalid_0's l2: 0.0861172\n",
      "[1000]\tvalid_0's l2: 0.085941\n",
      "[1100]\tvalid_0's l2: 0.0858142\n",
      "[1200]\tvalid_0's l2: 0.0856762\n",
      "[1300]\tvalid_0's l2: 0.0855819\n",
      "[1400]\tvalid_0's l2: 0.0854917\n",
      "[1500]\tvalid_0's l2: 0.0854243\n",
      "[1600]\tvalid_0's l2: 0.0853756\n",
      "[1700]\tvalid_0's l2: 0.085357\n",
      "[1800]\tvalid_0's l2: 0.0853382\n",
      "[1900]\tvalid_0's l2: 0.0853165\n",
      "[2000]\tvalid_0's l2: 0.0852871\n",
      "[2100]\tvalid_0's l2: 0.0852584\n",
      "[2200]\tvalid_0's l2: 0.0852405\n",
      "[2300]\tvalid_0's l2: 0.0852309\n",
      "[2400]\tvalid_0's l2: 0.0852284\n",
      "Early stopping, best iteration is:\n",
      "[2335]\tvalid_0's l2: 0.0852284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.102421\n",
      "[200]\tvalid_0's l2: 0.0918502\n",
      "[300]\tvalid_0's l2: 0.0890096\n",
      "[400]\tvalid_0's l2: 0.0877235\n",
      "[500]\tvalid_0's l2: 0.0868933\n",
      "[600]\tvalid_0's l2: 0.0862917\n",
      "[700]\tvalid_0's l2: 0.0858812\n",
      "[800]\tvalid_0's l2: 0.0855786\n",
      "[900]\tvalid_0's l2: 0.0853692\n",
      "[1000]\tvalid_0's l2: 0.0851912\n",
      "[1100]\tvalid_0's l2: 0.0850686\n",
      "[1200]\tvalid_0's l2: 0.0849618\n",
      "[1300]\tvalid_0's l2: 0.0848532\n",
      "[1400]\tvalid_0's l2: 0.0847645\n",
      "[1500]\tvalid_0's l2: 0.0847192\n",
      "[1600]\tvalid_0's l2: 0.0846636\n",
      "[1700]\tvalid_0's l2: 0.084621\n",
      "[1800]\tvalid_0's l2: 0.0845859\n",
      "[1900]\tvalid_0's l2: 0.0845319\n",
      "[2000]\tvalid_0's l2: 0.0845132\n",
      "[2100]\tvalid_0's l2: 0.0845058\n",
      "[2200]\tvalid_0's l2: 0.0844882\n",
      "[2300]\tvalid_0's l2: 0.0844741\n",
      "[2400]\tvalid_0's l2: 0.0844721\n",
      "Early stopping, best iteration is:\n",
      "[2326]\tvalid_0's l2: 0.0844721\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.102313\n",
      "[200]\tvalid_0's l2: 0.0916311\n",
      "[300]\tvalid_0's l2: 0.0886462\n",
      "[400]\tvalid_0's l2: 0.0873495\n",
      "[500]\tvalid_0's l2: 0.0865444\n",
      "[600]\tvalid_0's l2: 0.0859709\n",
      "[700]\tvalid_0's l2: 0.0855744\n",
      "[800]\tvalid_0's l2: 0.0852916\n",
      "[900]\tvalid_0's l2: 0.08509\n",
      "[1000]\tvalid_0's l2: 0.0849854\n",
      "[1100]\tvalid_0's l2: 0.0848855\n",
      "[1200]\tvalid_0's l2: 0.0848142\n",
      "[1300]\tvalid_0's l2: 0.0847278\n",
      "[1400]\tvalid_0's l2: 0.0846622\n",
      "[1500]\tvalid_0's l2: 0.084622\n",
      "[1600]\tvalid_0's l2: 0.0845911\n",
      "[1700]\tvalid_0's l2: 0.0845817\n",
      "[1800]\tvalid_0's l2: 0.0845561\n",
      "[1900]\tvalid_0's l2: 0.0845293\n",
      "[2000]\tvalid_0's l2: 0.0844875\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's l2: 0.0844875\n",
      "0.2932822893503929\n"
     ]
    }
   ],
   "source": [
    "lgbm_score =  0.0\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(\n",
    "        num_leaves=2**10,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.5,\n",
    "        reg_alpha=10.0,\n",
    "        reg_lambda=10.0,\n",
    "        n_estimators=10000,\n",
    "        silent=False\n",
    "    )\n",
    "    lgbm.fit(X_train, y_train, eval_set=(X_valid, y_valid), \n",
    "             eval_metric='mse', early_stopping_rounds=100,\n",
    "             verbose=100)\n",
    "    lgbm_score += np.sqrt(mean_squared_error(lgbm.predict(X_test), y_test))\n",
    "\n",
    "lgbm_score /= N_FOLDS\n",
    "\n",
    "print(lgbm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)prod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\n",
    "model = Model([user_input, book_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_x</th>\n",
       "      <th>African music_x</th>\n",
       "      <th>Alternative rock_x</th>\n",
       "      <th>Ambient_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_y</th>\n",
       "      <th>Soul_y</th>\n",
       "      <th>Surf rock_y</th>\n",
       "      <th>Synthpop_y</th>\n",
       "      <th>Synthwave_y</th>\n",
       "      <th>Techno_y</th>\n",
       "      <th>Traditional Music_y</th>\n",
       "      <th>Trap_y</th>\n",
       "      <th>Trip hop_y</th>\n",
       "      <th>Variété Française_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_x  African music_x  Alternative rock_x  Ambient_x  ...  \\\n",
       "0             0                0                   0          0  ...   \n",
       "1             0                0                   0          0  ...   \n",
       "2             0                0                   0          0  ...   \n",
       "3             0                0                   0          0  ...   \n",
       "4             0                0                   0          0  ...   \n",
       "\n",
       "   Singer-songwriter_y  Soul_y  Surf rock_y  Synthpop_y  Synthwave_y  \\\n",
       "0                    0       0            0           0            0   \n",
       "1                    0       0            0           0            0   \n",
       "2                    0       1            0           0            0   \n",
       "3                    0       0            1           0            0   \n",
       "4                    0       0            1           0            0   \n",
       "\n",
       "   Techno_y  Traditional Music_y  Trap_y  Trip hop_y  Variété Française_y  \n",
       "0         1                    0       0           1                    0  \n",
       "1         0                    0       0           0                    0  \n",
       "2         0                    0       1           0                    1  \n",
       "3         0                    0       0           0                    0  \n",
       "4         0                    0       0           0                    0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data = dataset.filter(regex='_y')\n",
    "b_data = dataset.filter(regex='_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(i_emb_dim=50, b_emb_dim=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    prod = Dot(name=\"Dot-Product\", axes=1)([influencer_embedding, band_embedding])\n",
    "    model = Model([influencer_input, band_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pa/.virtualenvs/groover/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pa/.virtualenvs/groover/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "83706/83706 [==============================] - 6s 73us/step - loss: 0.1854\n",
      "Epoch 2/10\n",
      "83706/83706 [==============================] - 4s 51us/step - loss: 0.1366\n",
      "Epoch 3/10\n",
      "83706/83706 [==============================] - 4s 52us/step - loss: 0.1264\n",
      "Epoch 4/10\n",
      "83706/83706 [==============================] - 4s 51us/step - loss: 0.1195\n",
      "Epoch 5/10\n",
      "83706/83706 [==============================] - 4s 52us/step - loss: 0.1158\n",
      "Epoch 6/10\n",
      "83706/83706 [==============================] - 4s 52us/step - loss: 0.1131\n",
      "Epoch 7/10\n",
      "83706/83706 [==============================] - 4s 52us/step - loss: 0.1099\n",
      "Epoch 8/10\n",
      "83706/83706 [==============================] - 4s 52us/step - loss: 0.1086\n",
      "Epoch 9/10\n",
      "83706/83706 [==============================] - 4s 53us/step - loss: 0.1067\n",
      "Epoch 10/10\n",
      "83706/83706 [==============================] - 5s 54us/step - loss: 0.1059\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([i_data, b_data], dataset.score, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_x': 'Variete Francaise_x', 'Variété Française_y': 'Variete Francaise_y'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data = dataset.filter(regex='_y')\n",
    "b_data = dataset.filter(regex='_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_y')]\n",
    "b_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.get_loc('Variété Française_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83706, 148)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46874/46874 [==============================] - 7s 150us/step - loss: 0.2231 - val_loss: 0.1751\n",
      "Epoch 2/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1512 - val_loss: 0.1471\n",
      "Epoch 3/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1372 - val_loss: 0.1382\n",
      "Epoch 4/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1299 - val_loss: 0.1347\n",
      "Epoch 5/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1240 - val_loss: 0.1358\n",
      "Epoch 6/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1208 - val_loss: 0.1293\n",
      "Epoch 7/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1175 - val_loss: 0.1253\n",
      "Epoch 8/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1153 - val_loss: 0.1221\n",
      "Epoch 9/10\n",
      "46874/46874 [==============================] - 4s 77us/step - loss: 0.1129 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1114 - val_loss: 0.1170\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 155us/step - loss: 0.2197 - val_loss: 0.1707\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 81us/step - loss: 0.1507 - val_loss: 0.1467\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1357 - val_loss: 0.1389\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1273 - val_loss: 0.1306\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1215 - val_loss: 0.1258\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1191 - val_loss: 0.1290\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1156 - val_loss: 0.1251\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1125 - val_loss: 0.1217\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1117 - val_loss: 0.1174\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1090 - val_loss: 0.1169\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 151us/step - loss: 0.2238 - val_loss: 0.1654\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1503 - val_loss: 0.1461\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1353 - val_loss: 0.1382\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1277 - val_loss: 0.1287\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1228 - val_loss: 0.1274\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 83us/step - loss: 0.1188 - val_loss: 0.1263\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1157 - val_loss: 0.1222\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1125 - val_loss: 0.1204\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1118 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1094 - val_loss: 0.1229\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 154us/step - loss: 0.2227 - val_loss: 0.1672\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1503 - val_loss: 0.1494\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1362 - val_loss: 0.1443\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1282 - val_loss: 0.1336\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1228 - val_loss: 0.1294\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1202 - val_loss: 0.1271\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 81us/step - loss: 0.1164 - val_loss: 0.1281\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1147 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1126 - val_loss: 0.1249\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1104 - val_loss: 0.1201\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 154us/step - loss: 0.2174 - val_loss: 0.1623\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 88us/step - loss: 0.1484 - val_loss: 0.1417\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1343 - val_loss: 0.1330\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1273 - val_loss: 0.1303\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1221 - val_loss: 0.1257\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 87us/step - loss: 0.1181 - val_loss: 0.1246\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 88us/step - loss: 0.1153 - val_loss: 0.1233\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1123 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1110 - val_loss: 0.1267\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1091 - val_loss: 0.1194\n",
      "0.3448840988103111\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx]], y_valid), \n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx]]), y_test))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.influencer_kind.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=5, last_dense=20, dropout=0.2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense1\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense2\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=10, last_dense=40, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='relu', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='relu', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='relu', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='relu', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='relu', name=\"Dense3\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_x</th>\n",
       "      <th>African music_x</th>\n",
       "      <th>Alternative rock_x</th>\n",
       "      <th>Ambient_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_y</th>\n",
       "      <th>Soul_y</th>\n",
       "      <th>Surf rock_y</th>\n",
       "      <th>Synthpop_y</th>\n",
       "      <th>Synthwave_y</th>\n",
       "      <th>Techno_y</th>\n",
       "      <th>Traditional Music_y</th>\n",
       "      <th>Trap_y</th>\n",
       "      <th>Trip hop_y</th>\n",
       "      <th>Variété Française_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_x  African music_x  Alternative rock_x  Ambient_x  ...  \\\n",
       "0             0                0                   0          0  ...   \n",
       "1             0                0                   0          0  ...   \n",
       "2             0                0                   0          0  ...   \n",
       "3             0                0                   0          0  ...   \n",
       "4             0                0                   0          0  ...   \n",
       "\n",
       "   Singer-songwriter_y  Soul_y  Surf rock_y  Synthpop_y  Synthwave_y  \\\n",
       "0                    0       0            0           0            0   \n",
       "1                    0       0            0           0            0   \n",
       "2                    0       1            0           0            0   \n",
       "3                    0       0            1           0            0   \n",
       "4                    0       0            1           0            0   \n",
       "\n",
       "   Techno_y  Traditional Music_y  Trap_y  Trip hop_y  Variété Française_y  \n",
       "0         1                    0       0           1                    0  \n",
       "1         0                    0       0           0                    0  \n",
       "2         0                    0       1           0                    1  \n",
       "3         0                    0       0           0                    0  \n",
       "4         0                    0       0           0                    0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "PATIENCE = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 16s 334us/step - loss: 0.1167 - val_loss: 0.1042\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.1032 - val_loss: 0.0989\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.1003 - val_loss: 0.0977\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 11s 238us/step - loss: 0.0993 - val_loss: 0.0954\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 11s 237us/step - loss: 0.0974 - val_loss: 0.0975\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 11s 231us/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0959 - val_loss: 0.0949\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0951 - val_loss: 0.0945\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0949 - val_loss: 0.0954\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0937 - val_loss: 0.0954\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 10s 218us/step - loss: 0.0932 - val_loss: 0.0953\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0931 - val_loss: 0.0943\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0924 - val_loss: 0.0959\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 10s 220us/step - loss: 0.0919 - val_loss: 0.0957\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 10s 221us/step - loss: 0.0917 - val_loss: 0.0952\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0915 - val_loss: 0.0948\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0911 - val_loss: 0.0953\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0910 - val_loss: 0.0956\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0906 - val_loss: 0.0949\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0901 - val_loss: 0.0971\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0902 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 11s 233us/step - loss: 0.0898 - val_loss: 0.0955\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 11s 224us/step - loss: 0.0898 - val_loss: 0.0968\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0891 - val_loss: 0.0960\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0894 - val_loss: 0.0975\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0892 - val_loss: 0.0963\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0885 - val_loss: 0.0959\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0886 - val_loss: 0.0959\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0882 - val_loss: 0.0961\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0884 - val_loss: 0.0963\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0879 - val_loss: 0.0964\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0875 - val_loss: 0.0961\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0875 - val_loss: 0.0958\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0874 - val_loss: 0.0969\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 10s 219us/step - loss: 0.0872 - val_loss: 0.0965\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0873 - val_loss: 0.0957\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0866 - val_loss: 0.0969\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0867 - val_loss: 0.0965\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0867 - val_loss: 0.0968\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 10s 220us/step - loss: 0.0865 - val_loss: 0.0980\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 10s 219us/step - loss: 0.0862 - val_loss: 0.0964\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0861 - val_loss: 0.0980\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0861 - val_loss: 0.0968\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 11s 231us/step - loss: 0.0857 - val_loss: 0.0986\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0859 - val_loss: 0.0998\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0856 - val_loss: 0.0981\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 11s 240us/step - loss: 0.0852 - val_loss: 0.0973\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 11s 235us/step - loss: 0.0852 - val_loss: 0.0972\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0854 - val_loss: 0.0978\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 11s 233us/step - loss: 0.0852 - val_loss: 0.0992\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0848 - val_loss: 0.0992\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0849 - val_loss: 0.0989\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0848 - val_loss: 0.0991\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 11s 235us/step - loss: 0.0844 - val_loss: 0.0991\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 11s 237us/step - loss: 0.0845 - val_loss: 0.0985\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 11s 236us/step - loss: 0.0843 - val_loss: 0.0972\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 11s 238us/step - loss: 0.0841 - val_loss: 0.0985\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 11s 234us/step - loss: 0.0842 - val_loss: 0.0990\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0839 - val_loss: 0.0984\n",
      "Epoch 60/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0834 - val_loss: 0.0993\n",
      "Epoch 61/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0840 - val_loss: 0.0975\n",
      "Epoch 62/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0838 - val_loss: 0.1007\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 339us/step - loss: 0.1164 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.1033 - val_loss: 0.0996\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.1002 - val_loss: 0.0980\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0987 - val_loss: 0.0967\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0977 - val_loss: 0.0968\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0970 - val_loss: 0.0968\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0959 - val_loss: 0.0979\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0953 - val_loss: 0.0972\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0949 - val_loss: 0.0996\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0942 - val_loss: 0.0970\n",
      "Epoch 11/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0934 - val_loss: 0.0967\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0935 - val_loss: 0.0965\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0928 - val_loss: 0.0969\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0923 - val_loss: 0.0957\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 245us/step - loss: 0.0917 - val_loss: 0.0959\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0916 - val_loss: 0.0965\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0913 - val_loss: 0.0968\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 241us/step - loss: 0.0908 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 242us/step - loss: 0.0907 - val_loss: 0.0971\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0903 - val_loss: 0.0969\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0903 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0897 - val_loss: 0.0966\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0895 - val_loss: 0.0972\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0892 - val_loss: 0.0969\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0890 - val_loss: 0.0982\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0887 - val_loss: 0.0969\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0885 - val_loss: 0.0994\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0883 - val_loss: 0.0976\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0880 - val_loss: 0.0989\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0880 - val_loss: 0.0973\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0879 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0880 - val_loss: 0.0985\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0874 - val_loss: 0.0988\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0874 - val_loss: 0.0989\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0869 - val_loss: 0.0981\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0869 - val_loss: 0.0989\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0874 - val_loss: 0.0983\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0864 - val_loss: 0.0989\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0864 - val_loss: 0.0993\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0858 - val_loss: 0.0995\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0859 - val_loss: 0.0988\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0858 - val_loss: 0.0999\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0855 - val_loss: 0.1008\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0856 - val_loss: 0.0990\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0852 - val_loss: 0.0993\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.0997\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0851 - val_loss: 0.1001\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0851 - val_loss: 0.1003\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0848 - val_loss: 0.0998\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0845 - val_loss: 0.0997\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0845 - val_loss: 0.1012\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0844 - val_loss: 0.1008\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0839 - val_loss: 0.1006\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0841 - val_loss: 0.1003\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0837 - val_loss: 0.1010\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0840 - val_loss: 0.1015\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0838 - val_loss: 0.1020\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0836 - val_loss: 0.1005\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0837 - val_loss: 0.1016\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0833 - val_loss: 0.1038\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0833 - val_loss: 0.1017\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0835 - val_loss: 0.1019\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0831 - val_loss: 0.1020\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00064: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 333us/step - loss: 0.1167 - val_loss: 0.1027\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.1039 - val_loss: 0.0996\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.1004 - val_loss: 0.0979\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0990 - val_loss: 0.0962\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0975 - val_loss: 0.0976\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0967 - val_loss: 0.0965\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0963 - val_loss: 0.0960\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0954 - val_loss: 0.0965\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0948 - val_loss: 0.0953\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0942 - val_loss: 0.0965\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0935 - val_loss: 0.0953\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0932 - val_loss: 0.0958\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0926 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0921 - val_loss: 0.0960\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0922 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0917 - val_loss: 0.0967\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0914 - val_loss: 0.0975\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0906 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0906 - val_loss: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0903 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0898 - val_loss: 0.0979\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0898 - val_loss: 0.0968\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0894 - val_loss: 0.0980\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0892 - val_loss: 0.0977\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0888 - val_loss: 0.0970\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0887 - val_loss: 0.0970\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 231us/step - loss: 0.0882 - val_loss: 0.0968\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0884 - val_loss: 0.0969\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0880 - val_loss: 0.0973\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0878 - val_loss: 0.0973\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0879 - val_loss: 0.0976\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0877 - val_loss: 0.0971\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0877 - val_loss: 0.0972\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0873 - val_loss: 0.0978\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0873 - val_loss: 0.0970\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0872 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0872 - val_loss: 0.0978\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0866 - val_loss: 0.0995\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0865 - val_loss: 0.0991\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0866 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0860 - val_loss: 0.0987\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0858 - val_loss: 0.0988\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0861 - val_loss: 0.0984\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0857 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0856 - val_loss: 0.0984\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0854 - val_loss: 0.0989\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.0999\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.1003\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0853 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0849 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0849 - val_loss: 0.0986\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0848 - val_loss: 0.0990\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0842 - val_loss: 0.1000\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0846 - val_loss: 0.0996\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0841 - val_loss: 0.0995\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0839 - val_loss: 0.1000\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0843 - val_loss: 0.0998\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0840 - val_loss: 0.1002\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 336us/step - loss: 0.1145 - val_loss: 0.1046\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.1023 - val_loss: 0.1011\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0993 - val_loss: 0.0988\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0979 - val_loss: 0.0980\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0970 - val_loss: 0.0987\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0958 - val_loss: 0.0990\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0953 - val_loss: 0.0969\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0941 - val_loss: 0.0972\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0937 - val_loss: 0.0981\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0928 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0925 - val_loss: 0.0974\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0919 - val_loss: 0.0978\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0917 - val_loss: 0.0980\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0911 - val_loss: 0.0977\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0909 - val_loss: 0.0972\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0906 - val_loss: 0.0963\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0902 - val_loss: 0.0979\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0899 - val_loss: 0.0973\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0895 - val_loss: 0.0980\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0890 - val_loss: 0.0977\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0892 - val_loss: 0.0968\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0885 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0883 - val_loss: 0.0983\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0880 - val_loss: 0.0982\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0879 - val_loss: 0.0977\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0875 - val_loss: 0.0983\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0875 - val_loss: 0.0978\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0868 - val_loss: 0.0997\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0871 - val_loss: 0.0975\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0866 - val_loss: 0.0983\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0863 - val_loss: 0.0987\n",
      "Epoch 33/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0859 - val_loss: 0.0980\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0857 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0853 - val_loss: 0.1000\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0855 - val_loss: 0.0988\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0851 - val_loss: 0.0988\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0852 - val_loss: 0.0994\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0850 - val_loss: 0.0996\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0849 - val_loss: 0.1000\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0845 - val_loss: 0.1003\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0844 - val_loss: 0.1008\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0846 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0839 - val_loss: 0.1005\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0840 - val_loss: 0.1005\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0838 - val_loss: 0.0996\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0834 - val_loss: 0.0989\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0833 - val_loss: 0.0999\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0831 - val_loss: 0.1000\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0830 - val_loss: 0.1011\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0828 - val_loss: 0.1004\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0826 - val_loss: 0.1011\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0827 - val_loss: 0.1005\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0823 - val_loss: 0.1019\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0825 - val_loss: 0.1011\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0821 - val_loss: 0.1009\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0822 - val_loss: 0.1014\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0820 - val_loss: 0.1005\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0817 - val_loss: 0.1016\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0816 - val_loss: 0.1012\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0817 - val_loss: 0.1019\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0814 - val_loss: 0.1023\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0813 - val_loss: 0.1013\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0814 - val_loss: 0.1022\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0812 - val_loss: 0.1008\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00066: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 339us/step - loss: 0.1162 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.1031 - val_loss: 0.0982\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0997 - val_loss: 0.1018\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0981 - val_loss: 0.0975\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0970 - val_loss: 0.0977\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0964 - val_loss: 0.0977\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0955 - val_loss: 0.0954\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0946 - val_loss: 0.0987\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0936 - val_loss: 0.0961\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0931 - val_loss: 0.0964\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0929 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0925 - val_loss: 0.0956\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0917 - val_loss: 0.0964\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0917 - val_loss: 0.0968\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0910 - val_loss: 0.0952\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0908 - val_loss: 0.0957\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0903 - val_loss: 0.0970\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0898 - val_loss: 0.0981\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0897 - val_loss: 0.0958\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0892 - val_loss: 0.0954\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0890 - val_loss: 0.0962\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0887 - val_loss: 0.0956\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0886 - val_loss: 0.0957\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0879 - val_loss: 0.0968\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0880 - val_loss: 0.0955\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0877 - val_loss: 0.0978\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0871 - val_loss: 0.0966\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0870 - val_loss: 0.0970\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0868 - val_loss: 0.0971\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0864 - val_loss: 0.0977\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0868 - val_loss: 0.0961\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0863 - val_loss: 0.0990\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0857 - val_loss: 0.0981\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0857 - val_loss: 0.0983\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0854 - val_loss: 0.0967\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0854 - val_loss: 0.0965\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0851 - val_loss: 0.0985\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0850 - val_loss: 0.0969\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0845 - val_loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0845 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0845 - val_loss: 0.0982\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0846 - val_loss: 0.0998\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0846 - val_loss: 0.0979\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0837 - val_loss: 0.0980\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0838 - val_loss: 0.1009\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0839 - val_loss: 0.0994\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0831 - val_loss: 0.0996\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0832 - val_loss: 0.0980\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0835 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0832 - val_loss: 0.0993\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0830 - val_loss: 0.0977\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0828 - val_loss: 0.0994\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0827 - val_loss: 0.0986\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0826 - val_loss: 0.0990\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0824 - val_loss: 0.0984\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0822 - val_loss: 0.0989\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0827 - val_loss: 0.0983\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0822 - val_loss: 0.0993\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0823 - val_loss: 0.1012\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0817 - val_loss: 0.0988\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0818 - val_loss: 0.0998\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0814 - val_loss: 0.0991\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0816 - val_loss: 0.0990\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0810 - val_loss: 0.1005\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0817 - val_loss: 0.1001\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00065: early stopping\n",
      "0.3092543342407225\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 16s 346us/step - loss: 0.1133 - val_loss: 0.0995\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.1032 - val_loss: 0.0976\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0996 - val_loss: 0.0965\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0985 - val_loss: 0.0965\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0970 - val_loss: 0.0953\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0962 - val_loss: 0.0978\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0955 - val_loss: 0.0945\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0947 - val_loss: 0.0953\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0940 - val_loss: 0.0942\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0930 - val_loss: 0.0958\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0929 - val_loss: 0.0950\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0920 - val_loss: 0.0946\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0915 - val_loss: 0.0945\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0912 - val_loss: 0.0965\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0906 - val_loss: 0.0954\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0903 - val_loss: 0.0956\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0898 - val_loss: 0.0945\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0896 - val_loss: 0.0946\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0895 - val_loss: 0.0965\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0888 - val_loss: 0.0966\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0883 - val_loss: 0.0958\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0881 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0881 - val_loss: 0.0962\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0876 - val_loss: 0.0960\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0875 - val_loss: 0.0976\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0868 - val_loss: 0.0960\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0866 - val_loss: 0.0962\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0859 - val_loss: 0.0970\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0857 - val_loss: 0.0972\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0855 - val_loss: 0.0972\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.0974\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0850 - val_loss: 0.0969\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.0986\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0847 - val_loss: 0.0980\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0847 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0842 - val_loss: 0.0986\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0837 - val_loss: 0.0975\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0834 - val_loss: 0.0977\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0835 - val_loss: 0.0985\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0833 - val_loss: 0.0988\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0829 - val_loss: 0.0999\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0828 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0828 - val_loss: 0.0991\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0824 - val_loss: 0.0988\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 12s 248us/step - loss: 0.0822 - val_loss: 0.0990\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 12s 245us/step - loss: 0.0822 - val_loss: 0.0998\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0819 - val_loss: 0.0990\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0816 - val_loss: 0.0988\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0813 - val_loss: 0.0983\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0817 - val_loss: 0.0999\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0814 - val_loss: 0.1005\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0812 - val_loss: 0.0992\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0809 - val_loss: 0.0998\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0810 - val_loss: 0.1014\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0802 - val_loss: 0.1008\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0802 - val_loss: 0.1016\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0806 - val_loss: 0.1007\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0800 - val_loss: 0.1014\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 352us/step - loss: 0.1143 - val_loss: 0.1036\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.1027 - val_loss: 0.0987\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0995 - val_loss: 0.0989\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0979 - val_loss: 0.0969\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0968 - val_loss: 0.0972\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0960 - val_loss: 0.0969\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0953 - val_loss: 0.0978\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0944 - val_loss: 0.0961\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0936 - val_loss: 0.0968\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0933 - val_loss: 0.0966\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0928 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0925 - val_loss: 0.0959\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0919 - val_loss: 0.0958\n",
      "Epoch 14/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0914 - val_loss: 0.0970\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0910 - val_loss: 0.0972\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0908 - val_loss: 0.0960\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0903 - val_loss: 0.0956\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0899 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0900 - val_loss: 0.0978\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0896 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0890 - val_loss: 0.0980\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0885 - val_loss: 0.0982\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0882 - val_loss: 0.0974\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0884 - val_loss: 0.0977\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0876 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0876 - val_loss: 0.0978\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0874 - val_loss: 0.0983\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0866 - val_loss: 0.0979\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0865 - val_loss: 0.0983\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0861 - val_loss: 0.0981\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0860 - val_loss: 0.0988\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0861 - val_loss: 0.0988\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0855 - val_loss: 0.1005\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0854 - val_loss: 0.0992\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0851 - val_loss: 0.1005\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.1016\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0846 - val_loss: 0.1002\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0845 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0842 - val_loss: 0.0996\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0839 - val_loss: 0.1006\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0836 - val_loss: 0.1016\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0836 - val_loss: 0.1015\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0835 - val_loss: 0.1014\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0830 - val_loss: 0.1012\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0827 - val_loss: 0.1007\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0823 - val_loss: 0.1006\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0823 - val_loss: 0.1012\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0821 - val_loss: 0.1020\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0818 - val_loss: 0.1009\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0817 - val_loss: 0.1029\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0817 - val_loss: 0.1022\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0816 - val_loss: 0.1017\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0811 - val_loss: 0.1024\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0805 - val_loss: 0.1031\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0808 - val_loss: 0.1027\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0803 - val_loss: 0.1030\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0804 - val_loss: 0.1028\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0803 - val_loss: 0.1039\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0800 - val_loss: 0.1033\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0801 - val_loss: 0.1047\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 13s 284us/step - loss: 0.0795 - val_loss: 0.1035\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 13s 287us/step - loss: 0.0797 - val_loss: 0.1029\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0790 - val_loss: 0.1049\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 14s 307us/step - loss: 0.0793 - val_loss: 0.1045\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 14s 305us/step - loss: 0.0797 - val_loss: 0.1050\n",
      "Epoch 67/10000\n",
      "46875/46875 [==============================] - 14s 306us/step - loss: 0.0793 - val_loss: 0.1049\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00067: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 427us/step - loss: 0.1164 - val_loss: 0.1015\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.1031 - val_loss: 0.0988\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.1006 - val_loss: 0.0995\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0992 - val_loss: 0.0971\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0977 - val_loss: 0.0981\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0966 - val_loss: 0.0964\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 309us/step - loss: 0.0954 - val_loss: 0.0971\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0952 - val_loss: 0.0985\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0941 - val_loss: 0.0959\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0942 - val_loss: 0.0960\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0931 - val_loss: 0.0960\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0927 - val_loss: 0.0958\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0922 - val_loss: 0.0971\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0915 - val_loss: 0.0982\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0915 - val_loss: 0.0974\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 15s 309us/step - loss: 0.0909 - val_loss: 0.0968\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0910 - val_loss: 0.0974\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0905 - val_loss: 0.0961\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0898 - val_loss: 0.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 15s 309us/step - loss: 0.0899 - val_loss: 0.0978\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0892 - val_loss: 0.0970\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0894 - val_loss: 0.0977\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0888 - val_loss: 0.0977\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0885 - val_loss: 0.0981\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0885 - val_loss: 0.0971\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0877 - val_loss: 0.0982\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0880 - val_loss: 0.0986\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0876 - val_loss: 0.0985\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0873 - val_loss: 0.0991\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0869 - val_loss: 0.0984\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0866 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0866 - val_loss: 0.0990\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0860 - val_loss: 0.0991\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0857 - val_loss: 0.0989\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0854 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0848 - val_loss: 0.1003\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0850 - val_loss: 0.0992\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0847 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0849 - val_loss: 0.1006\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0840 - val_loss: 0.1013\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0840 - val_loss: 0.0995\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0835 - val_loss: 0.1000\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0835 - val_loss: 0.1003\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0832 - val_loss: 0.1006\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0833 - val_loss: 0.1006\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0833 - val_loss: 0.1013\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 300us/step - loss: 0.0829 - val_loss: 0.1006\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0826 - val_loss: 0.1014\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0828 - val_loss: 0.1015\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0821 - val_loss: 0.1023\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0825 - val_loss: 0.1020\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0823 - val_loss: 0.1016\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0816 - val_loss: 0.1024\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0813 - val_loss: 0.1022\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0812 - val_loss: 0.1032\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0811 - val_loss: 0.1020\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0812 - val_loss: 0.1023\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0811 - val_loss: 0.1034\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0810 - val_loss: 0.1018\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0808 - val_loss: 0.1044\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0808 - val_loss: 0.1023\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 435us/step - loss: 0.1150 - val_loss: 0.1065\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.1027 - val_loss: 0.1007\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0993 - val_loss: 0.0988\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0979 - val_loss: 0.0988\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 15s 316us/step - loss: 0.0961 - val_loss: 0.0983\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 15s 315us/step - loss: 0.0954 - val_loss: 0.0982\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0945 - val_loss: 0.0974\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0934 - val_loss: 0.0989\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0932 - val_loss: 0.1011\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 15s 315us/step - loss: 0.0926 - val_loss: 0.0980\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0925 - val_loss: 0.0979\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0915 - val_loss: 0.0966\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0912 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0905 - val_loss: 0.0982\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0902 - val_loss: 0.0985\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 13s 285us/step - loss: 0.0898 - val_loss: 0.0969\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0895 - val_loss: 0.0973\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0892 - val_loss: 0.0980\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0891 - val_loss: 0.0972\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0885 - val_loss: 0.0974\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 251us/step - loss: 0.0879 - val_loss: 0.0989\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 251us/step - loss: 0.0877 - val_loss: 0.0990\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0878 - val_loss: 0.0980\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0874 - val_loss: 0.0984\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0870 - val_loss: 0.0985\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0867 - val_loss: 0.0991\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0865 - val_loss: 0.0988\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0860 - val_loss: 0.0991\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0862 - val_loss: 0.0978\n",
      "Epoch 30/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0853 - val_loss: 0.0981\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0857 - val_loss: 0.0987\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0851 - val_loss: 0.0991\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0848 - val_loss: 0.0992\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0847 - val_loss: 0.0985\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0845 - val_loss: 0.0999\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0841 - val_loss: 0.1005\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0840 - val_loss: 0.1011\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0841 - val_loss: 0.1006\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0840 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0833 - val_loss: 0.1005\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0829 - val_loss: 0.1005\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0830 - val_loss: 0.0995\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0827 - val_loss: 0.1000\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0822 - val_loss: 0.1009\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0822 - val_loss: 0.1011\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0821 - val_loss: 0.1008\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0819 - val_loss: 0.1017\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0817 - val_loss: 0.1011\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0812 - val_loss: 0.1017\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0814 - val_loss: 0.1014\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0808 - val_loss: 0.1026\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0810 - val_loss: 0.1029\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0804 - val_loss: 0.1023\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0801 - val_loss: 0.1017\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0799 - val_loss: 0.1027\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0799 - val_loss: 0.1032\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0804 - val_loss: 0.1036\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0795 - val_loss: 0.1018\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0794 - val_loss: 0.1034\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0794 - val_loss: 0.1030\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0792 - val_loss: 0.1033\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0788 - val_loss: 0.1033\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 17s 363us/step - loss: 0.1156 - val_loss: 0.1030\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.1027 - val_loss: 0.1007\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0998 - val_loss: 0.0976\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0985 - val_loss: 0.0973\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0973 - val_loss: 0.0961\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0959 - val_loss: 0.0976\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0947 - val_loss: 0.0983\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0942 - val_loss: 0.0966\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0934 - val_loss: 0.0961\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0929 - val_loss: 0.0972\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0922 - val_loss: 0.0951\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0919 - val_loss: 0.0966\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0913 - val_loss: 0.0964\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0912 - val_loss: 0.0963\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0905 - val_loss: 0.0958\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0901 - val_loss: 0.0967\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0898 - val_loss: 0.0960\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0896 - val_loss: 0.0960\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0892 - val_loss: 0.0959\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0885 - val_loss: 0.0961\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0881 - val_loss: 0.0949\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0878 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0878 - val_loss: 0.0959\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0875 - val_loss: 0.0970\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0869 - val_loss: 0.0959\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0867 - val_loss: 0.0968\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0863 - val_loss: 0.0972\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0862 - val_loss: 0.0972\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0860 - val_loss: 0.0976\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0858 - val_loss: 0.0972\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0856 - val_loss: 0.0964\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0854 - val_loss: 0.0968\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0849 - val_loss: 0.0974\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0849 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0847 - val_loss: 0.0980\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0846 - val_loss: 0.0969\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0843 - val_loss: 0.0982\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0841 - val_loss: 0.0971\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0841 - val_loss: 0.0979\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0836 - val_loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0833 - val_loss: 0.0976\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0835 - val_loss: 0.0977\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0829 - val_loss: 0.0997\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0829 - val_loss: 0.0987\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0826 - val_loss: 0.0987\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0823 - val_loss: 0.0987\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0822 - val_loss: 0.0990\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0823 - val_loss: 0.0993\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0818 - val_loss: 0.0986\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0817 - val_loss: 0.0982\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0815 - val_loss: 0.1003\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0816 - val_loss: 0.0995\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0811 - val_loss: 0.0993\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0812 - val_loss: 0.1007\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0807 - val_loss: 0.1000\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0805 - val_loss: 0.1008\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0803 - val_loss: 0.1003\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 252us/step - loss: 0.0807 - val_loss: 0.0997\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 252us/step - loss: 0.0807 - val_loss: 0.1004\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0800 - val_loss: 0.1020\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0799 - val_loss: 0.1014\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0799 - val_loss: 0.0994\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0797 - val_loss: 0.1006\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0795 - val_loss: 0.1015\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0796 - val_loss: 0.1003\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0792 - val_loss: 0.1011\n",
      "Epoch 67/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0787 - val_loss: 0.1004\n",
      "Epoch 68/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0793 - val_loss: 0.1013\n",
      "Epoch 69/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0788 - val_loss: 0.1010\n",
      "Epoch 70/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0788 - val_loss: 0.1025\n",
      "Epoch 71/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0785 - val_loss: 0.1017\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00071: early stopping\n",
      "0.3091182938655459\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 5, 50, 0.3)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 17s 367us/step - loss: 0.1194 - val_loss: 0.1088\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.1048 - val_loss: 0.0991\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.1018 - val_loss: 0.0973\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.1000 - val_loss: 0.1009\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0990 - val_loss: 0.0964\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.0984 - val_loss: 0.0956\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0971 - val_loss: 0.0955\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0963 - val_loss: 0.0952\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0958 - val_loss: 0.0971\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0955 - val_loss: 0.0995\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0945 - val_loss: 0.0954\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0942 - val_loss: 0.0951\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0940 - val_loss: 0.0966\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0934 - val_loss: 0.0953\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0930 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0926 - val_loss: 0.0954\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0922 - val_loss: 0.0963\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0922 - val_loss: 0.0957\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0919 - val_loss: 0.0980\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0914 - val_loss: 0.0950\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0915 - val_loss: 0.0952\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0908 - val_loss: 0.0949\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0911 - val_loss: 0.0957\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0907 - val_loss: 0.0971\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0905 - val_loss: 0.0956\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0905 - val_loss: 0.0962\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0902 - val_loss: 0.0962\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0901 - val_loss: 0.0964\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0897 - val_loss: 0.0966\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0899 - val_loss: 0.0969\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0901 - val_loss: 0.0971\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0892 - val_loss: 0.0972\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0897 - val_loss: 0.1060\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0905 - val_loss: 0.0965\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0891 - val_loss: 0.0960\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0890 - val_loss: 0.0969\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0887 - val_loss: 0.0966\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0886 - val_loss: 0.0964\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0885 - val_loss: 0.0988\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0885 - val_loss: 0.0974\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0882 - val_loss: 0.0978\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0885 - val_loss: 0.0983\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0883 - val_loss: 0.0977\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0879 - val_loss: 0.0967\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0880 - val_loss: 0.0978\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0876 - val_loss: 0.0979\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0874 - val_loss: 0.0997\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0876 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0874 - val_loss: 0.0986\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0981\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0869 - val_loss: 0.0989\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0976\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0867 - val_loss: 0.0974\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0869 - val_loss: 0.0994\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.0991\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0865 - val_loss: 0.0983\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0865 - val_loss: 0.0982\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0865 - val_loss: 0.0981\n",
      "Epoch 60/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0863 - val_loss: 0.0997\n",
      "Epoch 61/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0862 - val_loss: 0.0998\n",
      "Epoch 62/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0864 - val_loss: 0.1002\n",
      "Epoch 63/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0862 - val_loss: 0.0991\n",
      "Epoch 64/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0864 - val_loss: 0.0984\n",
      "Epoch 65/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0858 - val_loss: 0.0981\n",
      "Epoch 66/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0856 - val_loss: 0.0986\n",
      "Epoch 67/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0859 - val_loss: 0.0988\n",
      "Epoch 68/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.0979\n",
      "Epoch 69/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.1003\n",
      "Epoch 70/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0855 - val_loss: 0.0998\n",
      "Epoch 71/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.0986\n",
      "Epoch 72/10000\n",
      "46874/46874 [==============================] - 12s 260us/step - loss: 0.0853 - val_loss: 0.0993\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00072: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 17s 368us/step - loss: 0.1202 - val_loss: 0.1005\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.1033 - val_loss: 0.0989\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.1009 - val_loss: 0.1132\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0996 - val_loss: 0.0977\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0981 - val_loss: 0.0975\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0970 - val_loss: 0.0977\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0966 - val_loss: 0.0970\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0955 - val_loss: 0.0965\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0949 - val_loss: 0.0963\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0947 - val_loss: 0.0963\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0940 - val_loss: 0.0970\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0932 - val_loss: 0.0978\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0933 - val_loss: 0.0983\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0929 - val_loss: 0.0970\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0925 - val_loss: 0.0966\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0922 - val_loss: 0.0997\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0922 - val_loss: 0.0966\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0916 - val_loss: 0.0972\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0914 - val_loss: 0.0975\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0910 - val_loss: 0.0979\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0908 - val_loss: 0.0968\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0906 - val_loss: 0.0985\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0905 - val_loss: 0.0973\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0903 - val_loss: 0.0970\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0898 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0899 - val_loss: 0.0984\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 258us/step - loss: 0.0900 - val_loss: 0.0968\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0896 - val_loss: 0.0973\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0898 - val_loss: 0.0990\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0893 - val_loss: 0.0987\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0892 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0891 - val_loss: 0.0989\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0890 - val_loss: 0.1003\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0885 - val_loss: 0.0986\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0886 - val_loss: 0.0988\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0883 - val_loss: 0.0992\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0884 - val_loss: 0.0998\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0881 - val_loss: 0.0986\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0881 - val_loss: 0.1000\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0877 - val_loss: 0.0985\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0876 - val_loss: 0.0984\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0882 - val_loss: 0.0987\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0871 - val_loss: 0.0992\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0875 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0876 - val_loss: 0.0999\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0872 - val_loss: 0.0999\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0873 - val_loss: 0.1003\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0871 - val_loss: 0.0992\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0873 - val_loss: 0.0999\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0871 - val_loss: 0.1007\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0874 - val_loss: 0.1003\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0868 - val_loss: 0.1002\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.1003\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0872 - val_loss: 0.1002\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0867 - val_loss: 0.1001\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 258us/step - loss: 0.0866 - val_loss: 0.1002\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0871 - val_loss: 0.1007\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0866 - val_loss: 0.0996\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 377us/step - loss: 0.1185 - val_loss: 0.1037\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1055 - val_loss: 0.1006\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.1019 - val_loss: 0.1009\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1004 - val_loss: 0.0979\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0986 - val_loss: 0.0963\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0982 - val_loss: 0.0979\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0971 - val_loss: 0.0965\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0962 - val_loss: 0.0980\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0955 - val_loss: 0.0966\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0953 - val_loss: 0.0983\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0949 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0943 - val_loss: 0.0957\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0936 - val_loss: 0.0963\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0931 - val_loss: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0933 - val_loss: 0.0958\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0925 - val_loss: 0.0968\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0925 - val_loss: 0.0966\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0921 - val_loss: 0.0974\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0916 - val_loss: 0.0964\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0914 - val_loss: 0.0959\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0914 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0909 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0908 - val_loss: 0.0971\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0911 - val_loss: 0.0976\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0902 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0904 - val_loss: 0.0998\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0904 - val_loss: 0.0972\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0899 - val_loss: 0.0976\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0897 - val_loss: 0.0974\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0896 - val_loss: 0.0977\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0894 - val_loss: 0.0968\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0890 - val_loss: 0.0982\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0890 - val_loss: 0.0986\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0889 - val_loss: 0.0973\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0888 - val_loss: 0.0983\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0891 - val_loss: 0.0979\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0888 - val_loss: 0.0978\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0983\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0990\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0988\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0885 - val_loss: 0.1007\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0882 - val_loss: 0.0985\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0882 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0882 - val_loss: 0.0983\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0877 - val_loss: 0.0985\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0882 - val_loss: 0.0998\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0876 - val_loss: 0.0995\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0877 - val_loss: 0.0993\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0874 - val_loss: 0.0994\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0874 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0997\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.1001\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0874 - val_loss: 0.0992\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0866 - val_loss: 0.0996\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.1006\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0870 - val_loss: 0.0999\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.0986\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0865 - val_loss: 0.0993\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.1007\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.0988\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0866 - val_loss: 0.0987\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 377us/step - loss: 0.1191 - val_loss: 0.1030\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1040 - val_loss: 0.1009\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.1017 - val_loss: 0.0991\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0998 - val_loss: 0.0998\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0982 - val_loss: 0.0977\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0970 - val_loss: 0.0976\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0961 - val_loss: 0.0979\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0953 - val_loss: 0.0985\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0948 - val_loss: 0.0984\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0944 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0940 - val_loss: 0.0973\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0935 - val_loss: 0.0976\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0934 - val_loss: 0.0973\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0932 - val_loss: 0.0993\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0924 - val_loss: 0.0982\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0922 - val_loss: 0.0979\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0917 - val_loss: 0.0976\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0916 - val_loss: 0.1042\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0912 - val_loss: 0.0982\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0910 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0910 - val_loss: 0.0989\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0904 - val_loss: 0.0975\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0902 - val_loss: 0.0979\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0902 - val_loss: 0.0993\n",
      "Epoch 25/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0898 - val_loss: 0.0984\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0901 - val_loss: 0.0987\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0896 - val_loss: 0.0987\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0896 - val_loss: 0.0980\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0898 - val_loss: 0.0981\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0895 - val_loss: 0.0988\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0890 - val_loss: 0.0988\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0980\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0985\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0881 - val_loss: 0.0998\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0882 - val_loss: 0.0998\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0884 - val_loss: 0.0983\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0878 - val_loss: 0.0993\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0877 - val_loss: 0.0991\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0883 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0878 - val_loss: 0.0990\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0876 - val_loss: 0.0990\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0876 - val_loss: 0.0995\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0871 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0872 - val_loss: 0.0993\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0869 - val_loss: 0.1005\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.0999\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0867 - val_loss: 0.0992\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.1004\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0868 - val_loss: 0.1015\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0874 - val_loss: 0.0995\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0864 - val_loss: 0.0995\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0863 - val_loss: 0.1008\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0862 - val_loss: 0.1004\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0860 - val_loss: 0.0997\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0861 - val_loss: 0.1003\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0860 - val_loss: 0.0994\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0858 - val_loss: 0.0997\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0859 - val_loss: 0.0999\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00060: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 383us/step - loss: 0.1167 - val_loss: 0.1031\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.1041 - val_loss: 0.0997\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.1017 - val_loss: 0.0979\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0991 - val_loss: 0.0977\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0980 - val_loss: 0.0965\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0969 - val_loss: 0.0968\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0962 - val_loss: 0.0959\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0951 - val_loss: 0.0990\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0945 - val_loss: 0.0977\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0935 - val_loss: 0.0955\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0938 - val_loss: 0.0959\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0929 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0924 - val_loss: 0.0954\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0924 - val_loss: 0.0962\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0919 - val_loss: 0.0970\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0915 - val_loss: 0.0971\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0915 - val_loss: 0.0963\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0913 - val_loss: 0.0962\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0907 - val_loss: 0.0983\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0906 - val_loss: 0.0977\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0903 - val_loss: 0.0974\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0905 - val_loss: 0.0979\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0904 - val_loss: 0.0984\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0900 - val_loss: 0.0974\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0901 - val_loss: 0.0975\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0894 - val_loss: 0.0981\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0892 - val_loss: 0.0973\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0889 - val_loss: 0.0980\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0891 - val_loss: 0.0985\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0885 - val_loss: 0.0969\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0887 - val_loss: 0.0984\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0880 - val_loss: 0.0982\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0882 - val_loss: 0.0973\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0885 - val_loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0880 - val_loss: 0.0980\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0881 - val_loss: 0.0974\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0997\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0981\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0875 - val_loss: 0.0984\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0872 - val_loss: 0.0989\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0875 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0869 - val_loss: 0.0983\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0867 - val_loss: 0.0979\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0870 - val_loss: 0.0991\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0867 - val_loss: 0.0983\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0869 - val_loss: 0.0984\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0868 - val_loss: 0.0988\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0869 - val_loss: 0.0993\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0864 - val_loss: 0.0996\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0865 - val_loss: 0.0990\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0860 - val_loss: 0.0982\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0868 - val_loss: 0.1029\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0881 - val_loss: 0.1004\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0863 - val_loss: 0.0995\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0863 - val_loss: 0.0988\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0861 - val_loss: 0.0979\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0860 - val_loss: 0.0996\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0859 - val_loss: 0.1007\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0858 - val_loss: 0.1008\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0856 - val_loss: 0.0999\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00064: early stopping\n",
      "0.31002641435643463\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 5, 50, 0.5)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check pipe\n",
    "* Add L2 reg\n",
    "* look for text embeddings\n",
    "* preprocess text\n",
    "* build archi\n",
    "* print archi\n",
    "* pretrained emb\n",
    "* tqdm notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=10, last_dense=40, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='relu', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='relu', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='relu', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='relu', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    prod_ = Dense(50, activation='relu', name=\"Dense_\")(prod2)\n",
    "    drop = Dropout(rate=0.3)(prod_)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='relu', name=\"Dense3\")(drop)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 21s 438us/step - loss: 0.1130 - val_loss: 0.1007\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 14s 293us/step - loss: 0.1022 - val_loss: 0.0998\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0992 - val_loss: 0.0965\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0978 - val_loss: 0.0970\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0962 - val_loss: 0.0962\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0950 - val_loss: 0.0967\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0938 - val_loss: 0.0956\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0934 - val_loss: 0.0957\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 14s 302us/step - loss: 0.0918 - val_loss: 0.0966\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 15s 314us/step - loss: 0.0913 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 15s 314us/step - loss: 0.0902 - val_loss: 0.0956\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 14s 309us/step - loss: 0.0892 - val_loss: 0.0961\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 14s 297us/step - loss: 0.0889 - val_loss: 0.0965\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0878 - val_loss: 0.0965\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0870 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0858 - val_loss: 0.0966\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0849 - val_loss: 0.0985\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0839 - val_loss: 0.0973\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0829 - val_loss: 0.0995\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0822 - val_loss: 0.0997\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0814 - val_loss: 0.0996\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0804 - val_loss: 0.0999\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 14s 298us/step - loss: 0.0798 - val_loss: 0.0997\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0784 - val_loss: 0.0998\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0783 - val_loss: 0.1008\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0769 - val_loss: 0.1011\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0764 - val_loss: 0.1021\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0757 - val_loss: 0.1026\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0750 - val_loss: 0.1031\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0739 - val_loss: 0.1029\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0734 - val_loss: 0.1025\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0730 - val_loss: 0.1028\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0728 - val_loss: 0.1050\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0717 - val_loss: 0.1067\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0712 - val_loss: 0.1063\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0709 - val_loss: 0.1054\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0706 - val_loss: 0.1079\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 14s 297us/step - loss: 0.0697 - val_loss: 0.1083\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0692 - val_loss: 0.1047\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0683 - val_loss: 0.1049\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0679 - val_loss: 0.1076\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0678 - val_loss: 0.1068\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0675 - val_loss: 0.1069\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 14s 300us/step - loss: 0.0668 - val_loss: 0.1106\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0661 - val_loss: 0.1136\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0657 - val_loss: 0.1098\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 14s 292us/step - loss: 0.0655 - val_loss: 0.1094\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0653 - val_loss: 0.1115\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0651 - val_loss: 0.1093\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0646 - val_loss: 0.1135\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 14s 289us/step - loss: 0.0640 - val_loss: 0.1111\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0635 - val_loss: 0.1118\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 14s 292us/step - loss: 0.0637 - val_loss: 0.1095\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0632 - val_loss: 0.1111\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0628 - val_loss: 0.1125\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0628 - val_loss: 0.1132\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0620 - val_loss: 0.1112\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 423us/step - loss: 0.1153 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.1026 - val_loss: 0.0978\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0995 - val_loss: 0.0989\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0981 - val_loss: 0.0969\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0964 - val_loss: 0.0956\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0950 - val_loss: 0.0955\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0939 - val_loss: 0.0952\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0933 - val_loss: 0.1018\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0925 - val_loss: 0.0949\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0914 - val_loss: 0.0961\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0907 - val_loss: 0.0956\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0895 - val_loss: 0.0949\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0887 - val_loss: 0.0986\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0881 - val_loss: 0.0971\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0869 - val_loss: 0.0992\n",
      "Epoch 16/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0850 - val_loss: 0.0983\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0844 - val_loss: 0.0988\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0838 - val_loss: 0.1012\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0826 - val_loss: 0.1006\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0818 - val_loss: 0.1016\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0814 - val_loss: 0.1009\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0807 - val_loss: 0.1019\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0797 - val_loss: 0.1014\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0786 - val_loss: 0.1049\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0778 - val_loss: 0.1054\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0774 - val_loss: 0.1039\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0764 - val_loss: 0.1043\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0752 - val_loss: 0.1057\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0755 - val_loss: 0.1038\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0736 - val_loss: 0.1057\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0733 - val_loss: 0.1059\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0726 - val_loss: 0.1055\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0721 - val_loss: 0.1106\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0716 - val_loss: 0.1066\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0707 - val_loss: 0.1096\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0702 - val_loss: 0.1090\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0693 - val_loss: 0.1075\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0692 - val_loss: 0.1084\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0687 - val_loss: 0.1094\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0682 - val_loss: 0.1125\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0677 - val_loss: 0.1086\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0671 - val_loss: 0.1146\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0672 - val_loss: 0.1114\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0659 - val_loss: 0.1102\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0656 - val_loss: 0.1106\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0656 - val_loss: 0.1112\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0655 - val_loss: 0.1135\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0653 - val_loss: 0.1121\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0641 - val_loss: 0.1118\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0640 - val_loss: 0.1158\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0636 - val_loss: 0.1140\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0634 - val_loss: 0.1147\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0626 - val_loss: 0.1123\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0628 - val_loss: 0.1143\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0626 - val_loss: 0.1151\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0619 - val_loss: 0.1181\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0615 - val_loss: 0.1145\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0615 - val_loss: 0.1123\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 425us/step - loss: 0.1139 - val_loss: 0.1027\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.1020 - val_loss: 0.0981\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0994 - val_loss: 0.0966\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0980 - val_loss: 0.0967\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0962 - val_loss: 0.0983\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0953 - val_loss: 0.0965\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0938 - val_loss: 0.0960\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0923 - val_loss: 0.0975\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0921 - val_loss: 0.1007\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0907 - val_loss: 0.0969\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0900 - val_loss: 0.0984\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0888 - val_loss: 0.0976\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0875 - val_loss: 0.0993\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0866 - val_loss: 0.0983\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0859 - val_loss: 0.0986\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0848 - val_loss: 0.1003\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0839 - val_loss: 0.0993\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0828 - val_loss: 0.0992\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0818 - val_loss: 0.1002\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0806 - val_loss: 0.1013\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0799 - val_loss: 0.1027\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0793 - val_loss: 0.1020\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0791 - val_loss: 0.1006\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0773 - val_loss: 0.1030\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0768 - val_loss: 0.1042\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0760 - val_loss: 0.1040\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0751 - val_loss: 0.1041\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0740 - val_loss: 0.1051\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0736 - val_loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0735 - val_loss: 0.1061\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0721 - val_loss: 0.1083\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0712 - val_loss: 0.1057\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0708 - val_loss: 0.1093\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0702 - val_loss: 0.1069\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0694 - val_loss: 0.1096\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0688 - val_loss: 0.1098\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0683 - val_loss: 0.1118\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0680 - val_loss: 0.1110\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0669 - val_loss: 0.1107\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0668 - val_loss: 0.1113\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0662 - val_loss: 0.1112\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0660 - val_loss: 0.1097\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0652 - val_loss: 0.1135\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0652 - val_loss: 0.1118\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0648 - val_loss: 0.1126\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0646 - val_loss: 0.1131\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0642 - val_loss: 0.1138\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0643 - val_loss: 0.1135\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0633 - val_loss: 0.1134\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0625 - val_loss: 0.1157\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0623 - val_loss: 0.1150\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0627 - val_loss: 0.1159\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0625 - val_loss: 0.1148\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0616 - val_loss: 0.1156\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0618 - val_loss: 0.1178\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0614 - val_loss: 0.1187\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0611 - val_loss: 0.1121\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 429us/step - loss: 0.1147 - val_loss: 0.1031\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.1020 - val_loss: 0.1005\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0989 - val_loss: 0.1009\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0973 - val_loss: 0.0990\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0962 - val_loss: 0.0997\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0949 - val_loss: 0.0985\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0937 - val_loss: 0.0985\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0928 - val_loss: 0.0981\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0914 - val_loss: 0.0990\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0910 - val_loss: 0.0979\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0900 - val_loss: 0.0977\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0893 - val_loss: 0.0998\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0884 - val_loss: 0.0984\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0872 - val_loss: 0.0997\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0865 - val_loss: 0.0996\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0857 - val_loss: 0.0993\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0844 - val_loss: 0.1010\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0828 - val_loss: 0.1002\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0819 - val_loss: 0.0999\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0809 - val_loss: 0.1006\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0802 - val_loss: 0.1022\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0796 - val_loss: 0.1040\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0784 - val_loss: 0.1021\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0778 - val_loss: 0.1022\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0767 - val_loss: 0.1039\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0759 - val_loss: 0.1038\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0753 - val_loss: 0.1054\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0744 - val_loss: 0.1053\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0742 - val_loss: 0.1049\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0739 - val_loss: 0.1070\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0725 - val_loss: 0.1078\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0720 - val_loss: 0.1059\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0714 - val_loss: 0.1090\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0708 - val_loss: 0.1070\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0703 - val_loss: 0.1082\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0699 - val_loss: 0.1082\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0688 - val_loss: 0.1098\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0688 - val_loss: 0.1102\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0680 - val_loss: 0.1117\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0677 - val_loss: 0.1090\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0671 - val_loss: 0.1102\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0667 - val_loss: 0.1090\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0664 - val_loss: 0.1102\n",
      "Epoch 45/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0664 - val_loss: 0.1125\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0659 - val_loss: 0.1113\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0649 - val_loss: 0.1129\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0649 - val_loss: 0.1122\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0643 - val_loss: 0.1161\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0641 - val_loss: 0.1126\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0638 - val_loss: 0.1156\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0631 - val_loss: 0.1128\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0633 - val_loss: 0.1164\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0627 - val_loss: 0.1124\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0626 - val_loss: 0.1135\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0617 - val_loss: 0.1143\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0618 - val_loss: 0.1158\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0619 - val_loss: 0.1144\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0614 - val_loss: 0.1139\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0613 - val_loss: 0.1156\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0613 - val_loss: 0.1160\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00061: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 437us/step - loss: 0.1143 - val_loss: 0.1013\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.1023 - val_loss: 0.0979\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0972 - val_loss: 0.0973\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0960 - val_loss: 0.0980\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0946 - val_loss: 0.0974\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0932 - val_loss: 0.0964\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0921 - val_loss: 0.0958\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0913 - val_loss: 0.0967\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0906 - val_loss: 0.0973\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0894 - val_loss: 0.0990\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0887 - val_loss: 0.0977\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0879 - val_loss: 0.0975\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0867 - val_loss: 0.0969\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0858 - val_loss: 0.0976\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0857 - val_loss: 0.0970\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0844 - val_loss: 0.0993\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0837 - val_loss: 0.0977\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0829 - val_loss: 0.0998\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0818 - val_loss: 0.1000\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0812 - val_loss: 0.1003\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0804 - val_loss: 0.1026\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0792 - val_loss: 0.1016\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0787 - val_loss: 0.1021\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0780 - val_loss: 0.1039\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 305us/step - loss: 0.0772 - val_loss: 0.1048\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0763 - val_loss: 0.1040\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0759 - val_loss: 0.1023\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0750 - val_loss: 0.1043\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0747 - val_loss: 0.1072\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0735 - val_loss: 0.1051\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0729 - val_loss: 0.1073\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0725 - val_loss: 0.1079\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0718 - val_loss: 0.1077\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0713 - val_loss: 0.1067\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0706 - val_loss: 0.1053\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0701 - val_loss: 0.1092\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0691 - val_loss: 0.1089\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0689 - val_loss: 0.1072\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0683 - val_loss: 0.1094\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0679 - val_loss: 0.1115\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0676 - val_loss: 0.1113\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0673 - val_loss: 0.1110\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0665 - val_loss: 0.1118\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0662 - val_loss: 0.1107\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0658 - val_loss: 0.1098\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0652 - val_loss: 0.1127\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0654 - val_loss: 0.1117\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0647 - val_loss: 0.1139\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0652 - val_loss: 0.1131\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0641 - val_loss: 0.1141\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0639 - val_loss: 0.1158\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0638 - val_loss: 0.1118\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0631 - val_loss: 0.1140\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0627 - val_loss: 0.1132\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0626 - val_loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0625 - val_loss: 0.1128\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0628 - val_loss: 0.1136\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00058: early stopping\n",
      "0.3100033573517424\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 8, 100, 0.3)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content based : no interaction influencer/artist taken into account (no embedding for them)\n",
    "\n",
    "advantage : cold start allowed\n",
    "disadvantage : interesting info lossed\n",
    "\n",
    "==> hybrid recommender system\n",
    "\n",
    "label encoded influencer kind : in production, a category 'Other' can be created to account for potential kinds not present in current dataset.\n",
    "\n",
    "Grid search\n",
    "\n",
    "track info ==> proxy of song ID ==> potential leak for this dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groover",
   "language": "python",
   "name": "groover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
