{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/pa/.virtualenvs/groover/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/pa/.virtualenvs/groover/lib/python3.6/site-packages (from pydot) (2.4.6)\n",
      "Requirement already satisfied: graphviz in /home/pa/.virtualenvs/groover/lib/python3.6/site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_band</th>\n",
       "      <th>African music_band</th>\n",
       "      <th>Alternative rock_band</th>\n",
       "      <th>Ambient_band</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_influencer</th>\n",
       "      <th>Soul_influencer</th>\n",
       "      <th>Surf rock_influencer</th>\n",
       "      <th>Synthpop_influencer</th>\n",
       "      <th>Synthwave_influencer</th>\n",
       "      <th>Techno_influencer</th>\n",
       "      <th>Traditional Music_influencer</th>\n",
       "      <th>Trap_influencer</th>\n",
       "      <th>Trip hop_influencer</th>\n",
       "      <th>Variété Française_influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_band  African music_band  Alternative rock_band  Ambient_band  \\\n",
       "0                0                   0                      0             0   \n",
       "1                0                   0                      0             0   \n",
       "2                0                   0                      0             0   \n",
       "3                0                   0                      0             0   \n",
       "4                0                   0                      0             0   \n",
       "\n",
       "   ...  Singer-songwriter_influencer  Soul_influencer  Surf rock_influencer  \\\n",
       "0  ...                             0                0                     0   \n",
       "1  ...                             0                0                     0   \n",
       "2  ...                             0                1                     0   \n",
       "3  ...                             0                0                     1   \n",
       "4  ...                             0                0                     1   \n",
       "\n",
       "   Synthpop_influencer  Synthwave_influencer  Techno_influencer  \\\n",
       "0                    0                     0                  1   \n",
       "1                    0                     0                  0   \n",
       "2                    0                     0                  0   \n",
       "3                    0                     0                  0   \n",
       "4                    0                     0                  0   \n",
       "\n",
       "   Traditional Music_influencer  Trap_influencer  Trip hop_influencer  \\\n",
       "0                             0                0                    1   \n",
       "1                             0                0                    0   \n",
       "2                             0                1                    0   \n",
       "3                             0                0                    0   \n",
       "4                             0                0                    0   \n",
       "\n",
       "   Variété Française_influencer  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/preprocessed/merged_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stability measures of models, let us assess performance doing 5-Fold cross validation:\n",
    "\n",
    "one model kind will be trained 5 times, and its score will be averaged over the 5 out of sample sets.\n",
    "\n",
    "Stratified 5 Fold on `score` is performed so the target is welll distributed over the different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ Ids from tracks, bands and influencers are not allowed to be used since we are creating a **Content-Based** recommender system.\n",
    "\n",
    "This allows to avoid the cold start problem of only considering **Collaborative Filtering** but can be a loss of information for **Hybrid** recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['id', 'track_id', 'band_id', 'influencer_id', 'score'])\n",
    "y = dataset.score\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** averaged over the 5 out of sample datasets will be the performance metric.\n",
    "\n",
    "* Naive model : predicting score mean (computed of train sets) on test. Its score should be close to standard deviation of test\n",
    "\n",
    "* Random model : predicting [0, 1] random uniform score on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_train_mean = 0.0\n",
    "std_test_mean = 0.0\n",
    "naive_score = 0.0\n",
    "random_score =  0.0\n",
    "\n",
    "## y is transformed to an integer so skf can be performed\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    std_train_mean += np.std(y_train)\n",
    "    std_test_mean += np.std(y_test)\n",
    "    naive_score += np.sqrt(mean_squared_error([y_train.mean()] * len(y_test), y_test))\n",
    "    random_score += np.sqrt(mean_squared_error(np.random.uniform(0, 1, size=len(y_test)), y_test))\n",
    "\n",
    "std_train_mean /= N_FOLDS\n",
    "std_test_mean /= N_FOLDS\n",
    "naive_score /= N_FOLDS\n",
    "random_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average standard deviation of score on in sample sets: 0.39570093979500703\n",
      "\n",
      "Average standard deviation of score on out of sample sets: 0.39570093963773195\n",
      "\n",
      "Average RMSE of naive model on out of sample sets: 0.3957009399899617\n",
      "\n",
      "Average RMSE of random uniform model on out of sample sets: 0.5503498753830948\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nAverage standard deviation of score on in sample sets: {std_train_mean}')\n",
    "print(f'\\nAverage standard deviation of score on out of sample sets: {std_test_mean}')\n",
    "print(f'\\nAverage RMSE of naive model on out of sample sets: {naive_score}')\n",
    "print(f'\\nAverage RMSE of random uniform model on out of sample sets: {random_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train a LGBM model early stopped on 10% of in sample datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0947876\n",
      "[1000]\tvalid_0's l2: 0.092996\n",
      "[1500]\tvalid_0's l2: 0.0926348\n",
      "[2000]\tvalid_0's l2: 0.0926313\n",
      "[2500]\tvalid_0's l2: 0.0926313\n",
      "[3000]\tvalid_0's l2: 0.0926313\n",
      "[3500]\tvalid_0's l2: 0.0926313\n",
      "[4000]\tvalid_0's l2: 0.0926313\n",
      "[4500]\tvalid_0's l2: 0.0926313\n",
      "[5000]\tvalid_0's l2: 0.0926313\n",
      "[5500]\tvalid_0's l2: 0.0926313\n",
      "[6000]\tvalid_0's l2: 0.0926313\n",
      "[6500]\tvalid_0's l2: 0.0926313\n",
      "Early stopping, best iteration is:\n",
      "[6559]\tvalid_0's l2: 0.0926313\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0973691\n",
      "[1000]\tvalid_0's l2: 0.0953712\n",
      "[1500]\tvalid_0's l2: 0.0950005\n",
      "Early stopping, best iteration is:\n",
      "[1647]\tvalid_0's l2: 0.0949962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.096489\n",
      "[1000]\tvalid_0's l2: 0.094622\n",
      "[1500]\tvalid_0's l2: 0.0942171\n",
      "[2000]\tvalid_0's l2: 0.0940687\n",
      "Early stopping, best iteration is:\n",
      "[2018]\tvalid_0's l2: 0.0940683\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0948444\n",
      "[1000]\tvalid_0's l2: 0.0929073\n",
      "[1500]\tvalid_0's l2: 0.0925528\n",
      "[2000]\tvalid_0's l2: 0.0924698\n",
      "[2500]\tvalid_0's l2: 0.0924697\n",
      "[3000]\tvalid_0's l2: 0.0924697\n",
      "[3500]\tvalid_0's l2: 0.0924697\n",
      "[4000]\tvalid_0's l2: 0.0924697\n",
      "Early stopping, best iteration is:\n",
      "[4372]\tvalid_0's l2: 0.0924697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.09535\n",
      "[1000]\tvalid_0's l2: 0.0937357\n",
      "[1500]\tvalid_0's l2: 0.0934406\n",
      "[2000]\tvalid_0's l2: 0.0934011\n",
      "[2500]\tvalid_0's l2: 0.0934011\n",
      "[3000]\tvalid_0's l2: 0.0934011\n",
      "Early stopping, best iteration is:\n",
      "[3046]\tvalid_0's l2: 0.0934011\n"
     ]
    }
   ],
   "source": [
    "lgbm_score =  0.0\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(\n",
    "        num_leaves=2**10,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.5,\n",
    "        reg_alpha=10.0,\n",
    "        reg_lambda=10.0,\n",
    "        n_estimators=10000,\n",
    "        silent=False\n",
    "    )\n",
    "    lgbm.fit(X_train, y_train, eval_set=(X_valid, y_valid), \n",
    "             eval_metric='mse', early_stopping_rounds=100,\n",
    "             verbose=500)\n",
    "    lgbm_score += np.sqrt(mean_squared_error(lgbm.predict(X_test), y_test))\n",
    "\n",
    "lgbm_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.308811089530982\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM score: {lgbm_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_data = X.filter(regex='_band')\n",
    "influencer_data = X.filter(regex='_influencer')\n",
    "\n",
    "influencer_kind = X.influencer_kind\n",
    "i_kind_idx = X.columns.get_loc('influencer_kind')\n",
    "\n",
    "b_data_idx = [X.columns.get_loc(c) for c in band_data]\n",
    "i_data_idx = [X.columns.get_loc(c) for c in influencer_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple dot product model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Dot_model(\n",
    "    i_emb_dim=16, \n",
    "    b_emb_dim=16,\n",
    "    activation='relu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Build simple MLP Neural Network.\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[influencer_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation=activation, name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[band_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation=activation, name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Dot(name=\"Dot-Product\", axes=-1)([influencer_embedding, band_embedding])\n",
    "    \n",
    "    # Output\n",
    "    band_embedding_model = Model([influencer_input, band_input], band_embedding)\n",
    "    influencer_embedding_model = Model([influencer_input, band_input], influencer_embedding)\n",
    "    model = Model([influencer_input, band_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model, band_embedding_model, influencer_embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model and visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model, band_embedding_model, influencer_embedding_model = build_Dot_model()\n",
    "\n",
    "# Plot architecture\n",
    "plot_model(model, to_file='Dot_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "83706/83706 [==============================] - 2s 24us/step - loss: 0.1372\n",
      "Epoch 2/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.1094\n",
      "Epoch 3/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.1016\n",
      "Epoch 4/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0991\n",
      "Epoch 5/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0976\n",
      "Epoch 6/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0968\n",
      "Epoch 7/20\n",
      "83706/83706 [==============================] - 2s 24us/step - loss: 0.0964\n",
      "Epoch 8/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0961\n",
      "Epoch 9/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0956\n",
      "Epoch 10/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0954\n",
      "Epoch 11/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0952\n",
      "Epoch 12/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0950\n",
      "Epoch 13/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0948\n",
      "Epoch 14/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0948\n",
      "Epoch 15/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0945\n",
      "Epoch 16/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0946\n",
      "Epoch 17/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0943\n",
      "Epoch 18/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0944\n",
      "Epoch 19/20\n",
      "83706/83706 [==============================] - 2s 22us/step - loss: 0.0941\n",
      "Epoch 20/20\n",
      "83706/83706 [==============================] - 2s 23us/step - loss: 0.0940\n"
     ]
    }
   ],
   "source": [
    "# Fit model on 10 epochs on all data\n",
    "history = model.fit([influencer_data, band_data], dataset.score, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 70 nearest neighbors...\n",
      "[t-SNE] Indexed 71 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 71 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 71 / 71\n",
      "[t-SNE] Mean sigma: 0.557261\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 53.845135\n",
      "[t-SNE] KL divergence after 300 iterations: 0.770831\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "x=%{x}<br>y=%{y}<br>text=%{text}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "showlegend": false,
         "text": [
          "Acid house",
          "African music",
          "Alternative rock",
          "Ambient",
          "Blues",
          "Bossa Nova",
          "Chill-out",
          "Classical Music",
          "Coldwave",
          "Country",
          "Dance music",
          "Dance-pop",
          "Deep house",
          "Disco",
          "Dream Pop",
          "Dub",
          "Electro swing",
          "Electronic rock",
          "Electronica",
          "Electropop",
          "Experimental",
          "Experimental Jazz",
          "Experimental rock",
          "Film Music",
          "French house",
          "Funk",
          "Future house",
          "Garage rock",
          "Grime",
          "Hard rock",
          "Hip hop",
          "House music",
          "Indie folk",
          "Indie pop",
          "Indie rock",
          "Instrumental",
          "International Pop",
          "Latin music",
          "Lo-Fi",
          "Metal",
          "Minimal",
          "Modern Jazz",
          "New wave",
          "Noise rock",
          "Nouvelle Scène",
          "Nu-disco",
          "Pop rock",
          "Pop soul",
          "Post-punk",
          "Post-rock",
          "Progressive pop",
          "Progressive rock",
          "Psychedelic pop",
          "Psychedelic rock",
          "Punk",
          "R&B",
          "Rap",
          "Rap français",
          "Reggae",
          "Rock and roll",
          "Samba",
          "Singer-songwriter",
          "Soul",
          "Surf rock",
          "Synthpop",
          "Synthwave",
          "Techno",
          "Traditional Music",
          "Trap",
          "Trip hop",
          "Variété Française"
         ],
         "type": "scatter",
         "x": [
          -14.74853229522705,
          17.682838439941406,
          4.965287208557129,
          7.3318071365356445,
          17.349782943725586,
          -29.038164138793945,
          10.018109321594238,
          -22.190324783325195,
          0.00833328440785408,
          -34.290462493896484,
          -18.661819458007812,
          -44.31754684448242,
          0.15159042179584503,
          36.18705749511719,
          9.975814819335938,
          23.626827239990234,
          39.53641128540039,
          -19.76634979248047,
          -4.820689678192139,
          -1.1509919166564941,
          2.710825204849243,
          16.15608024597168,
          -17.016632080078125,
          1.8929799795150757,
          19.242267608642578,
          17.734994888305664,
          -3.7871947288513184,
          -9.638981819152832,
          30.49393081665039,
          -25.717613220214844,
          -33.36548614501953,
          25.483789443969727,
          -6.18173360824585,
          4.014444828033447,
          -7.202876567840576,
          7.121709823608398,
          11.735377311706543,
          23.940202713012695,
          -21.50227165222168,
          -29.63962745666504,
          6.372770309448242,
          -29.894298553466797,
          -3.6615445613861084,
          -12.36172866821289,
          -60.917972564697266,
          -13.409652709960938,
          -4.567030906677246,
          4.707525730133057,
          11.31328010559082,
          -10.173579216003418,
          3.926175355911255,
          -25.388864517211914,
          -12.126287460327148,
          10.580570220947266,
          -19.25565528869629,
          -4.833492755889893,
          31.022502899169922,
          -11.589822769165039,
          -11.433586120605469,
          0.6280190944671631,
          17.92748260498047,
          17.750226974487305,
          19.75979995727539,
          -29.78652572631836,
          0.20626206696033478,
          -17.477617263793945,
          31.65266990661621,
          30.424257278442383,
          -14.670209884643555,
          -7.367153644561768,
          -3.008390426635742
         ],
         "xaxis": "x",
         "y": [
          -15.31822395324707,
          6.2620720863342285,
          9.915458679199219,
          4.76536750793457,
          -6.688090801239014,
          -15.853318214416504,
          -5.662812232971191,
          7.831477165222168,
          -38.06044387817383,
          13.964759826660156,
          1.1890119314193726,
          -3.344533681869507,
          33.35895538330078,
          8.175802230834961,
          -14.344127655029297,
          16.002904891967773,
          -9.735025405883789,
          -6.852057456970215,
          -9.087818145751953,
          -2.943114757537842,
          -18.617233276367188,
          12.681920051574707,
          -29.953325271606445,
          15.142009735107422,
          -0.44492805004119873,
          -13.501596450805664,
          -25.408620834350586,
          9.681718826293945,
          -23.115806579589844,
          15.131693840026855,
          -5.149643898010254,
          3.347667694091797,
          27.612110137939453,
          -8.223662376403809,
          -3.3968605995178223,
          27.29782485961914,
          -0.145525261759758,
          -10.040058135986328,
          -14.331521987915039,
          -27.81319808959961,
          -26.564224243164062,
          2.960843324661255,
          20.7110652923584,
          22.06574249267578,
          -2.420520782470703,
          -2.6612446308135986,
          1.5138969421386719,
          -0.7790586352348328,
          19.740093231201172,
          15.165520668029785,
          21.007604598999023,
          -5.885558128356934,
          -8.383081436157227,
          11.500739097595215,
          24.2272891998291,
          6.8522796630859375,
          -13.182062149047852,
          -23.44985008239746,
          2.8516786098480225,
          5.586792469024658,
          -29.027299880981445,
          25.75881004333496,
          -20.43247413635254,
          27.148468017578125,
          -12.572957038879395,
          13.90992259979248,
          21.84640884399414,
          -4.036914348602295,
          7.633086681365967,
          -13.580419540405273,
          12.392845153808594
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"dfa79433-0566-4376-9d74-31f5ac0ebecb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"dfa79433-0566-4376-9d74-31f5ac0ebecb\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'dfa79433-0566-4376-9d74-31f5ac0ebecb',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"Acid house\", \"African music\", \"Alternative rock\", \"Ambient\", \"Blues\", \"Bossa Nova\", \"Chill-out\", \"Classical Music\", \"Coldwave\", \"Country\", \"Dance music\", \"Dance-pop\", \"Deep house\", \"Disco\", \"Dream Pop\", \"Dub\", \"Electro swing\", \"Electronic rock\", \"Electronica\", \"Electropop\", \"Experimental\", \"Experimental Jazz\", \"Experimental rock\", \"Film Music\", \"French house\", \"Funk\", \"Future house\", \"Garage rock\", \"Grime\", \"Hard rock\", \"Hip hop\", \"House music\", \"Indie folk\", \"Indie pop\", \"Indie rock\", \"Instrumental\", \"International Pop\", \"Latin music\", \"Lo-Fi\", \"Metal\", \"Minimal\", \"Modern Jazz\", \"New wave\", \"Noise rock\", \"Nouvelle Sc\\u00e8ne\", \"Nu-disco\", \"Pop rock\", \"Pop soul\", \"Post-punk\", \"Post-rock\", \"Progressive pop\", \"Progressive rock\", \"Psychedelic pop\", \"Psychedelic rock\", \"Punk\", \"R&B\", \"Rap\", \"Rap fran\\u00e7ais\", \"Reggae\", \"Rock and roll\", \"Samba\", \"Singer-songwriter\", \"Soul\", \"Surf rock\", \"Synthpop\", \"Synthwave\", \"Techno\", \"Traditional Music\", \"Trap\", \"Trip hop\", \"Vari\\u00e9t\\u00e9 Fran\\u00e7aise\"], \"type\": \"scatter\", \"x\": [-14.74853229522705, 17.682838439941406, 4.965287208557129, 7.3318071365356445, 17.349782943725586, -29.038164138793945, 10.018109321594238, -22.190324783325195, 0.00833328440785408, -34.290462493896484, -18.661819458007812, -44.31754684448242, 0.15159042179584503, 36.18705749511719, 9.975814819335938, 23.626827239990234, 39.53641128540039, -19.76634979248047, -4.820689678192139, -1.1509919166564941, 2.710825204849243, 16.15608024597168, -17.016632080078125, 1.8929799795150757, 19.242267608642578, 17.734994888305664, -3.7871947288513184, -9.638981819152832, 30.49393081665039, -25.717613220214844, -33.36548614501953, 25.483789443969727, -6.18173360824585, 4.014444828033447, -7.202876567840576, 7.121709823608398, 11.735377311706543, 23.940202713012695, -21.50227165222168, -29.63962745666504, 6.372770309448242, -29.894298553466797, -3.6615445613861084, -12.36172866821289, -60.917972564697266, -13.409652709960938, -4.567030906677246, 4.707525730133057, 11.31328010559082, -10.173579216003418, 3.926175355911255, -25.388864517211914, -12.126287460327148, 10.580570220947266, -19.25565528869629, -4.833492755889893, 31.022502899169922, -11.589822769165039, -11.433586120605469, 0.6280190944671631, 17.92748260498047, 17.750226974487305, 19.75979995727539, -29.78652572631836, 0.20626206696033478, -17.477617263793945, 31.65266990661621, 30.424257278442383, -14.670209884643555, -7.367153644561768, -3.008390426635742], \"xaxis\": \"x\", \"y\": [-15.31822395324707, 6.2620720863342285, 9.915458679199219, 4.76536750793457, -6.688090801239014, -15.853318214416504, -5.662812232971191, 7.831477165222168, -38.06044387817383, 13.964759826660156, 1.1890119314193726, -3.344533681869507, 33.35895538330078, 8.175802230834961, -14.344127655029297, 16.002904891967773, -9.735025405883789, -6.852057456970215, -9.087818145751953, -2.943114757537842, -18.617233276367188, 12.681920051574707, -29.953325271606445, 15.142009735107422, -0.44492805004119873, -13.501596450805664, -25.408620834350586, 9.681718826293945, -23.115806579589844, 15.131693840026855, -5.149643898010254, 3.347667694091797, 27.612110137939453, -8.223662376403809, -3.3968605995178223, 27.29782485961914, -0.145525261759758, -10.040058135986328, -14.331521987915039, -27.81319808959961, -26.564224243164062, 2.960843324661255, 20.7110652923584, 22.06574249267578, -2.420520782470703, -2.6612446308135986, 1.5138969421386719, -0.7790586352348328, 19.740093231201172, 15.165520668029785, 21.007604598999023, -5.885558128356934, -8.383081436157227, 11.500739097595215, 24.2272891998291, 6.8522796630859375, -13.182062149047852, -23.44985008239746, 2.8516786098480225, 5.586792469024658, -29.027299880981445, 25.75881004333496, -20.43247413635254, 27.148468017578125, -12.572957038879395, 13.90992259979248, 21.84640884399414, -4.036914348602295, 7.633086681365967, -13.580419540405273, 12.392845153808594], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('dfa79433-0566-4376-9d74-31f5ac0ebecb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Band embeddings and perform 2D TSNE\n",
    "\n",
    "b_em = model.get_layer('Band-Embedding')\n",
    "b_em_weights = b_em.get_weights()[0]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(b_em_weights)\n",
    "\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1], text=[col[:-5] for col in band_data.columns])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influencer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 70 nearest neighbors...\n",
      "[t-SNE] Indexed 71 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 71 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 71 / 71\n",
      "[t-SNE] Mean sigma: 0.557261\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 49.742256\n",
      "[t-SNE] KL divergence after 300 iterations: 0.771352\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "x=%{x}<br>y=%{y}<br>text=%{text}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "showlegend": false,
         "text": [
          "Acid house",
          "African music",
          "Alternative rock",
          "Ambient",
          "Blues",
          "Bossa Nova",
          "Chill-out",
          "Classical Music",
          "Coldwave",
          "Country",
          "Dance music",
          "Dance-pop",
          "Deep house",
          "Disco",
          "Dream Pop",
          "Dub",
          "Electro swing",
          "Electronic rock",
          "Electronica",
          "Electropop",
          "Experimental",
          "Experimental Jazz",
          "Experimental rock",
          "Film Music",
          "French house",
          "Funk",
          "Future house",
          "Garage rock",
          "Grime",
          "Hard rock",
          "Hip hop",
          "House music",
          "Indie folk",
          "Indie pop",
          "Indie rock",
          "Instrumental",
          "International Pop",
          "Latin music",
          "Lo-Fi",
          "Metal",
          "Minimal",
          "Modern Jazz",
          "New wave",
          "Noise rock",
          "Nouvelle Scène",
          "Nu-disco",
          "Pop rock",
          "Pop soul",
          "Post-punk",
          "Post-rock",
          "Progressive pop",
          "Progressive rock",
          "Psychedelic pop",
          "Psychedelic rock",
          "Punk",
          "R&B",
          "Rap",
          "Rap français",
          "Reggae",
          "Rock and roll",
          "Samba",
          "Singer-songwriter",
          "Soul",
          "Surf rock",
          "Synthpop",
          "Synthwave",
          "Techno",
          "Traditional Music",
          "Trap",
          "Trip hop",
          "Variété Française"
         ],
         "type": "scatter",
         "x": [
          -11.994706153869629,
          -7.846391677856445,
          -4.209227085113525,
          6.496922016143799,
          -22.157690048217773,
          24.244422912597656,
          -16.45694923400879,
          -2.2766401767730713,
          2.823263645172119,
          -13.441282272338867,
          4.404933929443359,
          -5.6600728034973145,
          23.235668182373047,
          -9.602792739868164,
          16.422203063964844,
          -30.315935134887695,
          7.551563739776611,
          -3.219318389892578,
          -20.94646644592285,
          5.7701287269592285,
          -10.393070220947266,
          -33.527870178222656,
          17.60736846923828,
          2.0617222785949707,
          11.636609077453613,
          10.963153839111328,
          -30.313066482543945,
          -0.685817301273346,
          25.106658935546875,
          -0.18570375442504883,
          15.026880264282227,
          -15.609970092773438,
          -14.055931091308594,
          -8.59955883026123,
          -3.69560170173645,
          8.354347229003906,
          5.963544845581055,
          7.23886251449585,
          -11.321246147155762,
          -22.108427047729492,
          18.018701553344727,
          8.657730102539062,
          -9.420511245727539,
          19.137006759643555,
          8.259095191955566,
          -4.015529632568359,
          -3.3086564540863037,
          -3.0810725688934326,
          11.111361503601074,
          0.9401600360870361,
          -6.722184658050537,
          -1.4653122425079346,
          1.3853414058685303,
          -15.316739082336426,
          -23.09021759033203,
          -8.211153984069824,
          -22.308624267578125,
          -20.66350746154785,
          5.882843494415283,
          13.362518310546875,
          -29.00364875793457,
          3.0062172412872314,
          -7.503971099853516,
          -30.49146270751953,
          -2.059781074523926,
          18.700345993041992,
          -22.43702507019043,
          -16.761260986328125,
          0.1410301774740219,
          2.229163885116577,
          -7.455220699310303
         ],
         "xaxis": "x",
         "y": [
          7.993433952331543,
          11.827929496765137,
          -10.838289260864258,
          -7.616008281707764,
          -18.18345069885254,
          13.794590950012207,
          -2.9907052516937256,
          14.632115364074707,
          -29.323699951171875,
          -21.821178436279297,
          -1.923979640007019,
          -31.799942016601562,
          -0.9188554883003235,
          25.91033363342285,
          -0.5351433753967285,
          -18.551883697509766,
          28.20684814453125,
          20.35953712463379,
          3.8041272163391113,
          5.74100399017334,
          17.013885498046875,
          -7.945127010345459,
          -12.70109748840332,
          -7.136123180389404,
          4.148285388946533,
          -12.316194534301758,
          -6.165547847747803,
          6.201272964477539,
          -16.15507698059082,
          25.834733963012695,
          -20.43811798095703,
          3.3125498294830322,
          -9.161855697631836,
          -15.20075511932373,
          2.040933847427368,
          -0.13127964735031128,
          -13.176819801330566,
          -23.966873168945312,
          -3.361006736755371,
          -4.983846187591553,
          -7.103803634643555,
          18.36688232421875,
          -9.99388599395752,
          -25.48716926574707,
          -18.01058578491211,
          8.367420196533203,
          -2.6207830905914307,
          -15.424420356750488,
          -4.192771911621094,
          -11.860674858093262,
          -6.056524753570557,
          -20.811277389526367,
          11.277425765991211,
          -15.255793571472168,
          9.619694709777832,
          4.1261701583862305,
          -11.517112731933594,
          16.486713409423828,
          12.308030128479004,
          9.646993637084961,
          2.5311191082000732,
          -17.07302474975586,
          -23.931116104125977,
          13.837320327758789,
          -6.589401721954346,
          5.748171806335449,
          23.21009063720703,
          11.700106620788574,
          -0.3638204038143158,
          3.2213873863220215,
          -0.5258198976516724
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"ac833a0c-5515-44c8-816a-012cc757487e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"ac833a0c-5515-44c8-816a-012cc757487e\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'ac833a0c-5515-44c8-816a-012cc757487e',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"Acid house\", \"African music\", \"Alternative rock\", \"Ambient\", \"Blues\", \"Bossa Nova\", \"Chill-out\", \"Classical Music\", \"Coldwave\", \"Country\", \"Dance music\", \"Dance-pop\", \"Deep house\", \"Disco\", \"Dream Pop\", \"Dub\", \"Electro swing\", \"Electronic rock\", \"Electronica\", \"Electropop\", \"Experimental\", \"Experimental Jazz\", \"Experimental rock\", \"Film Music\", \"French house\", \"Funk\", \"Future house\", \"Garage rock\", \"Grime\", \"Hard rock\", \"Hip hop\", \"House music\", \"Indie folk\", \"Indie pop\", \"Indie rock\", \"Instrumental\", \"International Pop\", \"Latin music\", \"Lo-Fi\", \"Metal\", \"Minimal\", \"Modern Jazz\", \"New wave\", \"Noise rock\", \"Nouvelle Sc\\u00e8ne\", \"Nu-disco\", \"Pop rock\", \"Pop soul\", \"Post-punk\", \"Post-rock\", \"Progressive pop\", \"Progressive rock\", \"Psychedelic pop\", \"Psychedelic rock\", \"Punk\", \"R&B\", \"Rap\", \"Rap fran\\u00e7ais\", \"Reggae\", \"Rock and roll\", \"Samba\", \"Singer-songwriter\", \"Soul\", \"Surf rock\", \"Synthpop\", \"Synthwave\", \"Techno\", \"Traditional Music\", \"Trap\", \"Trip hop\", \"Vari\\u00e9t\\u00e9 Fran\\u00e7aise\"], \"type\": \"scatter\", \"x\": [-11.994706153869629, -7.846391677856445, -4.209227085113525, 6.496922016143799, -22.157690048217773, 24.244422912597656, -16.45694923400879, -2.2766401767730713, 2.823263645172119, -13.441282272338867, 4.404933929443359, -5.6600728034973145, 23.235668182373047, -9.602792739868164, 16.422203063964844, -30.315935134887695, 7.551563739776611, -3.219318389892578, -20.94646644592285, 5.7701287269592285, -10.393070220947266, -33.527870178222656, 17.60736846923828, 2.0617222785949707, 11.636609077453613, 10.963153839111328, -30.313066482543945, -0.685817301273346, 25.106658935546875, -0.18570375442504883, 15.026880264282227, -15.609970092773438, -14.055931091308594, -8.59955883026123, -3.69560170173645, 8.354347229003906, 5.963544845581055, 7.23886251449585, -11.321246147155762, -22.108427047729492, 18.018701553344727, 8.657730102539062, -9.420511245727539, 19.137006759643555, 8.259095191955566, -4.015529632568359, -3.3086564540863037, -3.0810725688934326, 11.111361503601074, 0.9401600360870361, -6.722184658050537, -1.4653122425079346, 1.3853414058685303, -15.316739082336426, -23.09021759033203, -8.211153984069824, -22.308624267578125, -20.66350746154785, 5.882843494415283, 13.362518310546875, -29.00364875793457, 3.0062172412872314, -7.503971099853516, -30.49146270751953, -2.059781074523926, 18.700345993041992, -22.43702507019043, -16.761260986328125, 0.1410301774740219, 2.229163885116577, -7.455220699310303], \"xaxis\": \"x\", \"y\": [7.993433952331543, 11.827929496765137, -10.838289260864258, -7.616008281707764, -18.18345069885254, 13.794590950012207, -2.9907052516937256, 14.632115364074707, -29.323699951171875, -21.821178436279297, -1.923979640007019, -31.799942016601562, -0.9188554883003235, 25.91033363342285, -0.5351433753967285, -18.551883697509766, 28.20684814453125, 20.35953712463379, 3.8041272163391113, 5.74100399017334, 17.013885498046875, -7.945127010345459, -12.70109748840332, -7.136123180389404, 4.148285388946533, -12.316194534301758, -6.165547847747803, 6.201272964477539, -16.15507698059082, 25.834733963012695, -20.43811798095703, 3.3125498294830322, -9.161855697631836, -15.20075511932373, 2.040933847427368, -0.13127964735031128, -13.176819801330566, -23.966873168945312, -3.361006736755371, -4.983846187591553, -7.103803634643555, 18.36688232421875, -9.99388599395752, -25.48716926574707, -18.01058578491211, 8.367420196533203, -2.6207830905914307, -15.424420356750488, -4.192771911621094, -11.860674858093262, -6.056524753570557, -20.811277389526367, 11.277425765991211, -15.255793571472168, 9.619694709777832, 4.1261701583862305, -11.517112731933594, 16.486713409423828, 12.308030128479004, 9.646993637084961, 2.5311191082000732, -17.07302474975586, -23.931116104125977, 13.837320327758789, -6.589401721954346, 5.748171806335449, 23.21009063720703, 11.700106620788574, -0.3638204038143158, 3.2213873863220215, -0.5258198976516724], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ac833a0c-5515-44c8-816a-012cc757487e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Influencer embeddings and perform 2D TSNE\n",
    "\n",
    "i_em = model.get_layer('Influencer-Embedding')\n",
    "i_em_weights = i_em.get_weights()[0]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(b_em_weights)\n",
    "\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1], text=[col[:-11] for col in influencer_data.columns])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE is not very stable on this example because we lack data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with cross validation and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60267/60267 [==============================] - 2s 29us/step - loss: 0.1450 - val_loss: 0.1186\n",
      "Epoch 2/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.1123 - val_loss: 0.1083\n",
      "Epoch 3/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.1053 - val_loss: 0.1034\n",
      "Epoch 4/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.1017 - val_loss: 0.1033\n",
      "Epoch 5/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0997 - val_loss: 0.1002\n",
      "Epoch 6/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0979 - val_loss: 0.0996\n",
      "Epoch 7/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0973 - val_loss: 0.0992\n",
      "Epoch 8/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0964 - val_loss: 0.0988\n",
      "Epoch 9/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0958 - val_loss: 0.0974\n",
      "Epoch 10/100\n",
      "60267/60267 [==============================] - 1s 25us/step - loss: 0.0956 - val_loss: 0.1007\n",
      "Epoch 11/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0950 - val_loss: 0.0976\n",
      "Epoch 12/100\n",
      "60267/60267 [==============================] - 2s 26us/step - loss: 0.0949 - val_loss: 0.0989\n",
      "Epoch 13/100\n",
      "60267/60267 [==============================] - 2s 26us/step - loss: 0.0945 - val_loss: 0.0971\n",
      "Epoch 14/100\n",
      "60267/60267 [==============================] - 2s 25us/step - loss: 0.0944 - val_loss: 0.0972\n",
      "Epoch 15/100\n",
      "60267/60267 [==============================] - 2s 25us/step - loss: 0.0942 - val_loss: 0.0981\n",
      "Epoch 16/100\n",
      "60267/60267 [==============================] - 1s 24us/step - loss: 0.0941 - val_loss: 0.1028\n",
      "Epoch 17/100\n",
      "60267/60267 [==============================] - 2s 26us/step - loss: 0.0940 - val_loss: 0.0980\n",
      "Epoch 18/100\n",
      "60267/60267 [==============================] - 2s 26us/step - loss: 0.0940 - val_loss: 0.0995\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 2s 29us/step - loss: 0.1456 - val_loss: 0.1231\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 1s 24us/step - loss: 0.1134 - val_loss: 0.1121\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 1s 25us/step - loss: 0.1062 - val_loss: 0.1080\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 1s 25us/step - loss: 0.1027 - val_loss: 0.1040\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1003 - val_loss: 0.1053\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0993 - val_loss: 0.1026\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0981 - val_loss: 0.1012\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 1s 25us/step - loss: 0.0974 - val_loss: 0.1029\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0969 - val_loss: 0.1014\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 29us/step - loss: 0.0965 - val_loss: 0.1005\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0961 - val_loss: 0.1002\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0957 - val_loss: 0.1037\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 1s 25us/step - loss: 0.0957 - val_loss: 0.1012\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0955 - val_loss: 0.1021\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0953 - val_loss: 0.1034\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0950 - val_loss: 0.1005\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00016: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 2s 31us/step - loss: 0.1429 - val_loss: 0.1168\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1112 - val_loss: 0.1078\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.1050 - val_loss: 0.1031\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1016 - val_loss: 0.1006\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0999 - val_loss: 0.1000\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0985 - val_loss: 0.0991\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0978 - val_loss: 0.0984\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0971 - val_loss: 0.0986\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0969 - val_loss: 0.0992\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0963 - val_loss: 0.0997\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0962 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0959 - val_loss: 0.0986\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0957 - val_loss: 0.0982\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0955 - val_loss: 0.0992\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0953 - val_loss: 0.0977\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0953 - val_loss: 0.0978\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0950 - val_loss: 0.0992\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0950 - val_loss: 0.0998\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 2s 28us/step - loss: 0.0949 - val_loss: 0.0986\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0946 - val_loss: 0.0987\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 2s 33us/step - loss: 0.1449 - val_loss: 0.1180\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1138 - val_loss: 0.1073\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1063 - val_loss: 0.1031\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1028 - val_loss: 0.1019\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1008 - val_loss: 0.1016\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0991 - val_loss: 0.0998\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0981 - val_loss: 0.0995\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0974 - val_loss: 0.0993\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0968 - val_loss: 0.0987\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0961 - val_loss: 0.0996\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0961 - val_loss: 0.0998\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0955 - val_loss: 0.0989\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0950 - val_loss: 0.0992\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0950 - val_loss: 0.0987\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0947 - val_loss: 0.0989\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0945 - val_loss: 0.1034\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0943 - val_loss: 0.0994\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0943 - val_loss: 0.0996\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.0941 - val_loss: 0.0989\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00019: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 2s 31us/step - loss: 0.1447 - val_loss: 0.1197\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 25us/step - loss: 0.1159 - val_loss: 0.1109\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1084 - val_loss: 0.1058\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.1038 - val_loss: 0.1032\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.1012 - val_loss: 0.1028\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0996 - val_loss: 0.1005\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0986 - val_loss: 0.1001\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0977 - val_loss: 0.0999\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0971 - val_loss: 0.1007\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0968 - val_loss: 0.0986\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0963 - val_loss: 0.1005\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0960 - val_loss: 0.1002\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0957 - val_loss: 0.0998\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 26us/step - loss: 0.0955 - val_loss: 0.1012\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 27us/step - loss: 0.0951 - val_loss: 0.0998\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model, band_embedding_model, influencer_embedding_model = build_Dot_model()\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN score: 0.31624817489734414\n"
     ]
    }
   ],
   "source": [
    "print(f'NN score: {nn_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN_model(\n",
    "    i_emb_dim=16, \n",
    "    b_emb_dim=16, \n",
    "    kind_emb_dim=8, \n",
    "    last_dense=16, \n",
    "    dropout=0.2,\n",
    "    activation='relu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Build simple MLP Neural Network.\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[influencer_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation=activation, name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(\n",
    "        influencer_kind.nunique(), \n",
    "        kind_emb_dim, \n",
    "        name=\"Influencer-Kind-Embedding\"\n",
    "    )(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(name=\"Influencer-Full-Embedding\", axis=-1)(\n",
    "        [influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)]\n",
    "    )\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[band_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation=activation, name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    concat = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    dense = Dense(last_dense, activation=activation, name=\"Dense\")(concat)\n",
    "    \n",
    "    # Dropout\n",
    "    dropout = Dropout(rate=dropout)(dense)\n",
    "    \n",
    "    # Output\n",
    "    output = Dense(1, activation=activation, name=\"Output\")(dropout)\n",
    "    band_embedding_model = Model([influencer_input, band_input, influencer_kind_input], band_embedding)\n",
    "    influencer_embedding_model = Model([influencer_input, band_input, influencer_kind_input],\n",
    "                                       influencer_full_emb)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], output)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model, band_embedding_model, influencer_embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model and visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model, band_embedding_model, influencer_embedding_model = build_NN_model()\n",
    "\n",
    "# Plot architecture\n",
    "plot_model(model, to_file='Dot_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "83706/83706 [==============================] - 3s 35us/step - loss: 0.1216\n",
      "Epoch 2/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.1070\n",
      "Epoch 3/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.1035\n",
      "Epoch 4/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.1013\n",
      "Epoch 5/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.1002\n",
      "Epoch 6/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.0993\n",
      "Epoch 7/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0988\n",
      "Epoch 8/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.0985\n",
      "Epoch 9/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0977\n",
      "Epoch 10/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0974\n",
      "Epoch 11/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0969\n",
      "Epoch 12/20\n",
      "83706/83706 [==============================] - 3s 30us/step - loss: 0.0967\n",
      "Epoch 13/20\n",
      "83706/83706 [==============================] - 2s 30us/step - loss: 0.0964\n",
      "Epoch 14/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0963\n",
      "Epoch 15/20\n",
      "83706/83706 [==============================] - 2s 30us/step - loss: 0.0959\n",
      "Epoch 16/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0961\n",
      "Epoch 17/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0957\n",
      "Epoch 18/20\n",
      "83706/83706 [==============================] - 2s 28us/step - loss: 0.0956\n",
      "Epoch 19/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0956\n",
      "Epoch 20/20\n",
      "83706/83706 [==============================] - 2s 29us/step - loss: 0.0950\n"
     ]
    }
   ],
   "source": [
    "# Fit model on 10 epochs on all data\n",
    "history = model.fit([influencer_data, band_data, influencer_kind], dataset.score, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 70 nearest neighbors...\n",
      "[t-SNE] Indexed 71 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 71 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 71 / 71\n",
      "[t-SNE] Mean sigma: 0.816457\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 53.252708\n",
      "[t-SNE] KL divergence after 300 iterations: 1.046860\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "x=%{x}<br>y=%{y}<br>text=%{text}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "showlegend": false,
         "text": [
          "Acid house",
          "African music",
          "Alternative rock",
          "Ambient",
          "Blues",
          "Bossa Nova",
          "Chill-out",
          "Classical Music",
          "Coldwave",
          "Country",
          "Dance music",
          "Dance-pop",
          "Deep house",
          "Disco",
          "Dream Pop",
          "Dub",
          "Electro swing",
          "Electronic rock",
          "Electronica",
          "Electropop",
          "Experimental",
          "Experimental Jazz",
          "Experimental rock",
          "Film Music",
          "French house",
          "Funk",
          "Future house",
          "Garage rock",
          "Grime",
          "Hard rock",
          "Hip hop",
          "House music",
          "Indie folk",
          "Indie pop",
          "Indie rock",
          "Instrumental",
          "International Pop",
          "Latin music",
          "Lo-Fi",
          "Metal",
          "Minimal",
          "Modern Jazz",
          "New wave",
          "Noise rock",
          "Nouvelle Scène",
          "Nu-disco",
          "Pop rock",
          "Pop soul",
          "Post-punk",
          "Post-rock",
          "Progressive pop",
          "Progressive rock",
          "Psychedelic pop",
          "Psychedelic rock",
          "Punk",
          "R&B",
          "Rap",
          "Rap français",
          "Reggae",
          "Rock and roll",
          "Samba",
          "Singer-songwriter",
          "Soul",
          "Surf rock",
          "Synthpop",
          "Synthwave",
          "Techno",
          "Traditional Music",
          "Trap",
          "Trip hop",
          "Variété Française"
         ],
         "type": "scatter",
         "x": [
          -17.8786563873291,
          -33.36389923095703,
          49.86211013793945,
          14.58238410949707,
          6.459550857543945,
          1.0854032039642334,
          -4.950168132781982,
          7.293919563293457,
          8.833745002746582,
          0.6555386781692505,
          -41.933555603027344,
          58.032386779785156,
          31.20258331298828,
          45.67236328125,
          -4.909320831298828,
          -2.587951183319092,
          -5.567998886108398,
          10.158734321594238,
          -49.48851013183594,
          -10.299095153808594,
          13.6327486038208,
          2.7759504318237305,
          15.33327579498291,
          -49.08639144897461,
          -12.523611068725586,
          35.454219818115234,
          44.67020034790039,
          -0.9992154240608215,
          11.96777057647705,
          69.28282928466797,
          -6.795801639556885,
          -35.456295013427734,
          2.4264233112335205,
          -7.437761306762695,
          32.482444763183594,
          20.171884536743164,
          25.086668014526367,
          33.573516845703125,
          -41.378150939941406,
          20.61737060546875,
          -30.96445655822754,
          5.797175407409668,
          -18.25881576538086,
          15.47928524017334,
          35.41893005371094,
          -27.525760650634766,
          20.791278839111328,
          -0.15702490508556366,
          8.085437774658203,
          -23.283430099487305,
          70.72261810302734,
          -31.38953399658203,
          -22.489727020263672,
          56.211273193359375,
          -28.614383697509766,
          32.966121673583984,
          -39.82394027709961,
          -54.62602996826172,
          -51.09967041015625,
          43.305702209472656,
          26.55386734008789,
          -18.44493293762207,
          -41.2039909362793,
          51.178428649902344,
          38.613243103027344,
          -25.646650314331055,
          24.23430061340332,
          20.426959991455078,
          -33.44738006591797,
          -19.013187408447266,
          -10.182950019836426
         ],
         "xaxis": "x",
         "y": [
          48.702659606933594,
          -38.4396858215332,
          9.249995231628418,
          30.84940528869629,
          63.1279182434082,
          1.6177916526794434,
          54.43686294555664,
          -51.40159225463867,
          45.13105773925781,
          -67.36127471923828,
          -20.162704467773438,
          27.694822311401367,
          23.198041915893555,
          19.326541900634766,
          -40.08881759643555,
          -10.075499534606934,
          10.70183277130127,
          6.235416889190674,
          9.414581298828125,
          -6.097404479980469,
          -15.03817081451416,
          29.399642944335938,
          -2.7920026779174805,
          -52.828304290771484,
          4.131996154785156,
          11.841939926147461,
          -2.582672595977783,
          -104.25975799560547,
          -24.411251068115234,
          -48.64097213745117,
          23.95890998840332,
          -65.31432342529297,
          15.956948280334473,
          38.26644515991211,
          -3.895380973815918,
          42.5750732421875,
          3.8063385486602783,
          -25.436784744262695,
          24.277137756347656,
          -30.00827980041504,
          -16.194520950317383,
          -7.030612945556641,
          22.07282257080078,
          21.39785385131836,
          48.1192512512207,
          0.04736943170428276,
          13.541081428527832,
          -25.11658477783203,
          -36.579490661621094,
          37.489253997802734,
          -10.38044261932373,
          53.837276458740234,
          9.955047607421875,
          -6.7085771560668945,
          25.204374313354492,
          34.770442962646484,
          41.194862365722656,
          29.483821868896484,
          -24.13498306274414,
          -38.44710922241211,
          -39.64754104614258,
          -35.43463134765625,
          -2.732343912124634,
          -24.405841827392578,
          -13.105183601379395,
          -51.57314682006836,
          -13.963448524475098,
          -53.228946685791016,
          13.461779594421387,
          -14.515600204467773,
          -21.714582443237305
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"8ecba1f7-fbed-436f-a2b1-3b6f9369b146\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"8ecba1f7-fbed-436f-a2b1-3b6f9369b146\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '8ecba1f7-fbed-436f-a2b1-3b6f9369b146',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"Acid house\", \"African music\", \"Alternative rock\", \"Ambient\", \"Blues\", \"Bossa Nova\", \"Chill-out\", \"Classical Music\", \"Coldwave\", \"Country\", \"Dance music\", \"Dance-pop\", \"Deep house\", \"Disco\", \"Dream Pop\", \"Dub\", \"Electro swing\", \"Electronic rock\", \"Electronica\", \"Electropop\", \"Experimental\", \"Experimental Jazz\", \"Experimental rock\", \"Film Music\", \"French house\", \"Funk\", \"Future house\", \"Garage rock\", \"Grime\", \"Hard rock\", \"Hip hop\", \"House music\", \"Indie folk\", \"Indie pop\", \"Indie rock\", \"Instrumental\", \"International Pop\", \"Latin music\", \"Lo-Fi\", \"Metal\", \"Minimal\", \"Modern Jazz\", \"New wave\", \"Noise rock\", \"Nouvelle Sc\\u00e8ne\", \"Nu-disco\", \"Pop rock\", \"Pop soul\", \"Post-punk\", \"Post-rock\", \"Progressive pop\", \"Progressive rock\", \"Psychedelic pop\", \"Psychedelic rock\", \"Punk\", \"R&B\", \"Rap\", \"Rap fran\\u00e7ais\", \"Reggae\", \"Rock and roll\", \"Samba\", \"Singer-songwriter\", \"Soul\", \"Surf rock\", \"Synthpop\", \"Synthwave\", \"Techno\", \"Traditional Music\", \"Trap\", \"Trip hop\", \"Vari\\u00e9t\\u00e9 Fran\\u00e7aise\"], \"type\": \"scatter\", \"x\": [-17.8786563873291, -33.36389923095703, 49.86211013793945, 14.58238410949707, 6.459550857543945, 1.0854032039642334, -4.950168132781982, 7.293919563293457, 8.833745002746582, 0.6555386781692505, -41.933555603027344, 58.032386779785156, 31.20258331298828, 45.67236328125, -4.909320831298828, -2.587951183319092, -5.567998886108398, 10.158734321594238, -49.48851013183594, -10.299095153808594, 13.6327486038208, 2.7759504318237305, 15.33327579498291, -49.08639144897461, -12.523611068725586, 35.454219818115234, 44.67020034790039, -0.9992154240608215, 11.96777057647705, 69.28282928466797, -6.795801639556885, -35.456295013427734, 2.4264233112335205, -7.437761306762695, 32.482444763183594, 20.171884536743164, 25.086668014526367, 33.573516845703125, -41.378150939941406, 20.61737060546875, -30.96445655822754, 5.797175407409668, -18.25881576538086, 15.47928524017334, 35.41893005371094, -27.525760650634766, 20.791278839111328, -0.15702490508556366, 8.085437774658203, -23.283430099487305, 70.72261810302734, -31.38953399658203, -22.489727020263672, 56.211273193359375, -28.614383697509766, 32.966121673583984, -39.82394027709961, -54.62602996826172, -51.09967041015625, 43.305702209472656, 26.55386734008789, -18.44493293762207, -41.2039909362793, 51.178428649902344, 38.613243103027344, -25.646650314331055, 24.23430061340332, 20.426959991455078, -33.44738006591797, -19.013187408447266, -10.182950019836426], \"xaxis\": \"x\", \"y\": [48.702659606933594, -38.4396858215332, 9.249995231628418, 30.84940528869629, 63.1279182434082, 1.6177916526794434, 54.43686294555664, -51.40159225463867, 45.13105773925781, -67.36127471923828, -20.162704467773438, 27.694822311401367, 23.198041915893555, 19.326541900634766, -40.08881759643555, -10.075499534606934, 10.70183277130127, 6.235416889190674, 9.414581298828125, -6.097404479980469, -15.03817081451416, 29.399642944335938, -2.7920026779174805, -52.828304290771484, 4.131996154785156, 11.841939926147461, -2.582672595977783, -104.25975799560547, -24.411251068115234, -48.64097213745117, 23.95890998840332, -65.31432342529297, 15.956948280334473, 38.26644515991211, -3.895380973815918, 42.5750732421875, 3.8063385486602783, -25.436784744262695, 24.277137756347656, -30.00827980041504, -16.194520950317383, -7.030612945556641, 22.07282257080078, 21.39785385131836, 48.1192512512207, 0.04736943170428276, 13.541081428527832, -25.11658477783203, -36.579490661621094, 37.489253997802734, -10.38044261932373, 53.837276458740234, 9.955047607421875, -6.7085771560668945, 25.204374313354492, 34.770442962646484, 41.194862365722656, 29.483821868896484, -24.13498306274414, -38.44710922241211, -39.64754104614258, -35.43463134765625, -2.732343912124634, -24.405841827392578, -13.105183601379395, -51.57314682006836, -13.963448524475098, -53.228946685791016, 13.461779594421387, -14.515600204467773, -21.714582443237305], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8ecba1f7-fbed-436f-a2b1-3b6f9369b146');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Band embeddings and perform 2D TSNE\n",
    "\n",
    "b_em = model.get_layer('Band-Embedding')\n",
    "b_em_weights = b_em.get_weights()[0]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(b_em_weights)\n",
    "\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1], text=[col[:-5] for col in band_data.columns])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influencer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 70 nearest neighbors...\n",
      "[t-SNE] Indexed 71 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 71 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 71 / 71\n",
      "[t-SNE] Mean sigma: 0.814674\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 55.328049\n",
      "[t-SNE] KL divergence after 300 iterations: 0.878721\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "x=%{x}<br>y=%{y}<br>text=%{text}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "showlegend": false,
         "text": [
          "Acid house",
          "African music",
          "Alternative rock",
          "Ambient",
          "Blues",
          "Bossa Nova",
          "Chill-out",
          "Classical Music",
          "Coldwave",
          "Country",
          "Dance music",
          "Dance-pop",
          "Deep house",
          "Disco",
          "Dream Pop",
          "Dub",
          "Electro swing",
          "Electronic rock",
          "Electronica",
          "Electropop",
          "Experimental",
          "Experimental Jazz",
          "Experimental rock",
          "Film Music",
          "French house",
          "Funk",
          "Future house",
          "Garage rock",
          "Grime",
          "Hard rock",
          "Hip hop",
          "House music",
          "Indie folk",
          "Indie pop",
          "Indie rock",
          "Instrumental",
          "International Pop",
          "Latin music",
          "Lo-Fi",
          "Metal",
          "Minimal",
          "Modern Jazz",
          "New wave",
          "Noise rock",
          "Nouvelle Scène",
          "Nu-disco",
          "Pop rock",
          "Pop soul",
          "Post-punk",
          "Post-rock",
          "Progressive pop",
          "Progressive rock",
          "Psychedelic pop",
          "Psychedelic rock",
          "Punk",
          "R&B",
          "Rap",
          "Rap français",
          "Reggae",
          "Rock and roll",
          "Samba",
          "Singer-songwriter",
          "Soul",
          "Surf rock",
          "Synthpop",
          "Synthwave",
          "Techno",
          "Traditional Music",
          "Trap",
          "Trip hop",
          "Variété Française"
         ],
         "type": "scatter",
         "x": [
          -24.303485870361328,
          -6.769148826599121,
          -2.7733047008514404,
          14.824728965759277,
          14.05582332611084,
          -0.19109517335891724,
          8.68883991241455,
          -17.744657516479492,
          -5.043976306915283,
          6.619360446929932,
          13.604475975036621,
          -16.826610565185547,
          -7.116899490356445,
          -9.584464073181152,
          7.194169044494629,
          -1.4054839611053467,
          21.279827117919922,
          -15.824361801147461,
          19.375286102294922,
          6.443842887878418,
          -11.359892845153809,
          -8.338284492492676,
          -0.43075674772262573,
          -12.454507827758789,
          7.748904705047607,
          -11.092864990234375,
          -20.30462074279785,
          20.6973934173584,
          -24.880962371826172,
          20.907855987548828,
          6.043399810791016,
          -5.142464637756348,
          11.361968994140625,
          3.1593565940856934,
          1.6778743267059326,
          13.03785228729248,
          22.48297691345215,
          -34.03528594970703,
          -14.60831356048584,
          -21.576282501220703,
          17.08256721496582,
          30.256162643432617,
          0.8012319207191467,
          4.185439586639404,
          -11.443459510803223,
          11.402785301208496,
          2.336573839187622,
          -1.9404033422470093,
          22.819093704223633,
          -27.515050888061523,
          0.2757880389690399,
          -23.089523315429688,
          -18.265701293945312,
          -0.32375478744506836,
          13.394793510437012,
          1.3273078203201294,
          -15.343259811401367,
          -12.747917175292969,
          7.622339725494385,
          25.15884780883789,
          -11.716358184814453,
          5.156815528869629,
          -1.3179450035095215,
          25.959136962890625,
          31.709308624267578,
          3.4515576362609863,
          14.090536117553711,
          -9.361162185668945,
          -6.216915130615234,
          -4.196885108947754,
          -22.55279541015625
         ],
         "xaxis": "x",
         "y": [
          22.970653533935547,
          11.835529327392578,
          -13.676787376403809,
          -16.307228088378906,
          15.825593948364258,
          -31.139867782592773,
          -16.833683013916016,
          13.235419273376465,
          5.833634376525879,
          -37.29185104370117,
          -27.212900161743164,
          2.481254816055298,
          23.351884841918945,
          -29.540056228637695,
          -3.996244430541992,
          -19.116405487060547,
          -19.76857566833496,
          -7.989322185516357,
          9.388345718383789,
          8.631169319152832,
          2.9771320819854736,
          -18.11887550354004,
          9.636456489562988,
          25.3284969329834,
          3.265533685684204,
          7.937710762023926,
          -9.886138916015625,
          16.941993713378906,
          9.307612419128418,
          1.0804413557052612,
          -10.227533340454102,
          -4.390488624572754,
          -9.448602676391602,
          -6.668887615203857,
          21.477872848510742,
          8.05156421661377,
          -28.465604782104492,
          3.391342878341675,
          -15.04030704498291,
          -20.462539672851562,
          -8.527984619140625,
          -4.222766876220703,
          4.636249542236328,
          0.042981088161468506,
          -8.314321517944336,
          25.839229583740234,
          -13.260496139526367,
          -24.44615364074707,
          -4.603443622589111,
          -7.894905090332031,
          15.016274452209473,
          -0.6966220140457153,
          7.19474458694458,
          -1.7386109828948975,
          -4.176100730895996,
          30.720138549804688,
          -2.494774341583252,
          -23.88330841064453,
          14.575662612915039,
          -12.567403793334961,
          16.971214294433594,
          -23.962326049804688,
          -7.100096225738525,
          9.976683616638184,
          6.58491849899292,
          -18.83285903930664,
          1.1773375272750854,
          -1.487067699432373,
          -9.451987266540527,
          0.9638587832450867,
          -31.266624450683594
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"14475303-4eb7-4b7f-b50c-796f6b5e85e3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"14475303-4eb7-4b7f-b50c-796f6b5e85e3\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '14475303-4eb7-4b7f-b50c-796f6b5e85e3',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"Acid house\", \"African music\", \"Alternative rock\", \"Ambient\", \"Blues\", \"Bossa Nova\", \"Chill-out\", \"Classical Music\", \"Coldwave\", \"Country\", \"Dance music\", \"Dance-pop\", \"Deep house\", \"Disco\", \"Dream Pop\", \"Dub\", \"Electro swing\", \"Electronic rock\", \"Electronica\", \"Electropop\", \"Experimental\", \"Experimental Jazz\", \"Experimental rock\", \"Film Music\", \"French house\", \"Funk\", \"Future house\", \"Garage rock\", \"Grime\", \"Hard rock\", \"Hip hop\", \"House music\", \"Indie folk\", \"Indie pop\", \"Indie rock\", \"Instrumental\", \"International Pop\", \"Latin music\", \"Lo-Fi\", \"Metal\", \"Minimal\", \"Modern Jazz\", \"New wave\", \"Noise rock\", \"Nouvelle Sc\\u00e8ne\", \"Nu-disco\", \"Pop rock\", \"Pop soul\", \"Post-punk\", \"Post-rock\", \"Progressive pop\", \"Progressive rock\", \"Psychedelic pop\", \"Psychedelic rock\", \"Punk\", \"R&B\", \"Rap\", \"Rap fran\\u00e7ais\", \"Reggae\", \"Rock and roll\", \"Samba\", \"Singer-songwriter\", \"Soul\", \"Surf rock\", \"Synthpop\", \"Synthwave\", \"Techno\", \"Traditional Music\", \"Trap\", \"Trip hop\", \"Vari\\u00e9t\\u00e9 Fran\\u00e7aise\"], \"type\": \"scatter\", \"x\": [-24.303485870361328, -6.769148826599121, -2.7733047008514404, 14.824728965759277, 14.05582332611084, -0.19109517335891724, 8.68883991241455, -17.744657516479492, -5.043976306915283, 6.619360446929932, 13.604475975036621, -16.826610565185547, -7.116899490356445, -9.584464073181152, 7.194169044494629, -1.4054839611053467, 21.279827117919922, -15.824361801147461, 19.375286102294922, 6.443842887878418, -11.359892845153809, -8.338284492492676, -0.43075674772262573, -12.454507827758789, 7.748904705047607, -11.092864990234375, -20.30462074279785, 20.6973934173584, -24.880962371826172, 20.907855987548828, 6.043399810791016, -5.142464637756348, 11.361968994140625, 3.1593565940856934, 1.6778743267059326, 13.03785228729248, 22.48297691345215, -34.03528594970703, -14.60831356048584, -21.576282501220703, 17.08256721496582, 30.256162643432617, 0.8012319207191467, 4.185439586639404, -11.443459510803223, 11.402785301208496, 2.336573839187622, -1.9404033422470093, 22.819093704223633, -27.515050888061523, 0.2757880389690399, -23.089523315429688, -18.265701293945312, -0.32375478744506836, 13.394793510437012, 1.3273078203201294, -15.343259811401367, -12.747917175292969, 7.622339725494385, 25.15884780883789, -11.716358184814453, 5.156815528869629, -1.3179450035095215, 25.959136962890625, 31.709308624267578, 3.4515576362609863, 14.090536117553711, -9.361162185668945, -6.216915130615234, -4.196885108947754, -22.55279541015625], \"xaxis\": \"x\", \"y\": [22.970653533935547, 11.835529327392578, -13.676787376403809, -16.307228088378906, 15.825593948364258, -31.139867782592773, -16.833683013916016, 13.235419273376465, 5.833634376525879, -37.29185104370117, -27.212900161743164, 2.481254816055298, 23.351884841918945, -29.540056228637695, -3.996244430541992, -19.116405487060547, -19.76857566833496, -7.989322185516357, 9.388345718383789, 8.631169319152832, 2.9771320819854736, -18.11887550354004, 9.636456489562988, 25.3284969329834, 3.265533685684204, 7.937710762023926, -9.886138916015625, 16.941993713378906, 9.307612419128418, 1.0804413557052612, -10.227533340454102, -4.390488624572754, -9.448602676391602, -6.668887615203857, 21.477872848510742, 8.05156421661377, -28.465604782104492, 3.391342878341675, -15.04030704498291, -20.462539672851562, -8.527984619140625, -4.222766876220703, 4.636249542236328, 0.042981088161468506, -8.314321517944336, 25.839229583740234, -13.260496139526367, -24.44615364074707, -4.603443622589111, -7.894905090332031, 15.016274452209473, -0.6966220140457153, 7.19474458694458, -1.7386109828948975, -4.176100730895996, 30.720138549804688, -2.494774341583252, -23.88330841064453, 14.575662612915039, -12.567403793334961, 16.971214294433594, -23.962326049804688, -7.100096225738525, 9.976683616638184, 6.58491849899292, -18.83285903930664, 1.1773375272750854, -1.487067699432373, -9.451987266540527, 0.9638587832450867, -31.266624450683594], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('14475303-4eb7-4b7f-b50c-796f6b5e85e3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Influencer embeddings and perform 2D TSNE\n",
    "\n",
    "i_em = model.get_layer('Influencer-Embedding')\n",
    "i_em_weights = i_em.get_weights()[0]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(i_em_weights)\n",
    "\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1], text=[col[:-11] for col in influencer_data.columns])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influencer kind embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 12 nearest neighbors...\n",
      "[t-SNE] Indexed 13 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 13 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 13 / 13\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 57.594818\n",
      "[t-SNE] KL divergence after 300 iterations: 0.396849\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "x=%{x}<br>y=%{y}<br>text=%{text}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "showlegend": false,
         "text": [
          "Booker",
          "Channel",
          "Event",
          "Journalist",
          "Label",
          "Manager",
          "Media",
          "Mentor",
          "Playlist",
          "Publisher",
          "Radio",
          "Springboard",
          "Supervisor"
         ],
         "type": "scatter",
         "x": [
          -22.07392692565918,
          232.82681274414062,
          88.19556427001953,
          25.565711975097656,
          -190.38011169433594,
          17.852758407592773,
          -91.93472290039062,
          -21.154773712158203,
          -149.137939453125,
          -124.82775115966797,
          -286.57220458984375,
          111.25955200195312,
          163.19593811035156
         ],
         "xaxis": "x",
         "y": [
          -76.53588104248047,
          -247.23561096191406,
          145.15396118164062,
          21.541393280029297,
          38.552589416503906,
          -178.01779174804688,
          17.36062240600586,
          120.39138793945312,
          -97.86139678955078,
          160.02798461914062,
          59.03377914428711,
          -69.34599304199219,
          50.63108444213867
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"973621a7-5946-44c9-bc66-68524821e520\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"973621a7-5946-44c9-bc66-68524821e520\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '973621a7-5946-44c9-bc66-68524821e520',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"Booker\", \"Channel\", \"Event\", \"Journalist\", \"Label\", \"Manager\", \"Media\", \"Mentor\", \"Playlist\", \"Publisher\", \"Radio\", \"Springboard\", \"Supervisor\"], \"type\": \"scatter\", \"x\": [-22.07392692565918, 232.82681274414062, 88.19556427001953, 25.565711975097656, -190.38011169433594, 17.852758407592773, -91.93472290039062, -21.154773712158203, -149.137939453125, -124.82775115966797, -286.57220458984375, 111.25955200195312, 163.19593811035156], \"xaxis\": \"x\", \"y\": [-76.53588104248047, -247.23561096191406, 145.15396118164062, 21.541393280029297, 38.552589416503906, -178.01779174804688, 17.36062240600586, 120.39138793945312, -97.86139678955078, 160.02798461914062, 59.03377914428711, -69.34599304199219, 50.63108444213867], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('973621a7-5946-44c9-bc66-68524821e520');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./data/preprocessed/influencer_kind_label_encoder.pickle', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "    \n",
    "ik_em = model.get_layer('Influencer-Kind-Embedding')\n",
    "ik_em_weights = ik_em.get_weights()[0]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(ik_em_weights)\n",
    "\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1], text=list(le.classes_))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60267/60267 [==============================] - 3s 48us/step - loss: 0.1284 - val_loss: 0.1047\n",
      "Epoch 2/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.1056 - val_loss: 0.0990\n",
      "Epoch 3/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.1027 - val_loss: 0.0980\n",
      "Epoch 4/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.1007 - val_loss: 0.0968\n",
      "Epoch 5/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.0999 - val_loss: 0.0955\n",
      "Epoch 6/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.0992 - val_loss: 0.0961\n",
      "Epoch 7/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.0984 - val_loss: 0.0954\n",
      "Epoch 8/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.0979 - val_loss: 0.0951\n",
      "Epoch 9/100\n",
      "60267/60267 [==============================] - 2s 35us/step - loss: 0.0976 - val_loss: 0.0956\n",
      "Epoch 10/100\n",
      "60267/60267 [==============================] - 2s 36us/step - loss: 0.0973 - val_loss: 0.0954\n",
      "Epoch 11/100\n",
      "60267/60267 [==============================] - 2s 38us/step - loss: 0.0964 - val_loss: 0.0948\n",
      "Epoch 12/100\n",
      "60267/60267 [==============================] - 2s 38us/step - loss: 0.0963 - val_loss: 0.0943\n",
      "Epoch 13/100\n",
      "60267/60267 [==============================] - 2s 36us/step - loss: 0.0963 - val_loss: 0.0954\n",
      "Epoch 14/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.0964 - val_loss: 0.0961\n",
      "Epoch 15/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.0959 - val_loss: 0.0938\n",
      "Epoch 16/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.0956 - val_loss: 0.0936\n",
      "Epoch 17/100\n",
      "60267/60267 [==============================] - 2s 34us/step - loss: 0.0954 - val_loss: 0.0939\n",
      "Epoch 18/100\n",
      "60267/60267 [==============================] - 2s 38us/step - loss: 0.0954 - val_loss: 0.0956\n",
      "Epoch 19/100\n",
      "60267/60267 [==============================] - 2s 38us/step - loss: 0.0953 - val_loss: 0.0946\n",
      "Epoch 20/100\n",
      "60267/60267 [==============================] - 2s 37us/step - loss: 0.0953 - val_loss: 0.0940\n",
      "Epoch 21/100\n",
      "60267/60267 [==============================] - 2s 37us/step - loss: 0.0953 - val_loss: 0.0942\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00021: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 3s 52us/step - loss: 0.1279 - val_loss: 0.1085\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.1083 - val_loss: 0.1002\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1047 - val_loss: 0.0982\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1033 - val_loss: 0.1003\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1023 - val_loss: 0.0978\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1015 - val_loss: 0.0975\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1004 - val_loss: 0.0968\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.1000 - val_loss: 0.0968\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0995 - val_loss: 0.0964\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0990 - val_loss: 0.0961\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0989 - val_loss: 0.0961\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0982 - val_loss: 0.0960\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0981 - val_loss: 0.0958\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0977 - val_loss: 0.0957\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0972 - val_loss: 0.0959\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0973 - val_loss: 0.0956\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0965 - val_loss: 0.0957\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0964 - val_loss: 0.0949\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0963 - val_loss: 0.0961\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0959 - val_loss: 0.0964\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0959 - val_loss: 0.0960\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0958 - val_loss: 0.0961\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 2s 33us/step - loss: 0.0956 - val_loss: 0.0947\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0957 - val_loss: 0.0957\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 2s 33us/step - loss: 0.0955 - val_loss: 0.0954\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0949 - val_loss: 0.0953\n",
      "Epoch 28/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0952 - val_loss: 0.0955\n",
      "Epoch 29/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0947 - val_loss: 0.0955\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 3s 51us/step - loss: 0.1334 - val_loss: 0.1053\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.1087 - val_loss: 0.1029\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1042 - val_loss: 0.0974\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1025 - val_loss: 0.0964\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1013 - val_loss: 0.0952\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1011 - val_loss: 0.0968\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1002 - val_loss: 0.0952\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0997 - val_loss: 0.0972\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0990 - val_loss: 0.0978\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0987 - val_loss: 0.0971\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0985 - val_loss: 0.0951\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0982 - val_loss: 0.0944\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0975 - val_loss: 0.0937\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0977 - val_loss: 0.0950\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0975 - val_loss: 0.0941\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0967 - val_loss: 0.0932\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0966 - val_loss: 0.0938\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0963 - val_loss: 0.0939\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0962 - val_loss: 0.0959\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0959 - val_loss: 0.0931\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0963 - val_loss: 0.0948\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0956 - val_loss: 0.0935\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0954 - val_loss: 0.0945\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0955 - val_loss: 0.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.0955 - val_loss: 0.0952\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00025: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 3s 49us/step - loss: 0.1271 - val_loss: 0.1054\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1091 - val_loss: 0.0988\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1048 - val_loss: 0.0967\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1029 - val_loss: 0.0957\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1020 - val_loss: 0.0951\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 34us/step - loss: 0.1007 - val_loss: 0.0966\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.1003 - val_loss: 0.0936\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0992 - val_loss: 0.0945\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0989 - val_loss: 0.0931\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0985 - val_loss: 0.0937\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0978 - val_loss: 0.0946\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0975 - val_loss: 0.0939\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0974 - val_loss: 0.0934\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0967 - val_loss: 0.0931\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0967 - val_loss: 0.0931\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0970 - val_loss: 0.0926\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0962 - val_loss: 0.0925\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0962 - val_loss: 0.0925\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0961 - val_loss: 0.0927\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0959 - val_loss: 0.0932\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0956 - val_loss: 0.0932\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0956 - val_loss: 0.0928\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00022: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 3s 55us/step - loss: 0.1274 - val_loss: 0.1038\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.1070 - val_loss: 0.1003\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.1027 - val_loss: 0.0988\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.1008 - val_loss: 0.0970\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.0997 - val_loss: 0.0958\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.0987 - val_loss: 0.0958\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0982 - val_loss: 0.0945\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0976 - val_loss: 0.0942\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0971 - val_loss: 0.0941\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0968 - val_loss: 0.0942\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0964 - val_loss: 0.0939\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0965 - val_loss: 0.0958\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0962 - val_loss: 0.0949\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0956 - val_loss: 0.0938\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 38us/step - loss: 0.0955 - val_loss: 0.0948\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 39us/step - loss: 0.0953 - val_loss: 0.0940\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0953 - val_loss: 0.0936\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0947 - val_loss: 0.0940\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0948 - val_loss: 0.0937\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0945 - val_loss: 0.0960\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 2s 37us/step - loss: 0.0942 - val_loss: 0.0930\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 2s 36us/step - loss: 0.0943 - val_loss: 0.0939\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0946 - val_loss: 0.0939\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0943 - val_loss: 0.0953\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0942 - val_loss: 0.0941\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 2s 35us/step - loss: 0.0940 - val_loss: 0.0937\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model, band_embedding_model, influencer_embedding_model = build_NN_model()\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, i_kind_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, i_kind_idx]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, i_kind_idx]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN score: 0.30981423403005004\n"
     ]
    }
   ],
   "source": [
    "print(f'NN score: {nn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60267/60267 [==============================] - 4s 73us/step - loss: 0.1233 - val_loss: 0.1039\n",
      "Epoch 2/100\n",
      "60267/60267 [==============================] - 3s 46us/step - loss: 0.1051 - val_loss: 0.0987\n",
      "Epoch 3/100\n",
      "60267/60267 [==============================] - 3s 51us/step - loss: 0.1018 - val_loss: 0.0991\n",
      "Epoch 4/100\n",
      "60267/60267 [==============================] - 3s 46us/step - loss: 0.1002 - val_loss: 0.0963\n",
      "Epoch 5/100\n",
      "60267/60267 [==============================] - 3s 45us/step - loss: 0.0991 - val_loss: 0.0973\n",
      "Epoch 6/100\n",
      "60267/60267 [==============================] - 3s 46us/step - loss: 0.0983 - val_loss: 0.0963\n",
      "Epoch 7/100\n",
      "60267/60267 [==============================] - 3s 43us/step - loss: 0.0977 - val_loss: 0.0963\n",
      "Epoch 8/100\n",
      "60267/60267 [==============================] - 3s 44us/step - loss: 0.0973 - val_loss: 0.0970\n",
      "Epoch 9/100\n",
      "60267/60267 [==============================] - 3s 45us/step - loss: 0.0969 - val_loss: 0.0954\n",
      "Epoch 10/100\n",
      "60267/60267 [==============================] - 3s 44us/step - loss: 0.0959 - val_loss: 0.0953\n",
      "Epoch 11/100\n",
      "60267/60267 [==============================] - 3s 43us/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 12/100\n",
      "60267/60267 [==============================] - 3s 43us/step - loss: 0.0957 - val_loss: 0.0943\n",
      "Epoch 13/100\n",
      "60267/60267 [==============================] - 3s 45us/step - loss: 0.0950 - val_loss: 0.0947\n",
      "Epoch 14/100\n",
      "60267/60267 [==============================] - 3s 48us/step - loss: 0.0949 - val_loss: 0.0953\n",
      "Epoch 15/100\n",
      "60267/60267 [==============================] - 3s 46us/step - loss: 0.0948 - val_loss: 0.0951\n",
      "Epoch 16/100\n",
      "60267/60267 [==============================] - 3s 48us/step - loss: 0.0943 - val_loss: 0.0948\n",
      "Epoch 17/100\n",
      "60267/60267 [==============================] - 3s 46us/step - loss: 0.0941 - val_loss: 0.0948\n",
      "Epoch 18/100\n",
      "60267/60267 [==============================] - 3s 49us/step - loss: 0.0939 - val_loss: 0.0942\n",
      "Epoch 19/100\n",
      "60267/60267 [==============================] - 3s 48us/step - loss: 0.0937 - val_loss: 0.0933\n",
      "Epoch 20/100\n",
      "60267/60267 [==============================] - 3s 48us/step - loss: 0.0935 - val_loss: 0.0947\n",
      "Epoch 21/100\n",
      "60267/60267 [==============================] - 3s 51us/step - loss: 0.0935 - val_loss: 0.0948\n",
      "Epoch 22/100\n",
      "60267/60267 [==============================] - 3s 50us/step - loss: 0.0934 - val_loss: 0.0950\n",
      "Epoch 23/100\n",
      "60267/60267 [==============================] - 3s 47us/step - loss: 0.0930 - val_loss: 0.0945\n",
      "Epoch 24/100\n",
      "60267/60267 [==============================] - 3s 47us/step - loss: 0.0932 - val_loss: 0.0942\n",
      "Epoch 25/100\n",
      "60267/60267 [==============================] - 3s 51us/step - loss: 0.0930 - val_loss: 0.0946\n",
      "Epoch 26/100\n",
      "60267/60267 [==============================] - 3s 54us/step - loss: 0.0927 - val_loss: 0.0950\n",
      "Epoch 27/100\n",
      "60267/60267 [==============================] - 3s 49us/step - loss: 0.0929 - val_loss: 0.0949\n",
      "Epoch 28/100\n",
      "60267/60267 [==============================] - 3s 47us/step - loss: 0.0929 - val_loss: 0.0941\n",
      "Epoch 29/100\n",
      "60267/60267 [==============================] - 3s 45us/step - loss: 0.0926 - val_loss: 0.0934\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 5s 78us/step - loss: 0.1196 - val_loss: 0.1033\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 3s 51us/step - loss: 0.1052 - val_loss: 0.1018\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.1018 - val_loss: 0.1001\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 3s 53us/step - loss: 0.1002 - val_loss: 0.0985\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 3s 49us/step - loss: 0.0987 - val_loss: 0.0974\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 3s 48us/step - loss: 0.0980 - val_loss: 0.0975\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 3s 50us/step - loss: 0.0975 - val_loss: 0.0979\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0972 - val_loss: 0.0972\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0962 - val_loss: 0.0968\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 3s 51us/step - loss: 0.0960 - val_loss: 0.0972\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 3s 48us/step - loss: 0.0957 - val_loss: 0.0973\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 3s 49us/step - loss: 0.0954 - val_loss: 0.0964\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0947 - val_loss: 0.0966\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0946 - val_loss: 0.0965\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0944 - val_loss: 0.0958\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0940 - val_loss: 0.0969\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0941 - val_loss: 0.0965\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0936 - val_loss: 0.0978\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0939 - val_loss: 0.0956\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.0938 - val_loss: 0.0956\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.0933 - val_loss: 0.0953\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0932 - val_loss: 0.0955\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.0932 - val_loss: 0.0954\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0930 - val_loss: 0.0954\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0927 - val_loss: 0.0961\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 3s 48us/step - loss: 0.0927 - val_loss: 0.0966\n",
      "Epoch 28/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0925 - val_loss: 0.0957\n",
      "Epoch 29/100\n",
      "60268/60268 [==============================] - 3s 50us/step - loss: 0.0927 - val_loss: 0.0971\n",
      "Epoch 30/100\n",
      "60268/60268 [==============================] - 3s 51us/step - loss: 0.0924 - val_loss: 0.0955\n",
      "Epoch 31/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0921 - val_loss: 0.0964\n",
      "Epoch 32/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0923 - val_loss: 0.0964\n",
      "Epoch 33/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0923 - val_loss: 0.0970\n",
      "Epoch 34/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0920 - val_loss: 0.0953\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00034: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 4s 72us/step - loss: 0.1211 - val_loss: 0.1037\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.1052 - val_loss: 0.1011\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.1017 - val_loss: 0.0969\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.1002 - val_loss: 0.0977\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 3s 49us/step - loss: 0.0988 - val_loss: 0.0957\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0983 - val_loss: 0.0956\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0978 - val_loss: 0.0951\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 3s 48us/step - loss: 0.0970 - val_loss: 0.0952\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 3s 50us/step - loss: 0.0965 - val_loss: 0.0948\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0964 - val_loss: 0.0946\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0959 - val_loss: 0.0949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0960 - val_loss: 0.0944\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0956 - val_loss: 0.0959\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0953 - val_loss: 0.0946\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0949 - val_loss: 0.0942\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0948 - val_loss: 0.0945\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0946 - val_loss: 0.0951\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0942 - val_loss: 0.0948\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0939 - val_loss: 0.0945\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0938 - val_loss: 0.0957\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0940 - val_loss: 0.0949\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0937 - val_loss: 0.0950\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0939 - val_loss: 0.0946\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0934 - val_loss: 0.0950\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0931 - val_loss: 0.0946\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00025: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 4s 66us/step - loss: 0.1203 - val_loss: 0.1023\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.1053 - val_loss: 0.0998\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.1022 - val_loss: 0.0959\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.1004 - val_loss: 0.0952\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0993 - val_loss: 0.0949\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0987 - val_loss: 0.0943\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0980 - val_loss: 0.0949\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0974 - val_loss: 0.0942\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0969 - val_loss: 0.0943\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0962 - val_loss: 0.0933\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0965 - val_loss: 0.0947\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0956 - val_loss: 0.0929\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0953 - val_loss: 0.0931\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0951 - val_loss: 0.0926\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0951 - val_loss: 0.0930\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0947 - val_loss: 0.0940\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0948 - val_loss: 0.0936\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0944 - val_loss: 0.0924\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0942 - val_loss: 0.0933\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 3s 48us/step - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0936 - val_loss: 0.0920\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0934 - val_loss: 0.0927\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0932 - val_loss: 0.0930\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.0933 - val_loss: 0.0926\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0931 - val_loss: 0.0924\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0930 - val_loss: 0.0931\n",
      "Epoch 28/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0930 - val_loss: 0.0924\n",
      "Epoch 29/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0927 - val_loss: 0.0943\n",
      "Epoch 30/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0928 - val_loss: 0.0923\n",
      "Epoch 31/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0925 - val_loss: 0.0927\n",
      "Epoch 32/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0924 - val_loss: 0.0934\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00032: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 4s 67us/step - loss: 0.1225 - val_loss: 0.1036\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.1061 - val_loss: 0.1007\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.1026 - val_loss: 0.0988\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.1008 - val_loss: 0.0984\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0997 - val_loss: 0.0966\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0992 - val_loss: 0.0960\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0981 - val_loss: 0.0968\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0975 - val_loss: 0.0968\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0970 - val_loss: 0.0968\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0966 - val_loss: 0.0969\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0967 - val_loss: 0.0965\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 2s 41us/step - loss: 0.0963 - val_loss: 0.0949\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 3s 42us/step - loss: 0.0960 - val_loss: 0.0962\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 2s 40us/step - loss: 0.0959 - val_loss: 0.0956\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0953 - val_loss: 0.0946\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0951 - val_loss: 0.0961\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0947 - val_loss: 0.0942\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0949 - val_loss: 0.0947\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0943 - val_loss: 0.0947\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 3s 44us/step - loss: 0.0942 - val_loss: 0.0949\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 3s 43us/step - loss: 0.0942 - val_loss: 0.0953\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 3s 45us/step - loss: 0.0940 - val_loss: 0.0948\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 3s 46us/step - loss: 0.0937 - val_loss: 0.0954\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 3s 47us/step - loss: 0.0936 - val_loss: 0.0950\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 5s 82us/step - loss: 0.0936 - val_loss: 0.0952\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 7s 116us/step - loss: 0.0935 - val_loss: 0.0963\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 6s 93us/step - loss: 0.0932 - val_loss: 0.0955\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model, band_embedding_model, influencer_embedding_model = build_NN_model(dropout=0.1)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, i_kind_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, i_kind_idx]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, i_kind_idx]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN score: 0.30963655165140275\n"
     ]
    }
   ],
   "source": [
    "print(f'NN score: {nn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx]], y_valid), \n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx]]), y_test))\n",
    "\n",
    "nn_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'NN score: {nn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(i_emb_dim=50, b_emb_dim=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    prod = Dot(name=\"Dot-Product\", axes=1)([influencer_embedding, band_embedding])\n",
    "    model = Model([influencer_input, band_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_x': 'Variete Francaise_x', 'Variété Française_y': 'Variete Francaise_y'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data = dataset.filter(regex='_y')\n",
    "b_data = dataset.filter(regex='_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_y')]\n",
    "b_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.get_loc('Variété Française_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83706, 148)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46874/46874 [==============================] - 7s 150us/step - loss: 0.2231 - val_loss: 0.1751\n",
      "Epoch 2/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1512 - val_loss: 0.1471\n",
      "Epoch 3/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1372 - val_loss: 0.1382\n",
      "Epoch 4/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1299 - val_loss: 0.1347\n",
      "Epoch 5/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1240 - val_loss: 0.1358\n",
      "Epoch 6/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1208 - val_loss: 0.1293\n",
      "Epoch 7/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1175 - val_loss: 0.1253\n",
      "Epoch 8/10\n",
      "46874/46874 [==============================] - 4s 76us/step - loss: 0.1153 - val_loss: 0.1221\n",
      "Epoch 9/10\n",
      "46874/46874 [==============================] - 4s 77us/step - loss: 0.1129 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "46874/46874 [==============================] - 4s 75us/step - loss: 0.1114 - val_loss: 0.1170\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 155us/step - loss: 0.2197 - val_loss: 0.1707\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 81us/step - loss: 0.1507 - val_loss: 0.1467\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1357 - val_loss: 0.1389\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1273 - val_loss: 0.1306\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1215 - val_loss: 0.1258\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1191 - val_loss: 0.1290\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1156 - val_loss: 0.1251\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1125 - val_loss: 0.1217\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1117 - val_loss: 0.1174\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 76us/step - loss: 0.1090 - val_loss: 0.1169\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 151us/step - loss: 0.2238 - val_loss: 0.1654\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1503 - val_loss: 0.1461\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1353 - val_loss: 0.1382\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1277 - val_loss: 0.1287\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1228 - val_loss: 0.1274\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 83us/step - loss: 0.1188 - val_loss: 0.1263\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1157 - val_loss: 0.1222\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1125 - val_loss: 0.1204\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1118 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1094 - val_loss: 0.1229\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 154us/step - loss: 0.2227 - val_loss: 0.1672\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1503 - val_loss: 0.1494\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1362 - val_loss: 0.1443\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 80us/step - loss: 0.1282 - val_loss: 0.1336\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1228 - val_loss: 0.1294\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1202 - val_loss: 0.1271\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 81us/step - loss: 0.1164 - val_loss: 0.1281\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1147 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 77us/step - loss: 0.1126 - val_loss: 0.1249\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1104 - val_loss: 0.1201\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 7s 154us/step - loss: 0.2174 - val_loss: 0.1623\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 4s 88us/step - loss: 0.1484 - val_loss: 0.1417\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 4s 82us/step - loss: 0.1343 - val_loss: 0.1330\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 4s 78us/step - loss: 0.1273 - val_loss: 0.1303\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1221 - val_loss: 0.1257\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 4s 87us/step - loss: 0.1181 - val_loss: 0.1246\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 4s 88us/step - loss: 0.1153 - val_loss: 0.1233\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1123 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1110 - val_loss: 0.1267\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 4s 79us/step - loss: 0.1091 - val_loss: 0.1194\n",
      "0.3448840988103111\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx]], y_valid), \n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx]]), y_test))\n",
    "\n",
    "nn_score /= N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6bbba488f89a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'NN score: {nn_score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_score' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'NN score: {nn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.influencer_kind.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=5, last_dense=20, dropout=0.2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense1\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense2\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=10, last_dense=40, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='relu', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='relu', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='relu', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='relu', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='relu', name=\"Dense3\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_x</th>\n",
       "      <th>African music_x</th>\n",
       "      <th>Alternative rock_x</th>\n",
       "      <th>Ambient_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_y</th>\n",
       "      <th>Soul_y</th>\n",
       "      <th>Surf rock_y</th>\n",
       "      <th>Synthpop_y</th>\n",
       "      <th>Synthwave_y</th>\n",
       "      <th>Techno_y</th>\n",
       "      <th>Traditional Music_y</th>\n",
       "      <th>Trap_y</th>\n",
       "      <th>Trip hop_y</th>\n",
       "      <th>Variété Française_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_x  African music_x  Alternative rock_x  Ambient_x  ...  \\\n",
       "0             0                0                   0          0  ...   \n",
       "1             0                0                   0          0  ...   \n",
       "2             0                0                   0          0  ...   \n",
       "3             0                0                   0          0  ...   \n",
       "4             0                0                   0          0  ...   \n",
       "\n",
       "   Singer-songwriter_y  Soul_y  Surf rock_y  Synthpop_y  Synthwave_y  \\\n",
       "0                    0       0            0           0            0   \n",
       "1                    0       0            0           0            0   \n",
       "2                    0       1            0           0            0   \n",
       "3                    0       0            1           0            0   \n",
       "4                    0       0            1           0            0   \n",
       "\n",
       "   Techno_y  Traditional Music_y  Trap_y  Trip hop_y  Variété Française_y  \n",
       "0         1                    0       0           1                    0  \n",
       "1         0                    0       0           0                    0  \n",
       "2         0                    0       1           0                    1  \n",
       "3         0                    0       0           0                    0  \n",
       "4         0                    0       0           0                    0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 16s 334us/step - loss: 0.1167 - val_loss: 0.1042\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.1032 - val_loss: 0.0989\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.1003 - val_loss: 0.0977\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 11s 238us/step - loss: 0.0993 - val_loss: 0.0954\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 11s 237us/step - loss: 0.0974 - val_loss: 0.0975\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 11s 231us/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0959 - val_loss: 0.0949\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0951 - val_loss: 0.0945\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0949 - val_loss: 0.0954\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0937 - val_loss: 0.0954\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 10s 218us/step - loss: 0.0932 - val_loss: 0.0953\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0931 - val_loss: 0.0943\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0924 - val_loss: 0.0959\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 10s 220us/step - loss: 0.0919 - val_loss: 0.0957\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 10s 221us/step - loss: 0.0917 - val_loss: 0.0952\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0915 - val_loss: 0.0948\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0911 - val_loss: 0.0953\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0910 - val_loss: 0.0956\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0906 - val_loss: 0.0949\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0901 - val_loss: 0.0971\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0902 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 11s 233us/step - loss: 0.0898 - val_loss: 0.0955\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 11s 224us/step - loss: 0.0898 - val_loss: 0.0968\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0891 - val_loss: 0.0960\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0894 - val_loss: 0.0975\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0892 - val_loss: 0.0963\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0885 - val_loss: 0.0959\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 10s 222us/step - loss: 0.0886 - val_loss: 0.0959\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0882 - val_loss: 0.0961\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0884 - val_loss: 0.0963\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0879 - val_loss: 0.0964\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0875 - val_loss: 0.0961\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0875 - val_loss: 0.0958\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0874 - val_loss: 0.0969\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 10s 219us/step - loss: 0.0872 - val_loss: 0.0965\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 11s 230us/step - loss: 0.0873 - val_loss: 0.0957\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0866 - val_loss: 0.0969\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0867 - val_loss: 0.0965\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0867 - val_loss: 0.0968\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 10s 220us/step - loss: 0.0865 - val_loss: 0.0980\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 10s 219us/step - loss: 0.0862 - val_loss: 0.0964\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0861 - val_loss: 0.0980\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 11s 225us/step - loss: 0.0861 - val_loss: 0.0968\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 11s 231us/step - loss: 0.0857 - val_loss: 0.0986\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0859 - val_loss: 0.0998\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 11s 228us/step - loss: 0.0856 - val_loss: 0.0981\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 11s 240us/step - loss: 0.0852 - val_loss: 0.0973\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 11s 235us/step - loss: 0.0852 - val_loss: 0.0972\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 11s 232us/step - loss: 0.0854 - val_loss: 0.0978\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 11s 233us/step - loss: 0.0852 - val_loss: 0.0992\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0848 - val_loss: 0.0992\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 11s 229us/step - loss: 0.0849 - val_loss: 0.0989\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0848 - val_loss: 0.0991\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 11s 235us/step - loss: 0.0844 - val_loss: 0.0991\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 11s 237us/step - loss: 0.0845 - val_loss: 0.0985\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 11s 236us/step - loss: 0.0843 - val_loss: 0.0972\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 11s 238us/step - loss: 0.0841 - val_loss: 0.0985\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 11s 234us/step - loss: 0.0842 - val_loss: 0.0990\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0839 - val_loss: 0.0984\n",
      "Epoch 60/10000\n",
      "46874/46874 [==============================] - 11s 227us/step - loss: 0.0834 - val_loss: 0.0993\n",
      "Epoch 61/10000\n",
      "46874/46874 [==============================] - 11s 226us/step - loss: 0.0840 - val_loss: 0.0975\n",
      "Epoch 62/10000\n",
      "46874/46874 [==============================] - 10s 223us/step - loss: 0.0838 - val_loss: 0.1007\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 339us/step - loss: 0.1164 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.1033 - val_loss: 0.0996\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.1002 - val_loss: 0.0980\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0987 - val_loss: 0.0967\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0977 - val_loss: 0.0968\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0970 - val_loss: 0.0968\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0959 - val_loss: 0.0979\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0953 - val_loss: 0.0972\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.0949 - val_loss: 0.0996\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0942 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0934 - val_loss: 0.0967\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0935 - val_loss: 0.0965\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0928 - val_loss: 0.0969\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 227us/step - loss: 0.0923 - val_loss: 0.0957\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 245us/step - loss: 0.0917 - val_loss: 0.0959\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0916 - val_loss: 0.0965\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0913 - val_loss: 0.0968\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 241us/step - loss: 0.0908 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 242us/step - loss: 0.0907 - val_loss: 0.0971\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0903 - val_loss: 0.0969\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0903 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0897 - val_loss: 0.0966\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0895 - val_loss: 0.0972\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0892 - val_loss: 0.0969\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0890 - val_loss: 0.0982\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0887 - val_loss: 0.0969\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0885 - val_loss: 0.0994\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0883 - val_loss: 0.0976\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0880 - val_loss: 0.0989\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0880 - val_loss: 0.0973\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0879 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0880 - val_loss: 0.0985\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0874 - val_loss: 0.0988\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0874 - val_loss: 0.0989\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0869 - val_loss: 0.0981\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0869 - val_loss: 0.0989\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0874 - val_loss: 0.0983\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0864 - val_loss: 0.0989\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0864 - val_loss: 0.0993\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0858 - val_loss: 0.0995\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0859 - val_loss: 0.0988\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0858 - val_loss: 0.0999\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0855 - val_loss: 0.1008\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0856 - val_loss: 0.0990\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0852 - val_loss: 0.0993\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.0997\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0851 - val_loss: 0.1001\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0851 - val_loss: 0.1003\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0848 - val_loss: 0.0998\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0845 - val_loss: 0.0997\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0845 - val_loss: 0.1012\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0844 - val_loss: 0.1008\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0839 - val_loss: 0.1006\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0841 - val_loss: 0.1003\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0837 - val_loss: 0.1010\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0840 - val_loss: 0.1015\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0838 - val_loss: 0.1020\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0836 - val_loss: 0.1005\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0837 - val_loss: 0.1016\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0833 - val_loss: 0.1038\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0833 - val_loss: 0.1017\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0835 - val_loss: 0.1019\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0831 - val_loss: 0.1020\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00064: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 333us/step - loss: 0.1167 - val_loss: 0.1027\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.1039 - val_loss: 0.0996\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.1004 - val_loss: 0.0979\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0990 - val_loss: 0.0962\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0975 - val_loss: 0.0976\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0967 - val_loss: 0.0965\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0963 - val_loss: 0.0960\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0954 - val_loss: 0.0965\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0948 - val_loss: 0.0953\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0942 - val_loss: 0.0965\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0935 - val_loss: 0.0953\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0932 - val_loss: 0.0958\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0926 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0921 - val_loss: 0.0960\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0922 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0917 - val_loss: 0.0967\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0914 - val_loss: 0.0975\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0906 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 235us/step - loss: 0.0906 - val_loss: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0903 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0898 - val_loss: 0.0979\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0898 - val_loss: 0.0968\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0894 - val_loss: 0.0980\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0892 - val_loss: 0.0977\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0888 - val_loss: 0.0970\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0887 - val_loss: 0.0970\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 231us/step - loss: 0.0882 - val_loss: 0.0968\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0884 - val_loss: 0.0969\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0880 - val_loss: 0.0973\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0878 - val_loss: 0.0973\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0879 - val_loss: 0.0976\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0877 - val_loss: 0.0971\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0877 - val_loss: 0.0972\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0873 - val_loss: 0.0978\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0873 - val_loss: 0.0970\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0872 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0872 - val_loss: 0.0978\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0866 - val_loss: 0.0995\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0865 - val_loss: 0.0991\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0866 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0860 - val_loss: 0.0987\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0858 - val_loss: 0.0988\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0861 - val_loss: 0.0984\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0857 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0856 - val_loss: 0.0984\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0854 - val_loss: 0.0989\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.0999\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0853 - val_loss: 0.1003\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0853 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0849 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0849 - val_loss: 0.0986\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0848 - val_loss: 0.0990\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 234us/step - loss: 0.0842 - val_loss: 0.1000\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0846 - val_loss: 0.0996\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 232us/step - loss: 0.0841 - val_loss: 0.0995\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0839 - val_loss: 0.1000\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0843 - val_loss: 0.0998\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0840 - val_loss: 0.1002\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 233us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 336us/step - loss: 0.1145 - val_loss: 0.1046\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.1023 - val_loss: 0.1011\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0993 - val_loss: 0.0988\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0979 - val_loss: 0.0980\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0970 - val_loss: 0.0987\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0958 - val_loss: 0.0990\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0953 - val_loss: 0.0969\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0941 - val_loss: 0.0972\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0937 - val_loss: 0.0981\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0928 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0925 - val_loss: 0.0974\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0919 - val_loss: 0.0978\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0917 - val_loss: 0.0980\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0911 - val_loss: 0.0977\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0909 - val_loss: 0.0972\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0906 - val_loss: 0.0963\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0902 - val_loss: 0.0979\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0899 - val_loss: 0.0973\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0895 - val_loss: 0.0980\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0890 - val_loss: 0.0977\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0892 - val_loss: 0.0968\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0885 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0883 - val_loss: 0.0983\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0880 - val_loss: 0.0982\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0879 - val_loss: 0.0977\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0875 - val_loss: 0.0983\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0875 - val_loss: 0.0978\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0868 - val_loss: 0.0997\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0871 - val_loss: 0.0975\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0866 - val_loss: 0.0983\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0863 - val_loss: 0.0987\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0859 - val_loss: 0.0980\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0857 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0853 - val_loss: 0.1000\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0855 - val_loss: 0.0988\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0851 - val_loss: 0.0988\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0852 - val_loss: 0.0994\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0850 - val_loss: 0.0996\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0849 - val_loss: 0.1000\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0845 - val_loss: 0.1003\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0844 - val_loss: 0.1008\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0846 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0839 - val_loss: 0.1005\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0840 - val_loss: 0.1005\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0838 - val_loss: 0.0996\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0834 - val_loss: 0.0989\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0833 - val_loss: 0.0999\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0831 - val_loss: 0.1000\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0830 - val_loss: 0.1011\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0828 - val_loss: 0.1004\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0826 - val_loss: 0.1011\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0827 - val_loss: 0.1005\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0823 - val_loss: 0.1019\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0825 - val_loss: 0.1011\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 236us/step - loss: 0.0821 - val_loss: 0.1009\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0822 - val_loss: 0.1014\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0820 - val_loss: 0.1005\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0817 - val_loss: 0.1016\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0816 - val_loss: 0.1012\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0817 - val_loss: 0.1019\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0814 - val_loss: 0.1023\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0813 - val_loss: 0.1013\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0814 - val_loss: 0.1022\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0812 - val_loss: 0.1008\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00066: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 339us/step - loss: 0.1162 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.1031 - val_loss: 0.0982\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0997 - val_loss: 0.1018\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0981 - val_loss: 0.0975\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0970 - val_loss: 0.0977\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0964 - val_loss: 0.0977\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0955 - val_loss: 0.0954\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0946 - val_loss: 0.0987\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0936 - val_loss: 0.0961\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0931 - val_loss: 0.0964\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0929 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0925 - val_loss: 0.0956\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0917 - val_loss: 0.0964\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0917 - val_loss: 0.0968\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0910 - val_loss: 0.0952\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0908 - val_loss: 0.0957\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0903 - val_loss: 0.0970\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0898 - val_loss: 0.0981\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0897 - val_loss: 0.0958\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0892 - val_loss: 0.0954\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0890 - val_loss: 0.0962\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0887 - val_loss: 0.0956\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0886 - val_loss: 0.0957\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0879 - val_loss: 0.0968\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0880 - val_loss: 0.0955\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0877 - val_loss: 0.0978\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0871 - val_loss: 0.0966\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0870 - val_loss: 0.0970\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0868 - val_loss: 0.0971\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0864 - val_loss: 0.0977\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0868 - val_loss: 0.0961\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0863 - val_loss: 0.0990\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0857 - val_loss: 0.0981\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0857 - val_loss: 0.0983\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0854 - val_loss: 0.0967\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0854 - val_loss: 0.0965\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0851 - val_loss: 0.0985\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 240us/step - loss: 0.0850 - val_loss: 0.0969\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0845 - val_loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0845 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0845 - val_loss: 0.0982\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0846 - val_loss: 0.0998\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0846 - val_loss: 0.0979\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0837 - val_loss: 0.0980\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0838 - val_loss: 0.1009\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0839 - val_loss: 0.0994\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0831 - val_loss: 0.0996\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0832 - val_loss: 0.0980\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0835 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0832 - val_loss: 0.0993\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0830 - val_loss: 0.0977\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0828 - val_loss: 0.0994\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0827 - val_loss: 0.0986\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0826 - val_loss: 0.0990\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0824 - val_loss: 0.0984\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0822 - val_loss: 0.0989\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0827 - val_loss: 0.0983\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0822 - val_loss: 0.0993\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0823 - val_loss: 0.1012\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0817 - val_loss: 0.0988\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 238us/step - loss: 0.0818 - val_loss: 0.0998\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0814 - val_loss: 0.0991\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0816 - val_loss: 0.0990\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 11s 237us/step - loss: 0.0810 - val_loss: 0.1005\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 11s 239us/step - loss: 0.0817 - val_loss: 0.1001\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00065: early stopping\n",
      "0.3092543342407225\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 16s 346us/step - loss: 0.1133 - val_loss: 0.0995\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.1032 - val_loss: 0.0976\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0996 - val_loss: 0.0965\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0985 - val_loss: 0.0965\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 11s 242us/step - loss: 0.0970 - val_loss: 0.0953\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0962 - val_loss: 0.0978\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0955 - val_loss: 0.0945\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0947 - val_loss: 0.0953\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0940 - val_loss: 0.0942\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0930 - val_loss: 0.0958\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0929 - val_loss: 0.0950\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0920 - val_loss: 0.0946\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0915 - val_loss: 0.0945\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0912 - val_loss: 0.0965\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0906 - val_loss: 0.0954\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0903 - val_loss: 0.0956\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0898 - val_loss: 0.0945\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0896 - val_loss: 0.0946\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0895 - val_loss: 0.0965\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 11s 243us/step - loss: 0.0888 - val_loss: 0.0966\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0883 - val_loss: 0.0958\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0881 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0881 - val_loss: 0.0962\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0876 - val_loss: 0.0960\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0875 - val_loss: 0.0976\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0868 - val_loss: 0.0960\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0866 - val_loss: 0.0962\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0859 - val_loss: 0.0970\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0857 - val_loss: 0.0972\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0855 - val_loss: 0.0972\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.0974\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0850 - val_loss: 0.0969\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.0986\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0847 - val_loss: 0.0980\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0847 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0842 - val_loss: 0.0986\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0837 - val_loss: 0.0975\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0834 - val_loss: 0.0977\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0835 - val_loss: 0.0985\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0833 - val_loss: 0.0988\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0829 - val_loss: 0.0999\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0828 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0828 - val_loss: 0.0991\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0824 - val_loss: 0.0988\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 12s 248us/step - loss: 0.0822 - val_loss: 0.0990\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 12s 245us/step - loss: 0.0822 - val_loss: 0.0998\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0819 - val_loss: 0.0990\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0816 - val_loss: 0.0988\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0813 - val_loss: 0.0983\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 12s 246us/step - loss: 0.0817 - val_loss: 0.0999\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0814 - val_loss: 0.1005\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0812 - val_loss: 0.0992\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0809 - val_loss: 0.0998\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0810 - val_loss: 0.1014\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0802 - val_loss: 0.1008\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0802 - val_loss: 0.1016\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 11s 245us/step - loss: 0.0806 - val_loss: 0.1007\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 11s 244us/step - loss: 0.0800 - val_loss: 0.1014\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 16s 352us/step - loss: 0.1143 - val_loss: 0.1036\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.1027 - val_loss: 0.0987\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0995 - val_loss: 0.0989\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0979 - val_loss: 0.0969\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0968 - val_loss: 0.0972\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0960 - val_loss: 0.0969\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0953 - val_loss: 0.0978\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0944 - val_loss: 0.0961\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0936 - val_loss: 0.0968\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0933 - val_loss: 0.0966\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 247us/step - loss: 0.0928 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0925 - val_loss: 0.0959\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0919 - val_loss: 0.0958\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0914 - val_loss: 0.0970\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0910 - val_loss: 0.0972\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0908 - val_loss: 0.0960\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0903 - val_loss: 0.0956\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0899 - val_loss: 0.0968\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0900 - val_loss: 0.0978\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0896 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0890 - val_loss: 0.0980\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0885 - val_loss: 0.0982\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0882 - val_loss: 0.0974\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0884 - val_loss: 0.0977\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0876 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0876 - val_loss: 0.0978\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0874 - val_loss: 0.0983\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0866 - val_loss: 0.0979\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0865 - val_loss: 0.0983\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0861 - val_loss: 0.0981\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0860 - val_loss: 0.0988\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0861 - val_loss: 0.0988\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0855 - val_loss: 0.1005\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0854 - val_loss: 0.0992\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0851 - val_loss: 0.1005\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0848 - val_loss: 0.1016\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0846 - val_loss: 0.1002\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0845 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0842 - val_loss: 0.0996\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0839 - val_loss: 0.1006\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0836 - val_loss: 0.1016\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0836 - val_loss: 0.1015\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0835 - val_loss: 0.1014\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0830 - val_loss: 0.1012\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 11s 243us/step - loss: 0.0827 - val_loss: 0.1007\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0823 - val_loss: 0.1006\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0823 - val_loss: 0.1012\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0821 - val_loss: 0.1020\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0818 - val_loss: 0.1009\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0817 - val_loss: 0.1029\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0817 - val_loss: 0.1022\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 11s 245us/step - loss: 0.0816 - val_loss: 0.1017\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0811 - val_loss: 0.1024\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0805 - val_loss: 0.1031\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0808 - val_loss: 0.1027\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0803 - val_loss: 0.1030\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0804 - val_loss: 0.1028\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0803 - val_loss: 0.1039\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0800 - val_loss: 0.1033\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 11s 244us/step - loss: 0.0801 - val_loss: 0.1047\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 13s 284us/step - loss: 0.0795 - val_loss: 0.1035\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 13s 287us/step - loss: 0.0797 - val_loss: 0.1029\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0790 - val_loss: 0.1049\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 14s 307us/step - loss: 0.0793 - val_loss: 0.1045\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 14s 305us/step - loss: 0.0797 - val_loss: 0.1050\n",
      "Epoch 67/10000\n",
      "46875/46875 [==============================] - 14s 306us/step - loss: 0.0793 - val_loss: 0.1049\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00067: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 427us/step - loss: 0.1164 - val_loss: 0.1015\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.1031 - val_loss: 0.0988\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.1006 - val_loss: 0.0995\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0992 - val_loss: 0.0971\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0977 - val_loss: 0.0981\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0966 - val_loss: 0.0964\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 309us/step - loss: 0.0954 - val_loss: 0.0971\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0952 - val_loss: 0.0985\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0941 - val_loss: 0.0959\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0942 - val_loss: 0.0960\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0931 - val_loss: 0.0960\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0927 - val_loss: 0.0958\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0922 - val_loss: 0.0971\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0915 - val_loss: 0.0982\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0915 - val_loss: 0.0974\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 15s 309us/step - loss: 0.0909 - val_loss: 0.0968\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0910 - val_loss: 0.0974\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0905 - val_loss: 0.0961\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0898 - val_loss: 0.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 15s 309us/step - loss: 0.0899 - val_loss: 0.0978\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0892 - val_loss: 0.0970\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0894 - val_loss: 0.0977\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0888 - val_loss: 0.0977\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0885 - val_loss: 0.0981\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0885 - val_loss: 0.0971\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0877 - val_loss: 0.0982\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0880 - val_loss: 0.0986\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0876 - val_loss: 0.0985\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0873 - val_loss: 0.0991\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0869 - val_loss: 0.0984\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0866 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0866 - val_loss: 0.0990\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0865 - val_loss: 0.0987\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0860 - val_loss: 0.0991\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0857 - val_loss: 0.0989\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0854 - val_loss: 0.0984\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0848 - val_loss: 0.1003\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0850 - val_loss: 0.0992\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0847 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0849 - val_loss: 0.1006\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0840 - val_loss: 0.1013\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0840 - val_loss: 0.0995\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0835 - val_loss: 0.1000\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0835 - val_loss: 0.1003\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0832 - val_loss: 0.1006\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0833 - val_loss: 0.1006\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 15s 310us/step - loss: 0.0833 - val_loss: 0.1013\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 300us/step - loss: 0.0829 - val_loss: 0.1006\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0826 - val_loss: 0.1014\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0828 - val_loss: 0.1015\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0821 - val_loss: 0.1023\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0825 - val_loss: 0.1020\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0823 - val_loss: 0.1016\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0816 - val_loss: 0.1024\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0813 - val_loss: 0.1022\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0812 - val_loss: 0.1032\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0811 - val_loss: 0.1020\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0812 - val_loss: 0.1023\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0811 - val_loss: 0.1034\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 15s 312us/step - loss: 0.0810 - val_loss: 0.1018\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0808 - val_loss: 0.1044\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0808 - val_loss: 0.1023\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 435us/step - loss: 0.1150 - val_loss: 0.1065\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.1027 - val_loss: 0.1007\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0993 - val_loss: 0.0988\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0979 - val_loss: 0.0988\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 15s 316us/step - loss: 0.0961 - val_loss: 0.0983\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 15s 315us/step - loss: 0.0954 - val_loss: 0.0982\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0945 - val_loss: 0.0974\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0934 - val_loss: 0.0989\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 15s 311us/step - loss: 0.0932 - val_loss: 0.1011\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 15s 315us/step - loss: 0.0926 - val_loss: 0.0980\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0925 - val_loss: 0.0979\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0915 - val_loss: 0.0966\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 15s 314us/step - loss: 0.0912 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 15s 313us/step - loss: 0.0905 - val_loss: 0.0982\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0902 - val_loss: 0.0985\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 13s 285us/step - loss: 0.0898 - val_loss: 0.0969\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0895 - val_loss: 0.0973\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0892 - val_loss: 0.0980\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0891 - val_loss: 0.0972\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0885 - val_loss: 0.0974\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 251us/step - loss: 0.0879 - val_loss: 0.0989\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 251us/step - loss: 0.0877 - val_loss: 0.0990\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0878 - val_loss: 0.0980\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0874 - val_loss: 0.0984\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0870 - val_loss: 0.0985\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0867 - val_loss: 0.0991\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0865 - val_loss: 0.0988\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0860 - val_loss: 0.0991\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0862 - val_loss: 0.0978\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0853 - val_loss: 0.0981\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0857 - val_loss: 0.0987\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0851 - val_loss: 0.0991\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0848 - val_loss: 0.0992\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0847 - val_loss: 0.0985\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0845 - val_loss: 0.0999\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0841 - val_loss: 0.1005\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0840 - val_loss: 0.1011\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0841 - val_loss: 0.1006\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0840 - val_loss: 0.1002\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0833 - val_loss: 0.1005\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0829 - val_loss: 0.1005\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0830 - val_loss: 0.0995\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0827 - val_loss: 0.1000\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0822 - val_loss: 0.1009\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0822 - val_loss: 0.1011\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0821 - val_loss: 0.1008\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0819 - val_loss: 0.1017\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 248us/step - loss: 0.0817 - val_loss: 0.1011\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0812 - val_loss: 0.1017\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0814 - val_loss: 0.1014\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0808 - val_loss: 0.1026\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0810 - val_loss: 0.1029\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0804 - val_loss: 0.1023\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0801 - val_loss: 0.1017\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0799 - val_loss: 0.1027\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0799 - val_loss: 0.1032\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0804 - val_loss: 0.1036\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0795 - val_loss: 0.1018\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0794 - val_loss: 0.1034\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0794 - val_loss: 0.1030\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 250us/step - loss: 0.0792 - val_loss: 0.1033\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 249us/step - loss: 0.0788 - val_loss: 0.1033\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 17s 363us/step - loss: 0.1156 - val_loss: 0.1030\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.1027 - val_loss: 0.1007\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0998 - val_loss: 0.0976\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0985 - val_loss: 0.0973\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0973 - val_loss: 0.0961\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0959 - val_loss: 0.0976\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0947 - val_loss: 0.0983\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0942 - val_loss: 0.0966\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0934 - val_loss: 0.0961\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0929 - val_loss: 0.0972\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0922 - val_loss: 0.0951\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0919 - val_loss: 0.0966\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0913 - val_loss: 0.0964\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0912 - val_loss: 0.0963\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0905 - val_loss: 0.0958\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0901 - val_loss: 0.0967\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0898 - val_loss: 0.0960\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0896 - val_loss: 0.0960\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0892 - val_loss: 0.0959\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0885 - val_loss: 0.0961\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0881 - val_loss: 0.0949\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0878 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0878 - val_loss: 0.0959\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0875 - val_loss: 0.0970\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0869 - val_loss: 0.0959\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0867 - val_loss: 0.0968\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0863 - val_loss: 0.0972\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0862 - val_loss: 0.0972\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0860 - val_loss: 0.0976\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0858 - val_loss: 0.0972\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0856 - val_loss: 0.0964\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0854 - val_loss: 0.0968\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0849 - val_loss: 0.0974\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0849 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0847 - val_loss: 0.0980\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0846 - val_loss: 0.0969\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0843 - val_loss: 0.0982\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0841 - val_loss: 0.0971\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0841 - val_loss: 0.0979\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0836 - val_loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0833 - val_loss: 0.0976\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0835 - val_loss: 0.0977\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0829 - val_loss: 0.0997\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0829 - val_loss: 0.0987\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0826 - val_loss: 0.0987\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0823 - val_loss: 0.0987\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0822 - val_loss: 0.0990\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0823 - val_loss: 0.0993\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0818 - val_loss: 0.0986\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0817 - val_loss: 0.0982\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0815 - val_loss: 0.1003\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0816 - val_loss: 0.0995\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0811 - val_loss: 0.0993\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0812 - val_loss: 0.1007\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0807 - val_loss: 0.1000\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0805 - val_loss: 0.1008\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 253us/step - loss: 0.0803 - val_loss: 0.1003\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 252us/step - loss: 0.0807 - val_loss: 0.0997\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 252us/step - loss: 0.0807 - val_loss: 0.1004\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0800 - val_loss: 0.1020\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0799 - val_loss: 0.1014\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0799 - val_loss: 0.0994\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0797 - val_loss: 0.1006\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0795 - val_loss: 0.1015\n",
      "Epoch 65/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0796 - val_loss: 0.1003\n",
      "Epoch 66/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0792 - val_loss: 0.1011\n",
      "Epoch 67/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0787 - val_loss: 0.1004\n",
      "Epoch 68/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0793 - val_loss: 0.1013\n",
      "Epoch 69/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0788 - val_loss: 0.1010\n",
      "Epoch 70/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0788 - val_loss: 0.1025\n",
      "Epoch 71/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0785 - val_loss: 0.1017\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00071: early stopping\n",
      "0.3091182938655459\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 5, 50, 0.3)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 17s 367us/step - loss: 0.1194 - val_loss: 0.1088\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.1048 - val_loss: 0.0991\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.1018 - val_loss: 0.0973\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.1000 - val_loss: 0.1009\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0990 - val_loss: 0.0964\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 12s 255us/step - loss: 0.0984 - val_loss: 0.0956\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0971 - val_loss: 0.0955\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0963 - val_loss: 0.0952\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0958 - val_loss: 0.0971\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0955 - val_loss: 0.0995\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0945 - val_loss: 0.0954\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0942 - val_loss: 0.0951\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0940 - val_loss: 0.0966\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0934 - val_loss: 0.0953\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0930 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0926 - val_loss: 0.0954\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0922 - val_loss: 0.0963\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 12s 256us/step - loss: 0.0922 - val_loss: 0.0957\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0919 - val_loss: 0.0980\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0914 - val_loss: 0.0950\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0915 - val_loss: 0.0952\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0908 - val_loss: 0.0949\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0911 - val_loss: 0.0957\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0907 - val_loss: 0.0971\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0905 - val_loss: 0.0956\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0905 - val_loss: 0.0962\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0902 - val_loss: 0.0962\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0901 - val_loss: 0.0964\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0897 - val_loss: 0.0966\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0899 - val_loss: 0.0969\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0901 - val_loss: 0.0971\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0892 - val_loss: 0.0972\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0897 - val_loss: 0.1060\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0905 - val_loss: 0.0965\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0891 - val_loss: 0.0960\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0890 - val_loss: 0.0969\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0887 - val_loss: 0.0966\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0886 - val_loss: 0.0964\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0885 - val_loss: 0.0988\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0885 - val_loss: 0.0974\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0882 - val_loss: 0.0978\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0885 - val_loss: 0.0983\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0883 - val_loss: 0.0977\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0879 - val_loss: 0.0967\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0880 - val_loss: 0.0978\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0876 - val_loss: 0.0979\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0874 - val_loss: 0.0997\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0876 - val_loss: 0.0989\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0874 - val_loss: 0.0986\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0981\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0869 - val_loss: 0.0989\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0976\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0867 - val_loss: 0.0974\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0869 - val_loss: 0.0994\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.0991\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0865 - val_loss: 0.0983\n",
      "Epoch 58/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0865 - val_loss: 0.0982\n",
      "Epoch 59/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0865 - val_loss: 0.0981\n",
      "Epoch 60/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0863 - val_loss: 0.0997\n",
      "Epoch 61/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0862 - val_loss: 0.0998\n",
      "Epoch 62/10000\n",
      "46874/46874 [==============================] - 12s 259us/step - loss: 0.0864 - val_loss: 0.1002\n",
      "Epoch 63/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0862 - val_loss: 0.0991\n",
      "Epoch 64/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0864 - val_loss: 0.0984\n",
      "Epoch 65/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0858 - val_loss: 0.0981\n",
      "Epoch 66/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0856 - val_loss: 0.0986\n",
      "Epoch 67/10000\n",
      "46874/46874 [==============================] - 12s 257us/step - loss: 0.0859 - val_loss: 0.0988\n",
      "Epoch 68/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.0979\n",
      "Epoch 69/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.1003\n",
      "Epoch 70/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0855 - val_loss: 0.0998\n",
      "Epoch 71/10000\n",
      "46874/46874 [==============================] - 12s 258us/step - loss: 0.0857 - val_loss: 0.0986\n",
      "Epoch 72/10000\n",
      "46874/46874 [==============================] - 12s 260us/step - loss: 0.0853 - val_loss: 0.0993\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00072: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 17s 368us/step - loss: 0.1202 - val_loss: 0.1005\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.1033 - val_loss: 0.0989\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.1009 - val_loss: 0.1132\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 254us/step - loss: 0.0996 - val_loss: 0.0977\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0981 - val_loss: 0.0975\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0970 - val_loss: 0.0977\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0966 - val_loss: 0.0970\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0955 - val_loss: 0.0965\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0949 - val_loss: 0.0963\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0947 - val_loss: 0.0963\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0940 - val_loss: 0.0970\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0932 - val_loss: 0.0978\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0933 - val_loss: 0.0983\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0929 - val_loss: 0.0970\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0925 - val_loss: 0.0966\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0922 - val_loss: 0.0997\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0922 - val_loss: 0.0966\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0916 - val_loss: 0.0972\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0914 - val_loss: 0.0975\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0910 - val_loss: 0.0979\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0908 - val_loss: 0.0968\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0906 - val_loss: 0.0985\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0905 - val_loss: 0.0973\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0903 - val_loss: 0.0970\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0898 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0899 - val_loss: 0.0984\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 258us/step - loss: 0.0900 - val_loss: 0.0968\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0896 - val_loss: 0.0973\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0898 - val_loss: 0.0990\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0893 - val_loss: 0.0987\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0892 - val_loss: 0.0984\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0891 - val_loss: 0.0989\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 255us/step - loss: 0.0890 - val_loss: 0.1003\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0885 - val_loss: 0.0986\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0886 - val_loss: 0.0988\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0883 - val_loss: 0.0992\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0884 - val_loss: 0.0998\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0881 - val_loss: 0.0986\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0881 - val_loss: 0.1000\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0877 - val_loss: 0.0985\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0876 - val_loss: 0.0984\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0882 - val_loss: 0.0987\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0871 - val_loss: 0.0992\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0875 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0876 - val_loss: 0.0999\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0872 - val_loss: 0.0999\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0873 - val_loss: 0.1003\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0871 - val_loss: 0.0992\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0873 - val_loss: 0.0999\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0871 - val_loss: 0.1007\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0874 - val_loss: 0.1003\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0868 - val_loss: 0.1002\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0868 - val_loss: 0.1003\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0872 - val_loss: 0.1002\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 256us/step - loss: 0.0867 - val_loss: 0.1001\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 258us/step - loss: 0.0866 - val_loss: 0.1002\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0871 - val_loss: 0.1007\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 257us/step - loss: 0.0866 - val_loss: 0.0996\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 377us/step - loss: 0.1185 - val_loss: 0.1037\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1055 - val_loss: 0.1006\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.1019 - val_loss: 0.1009\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1004 - val_loss: 0.0979\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0986 - val_loss: 0.0963\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0982 - val_loss: 0.0979\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0971 - val_loss: 0.0965\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0962 - val_loss: 0.0980\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0955 - val_loss: 0.0966\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0953 - val_loss: 0.0983\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0949 - val_loss: 0.0966\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0943 - val_loss: 0.0957\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0936 - val_loss: 0.0963\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0931 - val_loss: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0933 - val_loss: 0.0958\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0925 - val_loss: 0.0968\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0925 - val_loss: 0.0966\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0921 - val_loss: 0.0974\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0916 - val_loss: 0.0964\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0914 - val_loss: 0.0959\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0914 - val_loss: 0.0969\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0909 - val_loss: 0.0972\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0908 - val_loss: 0.0971\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0911 - val_loss: 0.0976\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0902 - val_loss: 0.0972\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0904 - val_loss: 0.0998\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0904 - val_loss: 0.0972\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0899 - val_loss: 0.0976\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0897 - val_loss: 0.0974\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0896 - val_loss: 0.0977\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0894 - val_loss: 0.0968\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0890 - val_loss: 0.0982\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0890 - val_loss: 0.0986\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0889 - val_loss: 0.0973\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0888 - val_loss: 0.0983\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0891 - val_loss: 0.0979\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0888 - val_loss: 0.0978\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0983\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0990\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0988\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0885 - val_loss: 0.1007\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0882 - val_loss: 0.0985\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0882 - val_loss: 0.0985\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0882 - val_loss: 0.0983\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0877 - val_loss: 0.0985\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0882 - val_loss: 0.0998\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0876 - val_loss: 0.0995\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0877 - val_loss: 0.0993\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0874 - val_loss: 0.0994\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0874 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.0997\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0873 - val_loss: 0.1001\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0874 - val_loss: 0.0992\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0866 - val_loss: 0.0996\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.1006\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0870 - val_loss: 0.0999\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.0986\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 259us/step - loss: 0.0865 - val_loss: 0.0993\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.1007\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.0988\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0866 - val_loss: 0.0987\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00062: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 377us/step - loss: 0.1191 - val_loss: 0.1030\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.1040 - val_loss: 0.1009\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.1017 - val_loss: 0.0991\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0998 - val_loss: 0.0998\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0982 - val_loss: 0.0977\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0970 - val_loss: 0.0976\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0961 - val_loss: 0.0979\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0953 - val_loss: 0.0985\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0948 - val_loss: 0.0984\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0944 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0940 - val_loss: 0.0973\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0935 - val_loss: 0.0976\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0934 - val_loss: 0.0973\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0932 - val_loss: 0.0993\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0924 - val_loss: 0.0982\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0922 - val_loss: 0.0979\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0917 - val_loss: 0.0976\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0916 - val_loss: 0.1042\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0912 - val_loss: 0.0982\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0910 - val_loss: 0.0973\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0910 - val_loss: 0.0989\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0904 - val_loss: 0.0975\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0902 - val_loss: 0.0979\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0902 - val_loss: 0.0993\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0898 - val_loss: 0.0984\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0901 - val_loss: 0.0987\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0896 - val_loss: 0.0987\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0896 - val_loss: 0.0980\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0898 - val_loss: 0.0981\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0895 - val_loss: 0.0988\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0890 - val_loss: 0.0988\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0980\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0886 - val_loss: 0.0985\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0888 - val_loss: 0.0987\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0881 - val_loss: 0.0998\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0882 - val_loss: 0.0998\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0884 - val_loss: 0.0983\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0878 - val_loss: 0.0993\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0877 - val_loss: 0.0991\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0883 - val_loss: 0.0991\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0878 - val_loss: 0.0990\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0876 - val_loss: 0.0990\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0876 - val_loss: 0.0995\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0871 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0868 - val_loss: 0.1005\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0872 - val_loss: 0.0993\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0869 - val_loss: 0.1005\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0870 - val_loss: 0.0999\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0867 - val_loss: 0.0992\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0866 - val_loss: 0.1004\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0868 - val_loss: 0.1015\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0874 - val_loss: 0.0995\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 262us/step - loss: 0.0864 - val_loss: 0.0995\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0863 - val_loss: 0.1008\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0862 - val_loss: 0.1004\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 260us/step - loss: 0.0860 - val_loss: 0.0997\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0861 - val_loss: 0.1003\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0860 - val_loss: 0.0994\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0858 - val_loss: 0.0997\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 261us/step - loss: 0.0859 - val_loss: 0.0999\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00060: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 18s 383us/step - loss: 0.1167 - val_loss: 0.1031\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.1041 - val_loss: 0.0997\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.1017 - val_loss: 0.0979\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0991 - val_loss: 0.0977\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0980 - val_loss: 0.0965\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0969 - val_loss: 0.0968\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0962 - val_loss: 0.0959\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0951 - val_loss: 0.0990\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0945 - val_loss: 0.0977\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0935 - val_loss: 0.0955\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0938 - val_loss: 0.0959\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0929 - val_loss: 0.0970\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0924 - val_loss: 0.0954\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0924 - val_loss: 0.0962\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0919 - val_loss: 0.0970\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0915 - val_loss: 0.0971\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0915 - val_loss: 0.0963\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0913 - val_loss: 0.0962\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0907 - val_loss: 0.0983\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0906 - val_loss: 0.0977\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0903 - val_loss: 0.0974\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0905 - val_loss: 0.0979\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0904 - val_loss: 0.0984\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0900 - val_loss: 0.0974\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0901 - val_loss: 0.0975\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0894 - val_loss: 0.0981\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0892 - val_loss: 0.0973\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0889 - val_loss: 0.0980\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0891 - val_loss: 0.0985\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0889 - val_loss: 0.0971\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0885 - val_loss: 0.0969\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0887 - val_loss: 0.0984\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0880 - val_loss: 0.0982\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0882 - val_loss: 0.0973\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0885 - val_loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0880 - val_loss: 0.0980\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0881 - val_loss: 0.0974\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0997\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0981\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0875 - val_loss: 0.0984\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0872 - val_loss: 0.0989\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0875 - val_loss: 0.0989\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0869 - val_loss: 0.0983\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0867 - val_loss: 0.0979\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0870 - val_loss: 0.0991\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0867 - val_loss: 0.0983\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0869 - val_loss: 0.0984\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0875 - val_loss: 0.0988\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0868 - val_loss: 0.0988\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0869 - val_loss: 0.0993\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0864 - val_loss: 0.0996\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0865 - val_loss: 0.0990\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0860 - val_loss: 0.0982\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0868 - val_loss: 0.1029\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0881 - val_loss: 0.1004\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0863 - val_loss: 0.0995\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 12s 266us/step - loss: 0.0863 - val_loss: 0.0988\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0861 - val_loss: 0.0979\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0860 - val_loss: 0.0996\n",
      "Epoch 62/10000\n",
      "46875/46875 [==============================] - 12s 265us/step - loss: 0.0859 - val_loss: 0.1007\n",
      "Epoch 63/10000\n",
      "46875/46875 [==============================] - 12s 264us/step - loss: 0.0858 - val_loss: 0.1008\n",
      "Epoch 64/10000\n",
      "46875/46875 [==============================] - 12s 263us/step - loss: 0.0856 - val_loss: 0.0999\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00064: early stopping\n",
      "0.31002641435643463\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 5, 50, 0.5)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=10, last_dense=40, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='relu', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='relu', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='relu', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='relu', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    prod_ = Dense(50, activation='relu', name=\"Dense_\")(prod2)\n",
    "    drop = Dropout(rate=0.3)(prod_)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='relu', name=\"Dense3\")(drop)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46874/46874 [==============================] - 21s 438us/step - loss: 0.1130 - val_loss: 0.1007\n",
      "Epoch 2/10000\n",
      "46874/46874 [==============================] - 14s 293us/step - loss: 0.1022 - val_loss: 0.0998\n",
      "Epoch 3/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0992 - val_loss: 0.0965\n",
      "Epoch 4/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0978 - val_loss: 0.0970\n",
      "Epoch 5/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0962 - val_loss: 0.0962\n",
      "Epoch 6/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0950 - val_loss: 0.0967\n",
      "Epoch 7/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0938 - val_loss: 0.0956\n",
      "Epoch 8/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0934 - val_loss: 0.0957\n",
      "Epoch 9/10000\n",
      "46874/46874 [==============================] - 14s 302us/step - loss: 0.0918 - val_loss: 0.0966\n",
      "Epoch 10/10000\n",
      "46874/46874 [==============================] - 15s 314us/step - loss: 0.0913 - val_loss: 0.0970\n",
      "Epoch 11/10000\n",
      "46874/46874 [==============================] - 15s 314us/step - loss: 0.0902 - val_loss: 0.0956\n",
      "Epoch 12/10000\n",
      "46874/46874 [==============================] - 14s 309us/step - loss: 0.0892 - val_loss: 0.0961\n",
      "Epoch 13/10000\n",
      "46874/46874 [==============================] - 14s 297us/step - loss: 0.0889 - val_loss: 0.0965\n",
      "Epoch 14/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0878 - val_loss: 0.0965\n",
      "Epoch 15/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0870 - val_loss: 0.0970\n",
      "Epoch 16/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0858 - val_loss: 0.0966\n",
      "Epoch 17/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0849 - val_loss: 0.0985\n",
      "Epoch 18/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0839 - val_loss: 0.0973\n",
      "Epoch 19/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0829 - val_loss: 0.0995\n",
      "Epoch 20/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0822 - val_loss: 0.0997\n",
      "Epoch 21/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0814 - val_loss: 0.0996\n",
      "Epoch 22/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0804 - val_loss: 0.0999\n",
      "Epoch 23/10000\n",
      "46874/46874 [==============================] - 14s 298us/step - loss: 0.0798 - val_loss: 0.0997\n",
      "Epoch 24/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0784 - val_loss: 0.0998\n",
      "Epoch 25/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0783 - val_loss: 0.1008\n",
      "Epoch 26/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0769 - val_loss: 0.1011\n",
      "Epoch 27/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0764 - val_loss: 0.1021\n",
      "Epoch 28/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0757 - val_loss: 0.1026\n",
      "Epoch 29/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0750 - val_loss: 0.1031\n",
      "Epoch 30/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0739 - val_loss: 0.1029\n",
      "Epoch 31/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0734 - val_loss: 0.1025\n",
      "Epoch 32/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0730 - val_loss: 0.1028\n",
      "Epoch 33/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0728 - val_loss: 0.1050\n",
      "Epoch 34/10000\n",
      "46874/46874 [==============================] - 14s 294us/step - loss: 0.0717 - val_loss: 0.1067\n",
      "Epoch 35/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0712 - val_loss: 0.1063\n",
      "Epoch 36/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0709 - val_loss: 0.1054\n",
      "Epoch 37/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0706 - val_loss: 0.1079\n",
      "Epoch 38/10000\n",
      "46874/46874 [==============================] - 14s 297us/step - loss: 0.0697 - val_loss: 0.1083\n",
      "Epoch 39/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0692 - val_loss: 0.1047\n",
      "Epoch 40/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0683 - val_loss: 0.1049\n",
      "Epoch 41/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0679 - val_loss: 0.1076\n",
      "Epoch 42/10000\n",
      "46874/46874 [==============================] - 14s 295us/step - loss: 0.0678 - val_loss: 0.1068\n",
      "Epoch 43/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0675 - val_loss: 0.1069\n",
      "Epoch 44/10000\n",
      "46874/46874 [==============================] - 14s 300us/step - loss: 0.0668 - val_loss: 0.1106\n",
      "Epoch 45/10000\n",
      "46874/46874 [==============================] - 14s 296us/step - loss: 0.0661 - val_loss: 0.1136\n",
      "Epoch 46/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0657 - val_loss: 0.1098\n",
      "Epoch 47/10000\n",
      "46874/46874 [==============================] - 14s 292us/step - loss: 0.0655 - val_loss: 0.1094\n",
      "Epoch 48/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0653 - val_loss: 0.1115\n",
      "Epoch 49/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0651 - val_loss: 0.1093\n",
      "Epoch 50/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0646 - val_loss: 0.1135\n",
      "Epoch 51/10000\n",
      "46874/46874 [==============================] - 14s 289us/step - loss: 0.0640 - val_loss: 0.1111\n",
      "Epoch 52/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0635 - val_loss: 0.1118\n",
      "Epoch 53/10000\n",
      "46874/46874 [==============================] - 14s 292us/step - loss: 0.0637 - val_loss: 0.1095\n",
      "Epoch 54/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0632 - val_loss: 0.1111\n",
      "Epoch 55/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0628 - val_loss: 0.1125\n",
      "Epoch 56/10000\n",
      "46874/46874 [==============================] - 14s 291us/step - loss: 0.0628 - val_loss: 0.1132\n",
      "Epoch 57/10000\n",
      "46874/46874 [==============================] - 14s 290us/step - loss: 0.0620 - val_loss: 0.1112\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 423us/step - loss: 0.1153 - val_loss: 0.1026\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.1026 - val_loss: 0.0978\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0995 - val_loss: 0.0989\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0981 - val_loss: 0.0969\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0964 - val_loss: 0.0956\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0950 - val_loss: 0.0955\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0939 - val_loss: 0.0952\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0933 - val_loss: 0.1018\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0925 - val_loss: 0.0949\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0914 - val_loss: 0.0961\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0907 - val_loss: 0.0956\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0895 - val_loss: 0.0949\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0887 - val_loss: 0.0986\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0881 - val_loss: 0.0971\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0869 - val_loss: 0.0992\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0850 - val_loss: 0.0983\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0844 - val_loss: 0.0988\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0838 - val_loss: 0.1012\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0826 - val_loss: 0.1006\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0818 - val_loss: 0.1016\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0814 - val_loss: 0.1009\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0807 - val_loss: 0.1019\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0797 - val_loss: 0.1014\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0786 - val_loss: 0.1049\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0778 - val_loss: 0.1054\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0774 - val_loss: 0.1039\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0764 - val_loss: 0.1043\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0752 - val_loss: 0.1057\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0755 - val_loss: 0.1038\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0736 - val_loss: 0.1057\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0733 - val_loss: 0.1059\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0726 - val_loss: 0.1055\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0721 - val_loss: 0.1106\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0716 - val_loss: 0.1066\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0707 - val_loss: 0.1096\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0702 - val_loss: 0.1090\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0693 - val_loss: 0.1075\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0692 - val_loss: 0.1084\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0687 - val_loss: 0.1094\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0682 - val_loss: 0.1125\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0677 - val_loss: 0.1086\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0671 - val_loss: 0.1146\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0672 - val_loss: 0.1114\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0659 - val_loss: 0.1102\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0656 - val_loss: 0.1106\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0656 - val_loss: 0.1112\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0655 - val_loss: 0.1135\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0653 - val_loss: 0.1121\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0641 - val_loss: 0.1118\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0640 - val_loss: 0.1158\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0636 - val_loss: 0.1140\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0634 - val_loss: 0.1147\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0626 - val_loss: 0.1123\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0628 - val_loss: 0.1143\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0626 - val_loss: 0.1151\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 291us/step - loss: 0.0619 - val_loss: 0.1181\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0615 - val_loss: 0.1145\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0615 - val_loss: 0.1123\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 425us/step - loss: 0.1139 - val_loss: 0.1027\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.1020 - val_loss: 0.0981\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0994 - val_loss: 0.0966\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0980 - val_loss: 0.0967\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0962 - val_loss: 0.0983\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0953 - val_loss: 0.0965\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0938 - val_loss: 0.0960\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0923 - val_loss: 0.0975\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0921 - val_loss: 0.1007\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0907 - val_loss: 0.0969\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0900 - val_loss: 0.0984\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0888 - val_loss: 0.0976\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0875 - val_loss: 0.0993\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0866 - val_loss: 0.0983\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0859 - val_loss: 0.0986\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0848 - val_loss: 0.1003\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0839 - val_loss: 0.0993\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0828 - val_loss: 0.0992\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0818 - val_loss: 0.1002\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0806 - val_loss: 0.1013\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0799 - val_loss: 0.1027\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0793 - val_loss: 0.1020\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0791 - val_loss: 0.1006\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0773 - val_loss: 0.1030\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0768 - val_loss: 0.1042\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0760 - val_loss: 0.1040\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0751 - val_loss: 0.1041\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0740 - val_loss: 0.1051\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0736 - val_loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0735 - val_loss: 0.1061\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0721 - val_loss: 0.1083\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0712 - val_loss: 0.1057\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0708 - val_loss: 0.1093\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0702 - val_loss: 0.1069\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0694 - val_loss: 0.1096\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0688 - val_loss: 0.1098\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0683 - val_loss: 0.1118\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0680 - val_loss: 0.1110\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 292us/step - loss: 0.0669 - val_loss: 0.1107\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0668 - val_loss: 0.1113\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0662 - val_loss: 0.1112\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0660 - val_loss: 0.1097\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0652 - val_loss: 0.1135\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 295us/step - loss: 0.0652 - val_loss: 0.1118\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0648 - val_loss: 0.1126\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0646 - val_loss: 0.1131\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0642 - val_loss: 0.1138\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0643 - val_loss: 0.1135\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0633 - val_loss: 0.1134\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0625 - val_loss: 0.1157\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0623 - val_loss: 0.1150\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0627 - val_loss: 0.1159\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0625 - val_loss: 0.1148\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0616 - val_loss: 0.1156\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0618 - val_loss: 0.1178\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 294us/step - loss: 0.0614 - val_loss: 0.1187\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 293us/step - loss: 0.0611 - val_loss: 0.1121\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 429us/step - loss: 0.1147 - val_loss: 0.1031\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.1020 - val_loss: 0.1005\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0989 - val_loss: 0.1009\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0973 - val_loss: 0.0990\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0962 - val_loss: 0.0997\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0949 - val_loss: 0.0985\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0937 - val_loss: 0.0985\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0928 - val_loss: 0.0981\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0914 - val_loss: 0.0990\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0910 - val_loss: 0.0979\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0900 - val_loss: 0.0977\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0893 - val_loss: 0.0998\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0884 - val_loss: 0.0984\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0872 - val_loss: 0.0997\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0865 - val_loss: 0.0996\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0857 - val_loss: 0.0993\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0844 - val_loss: 0.1010\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0836 - val_loss: 0.1004\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0828 - val_loss: 0.1002\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0819 - val_loss: 0.0999\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0809 - val_loss: 0.1006\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0802 - val_loss: 0.1022\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0796 - val_loss: 0.1040\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0784 - val_loss: 0.1021\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0778 - val_loss: 0.1022\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0767 - val_loss: 0.1039\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0759 - val_loss: 0.1038\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0753 - val_loss: 0.1054\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0744 - val_loss: 0.1053\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 299us/step - loss: 0.0742 - val_loss: 0.1049\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0739 - val_loss: 0.1070\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0725 - val_loss: 0.1078\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0720 - val_loss: 0.1059\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0714 - val_loss: 0.1090\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0708 - val_loss: 0.1070\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0703 - val_loss: 0.1082\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0699 - val_loss: 0.1082\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0688 - val_loss: 0.1098\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0688 - val_loss: 0.1102\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0680 - val_loss: 0.1117\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0677 - val_loss: 0.1090\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0671 - val_loss: 0.1102\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0667 - val_loss: 0.1090\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0664 - val_loss: 0.1102\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0664 - val_loss: 0.1125\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0659 - val_loss: 0.1113\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0649 - val_loss: 0.1129\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0649 - val_loss: 0.1122\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0643 - val_loss: 0.1161\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0641 - val_loss: 0.1126\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0638 - val_loss: 0.1156\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0631 - val_loss: 0.1128\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0633 - val_loss: 0.1164\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 298us/step - loss: 0.0627 - val_loss: 0.1124\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 296us/step - loss: 0.0626 - val_loss: 0.1135\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0617 - val_loss: 0.1143\n",
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0618 - val_loss: 0.1158\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0619 - val_loss: 0.1144\n",
      "Epoch 59/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0614 - val_loss: 0.1139\n",
      "Epoch 60/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0613 - val_loss: 0.1156\n",
      "Epoch 61/10000\n",
      "46875/46875 [==============================] - 14s 297us/step - loss: 0.0613 - val_loss: 0.1160\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00061: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10000\n",
      "46875/46875 [==============================] - 20s 437us/step - loss: 0.1143 - val_loss: 0.1013\n",
      "Epoch 2/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.1023 - val_loss: 0.0979\n",
      "Epoch 3/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 4/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0972 - val_loss: 0.0973\n",
      "Epoch 5/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0960 - val_loss: 0.0980\n",
      "Epoch 6/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0946 - val_loss: 0.0974\n",
      "Epoch 7/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0932 - val_loss: 0.0964\n",
      "Epoch 8/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0921 - val_loss: 0.0958\n",
      "Epoch 9/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0913 - val_loss: 0.0967\n",
      "Epoch 10/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0906 - val_loss: 0.0973\n",
      "Epoch 11/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0894 - val_loss: 0.0990\n",
      "Epoch 12/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0887 - val_loss: 0.0977\n",
      "Epoch 13/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0879 - val_loss: 0.0975\n",
      "Epoch 14/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0867 - val_loss: 0.0969\n",
      "Epoch 15/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0858 - val_loss: 0.0976\n",
      "Epoch 16/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0857 - val_loss: 0.0970\n",
      "Epoch 17/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0844 - val_loss: 0.0993\n",
      "Epoch 18/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0837 - val_loss: 0.0977\n",
      "Epoch 19/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0829 - val_loss: 0.0998\n",
      "Epoch 20/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0818 - val_loss: 0.1000\n",
      "Epoch 21/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0812 - val_loss: 0.1003\n",
      "Epoch 22/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0804 - val_loss: 0.1026\n",
      "Epoch 23/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0792 - val_loss: 0.1016\n",
      "Epoch 24/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0787 - val_loss: 0.1021\n",
      "Epoch 25/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0780 - val_loss: 0.1039\n",
      "Epoch 26/10000\n",
      "46875/46875 [==============================] - 14s 305us/step - loss: 0.0772 - val_loss: 0.1048\n",
      "Epoch 27/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0763 - val_loss: 0.1040\n",
      "Epoch 28/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0759 - val_loss: 0.1023\n",
      "Epoch 29/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0750 - val_loss: 0.1043\n",
      "Epoch 30/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0747 - val_loss: 0.1072\n",
      "Epoch 31/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0735 - val_loss: 0.1051\n",
      "Epoch 32/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0729 - val_loss: 0.1073\n",
      "Epoch 33/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0725 - val_loss: 0.1079\n",
      "Epoch 34/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0718 - val_loss: 0.1077\n",
      "Epoch 35/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0713 - val_loss: 0.1067\n",
      "Epoch 36/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0706 - val_loss: 0.1053\n",
      "Epoch 37/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0701 - val_loss: 0.1092\n",
      "Epoch 38/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0691 - val_loss: 0.1089\n",
      "Epoch 39/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0689 - val_loss: 0.1072\n",
      "Epoch 40/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0683 - val_loss: 0.1094\n",
      "Epoch 41/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0679 - val_loss: 0.1115\n",
      "Epoch 42/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0676 - val_loss: 0.1113\n",
      "Epoch 43/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0673 - val_loss: 0.1110\n",
      "Epoch 44/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0665 - val_loss: 0.1118\n",
      "Epoch 45/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0662 - val_loss: 0.1107\n",
      "Epoch 46/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0658 - val_loss: 0.1098\n",
      "Epoch 47/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0652 - val_loss: 0.1127\n",
      "Epoch 48/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0654 - val_loss: 0.1117\n",
      "Epoch 49/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0647 - val_loss: 0.1139\n",
      "Epoch 50/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0652 - val_loss: 0.1131\n",
      "Epoch 51/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0641 - val_loss: 0.1141\n",
      "Epoch 52/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0639 - val_loss: 0.1158\n",
      "Epoch 53/10000\n",
      "46875/46875 [==============================] - 14s 304us/step - loss: 0.0638 - val_loss: 0.1118\n",
      "Epoch 54/10000\n",
      "46875/46875 [==============================] - 14s 303us/step - loss: 0.0631 - val_loss: 0.1140\n",
      "Epoch 55/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0627 - val_loss: 0.1132\n",
      "Epoch 56/10000\n",
      "46875/46875 [==============================] - 14s 302us/step - loss: 0.0626 - val_loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0625 - val_loss: 0.1128\n",
      "Epoch 58/10000\n",
      "46875/46875 [==============================] - 14s 301us/step - loss: 0.0628 - val_loss: 0.1136\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00058: early stopping\n",
      "0.3100033573517424\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3(80, 80, 8, 100, 0.3)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add README : \n",
    "    * install requirements.txt in venv\n",
    "    * store data in `./data/raw/`\n",
    "    * install graphviz (sudo apt-get ...)\n",
    "    * run notebooks from 01 to ..\n",
    "* Visualize model\n",
    "* Visualize embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check pipe\n",
    "* Add L2 reg\n",
    "* look for text embeddings\n",
    "* preprocess text\n",
    "* build archi\n",
    "* print archi\n",
    "* pretrained emb\n",
    "* tqdm notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content based : no interaction influencer/artist taken into account (no embedding for them)\n",
    "\n",
    "advantage : cold start allowed\n",
    "disadvantage : interesting info lossed\n",
    "\n",
    "==> hybrid recommender system\n",
    "\n",
    "label encoded influencer kind : in production, a category 'Other' can be created to account for potential kinds not present in current dataset.\n",
    "\n",
    "Grid search\n",
    "\n",
    "track info ==> proxy of song ID ==> potential leak for this dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groover",
   "language": "python",
   "name": "groover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
