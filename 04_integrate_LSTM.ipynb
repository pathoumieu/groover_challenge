{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/raw/submission_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pk</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_info</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>influencer_feedback</th>\n",
       "      <th>decision</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>Label</td>\n",
       "      <td>Bonjour, \\nle track surf sur les codes \"austra...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>Radio</td>\n",
       "      <td>Bonjour, merci pour votre envoi. Le morceau n'...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Le morceau est à lui tout seul une succession ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>Channel</td>\n",
       "      <td>Très bonne pop aux airs de Tame Impala et Pond...</td>\n",
       "      <td>['share it on social media', 'add it to a play...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>Media</td>\n",
       "      <td>La production est assurément excellente, mais ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    pk  track_id track_info  band_id  influencer_id influencer_kind  \\\n",
       "0  7312  7312       324   test tim      303            102           Label   \n",
       "1  7313  7313       324   test tim      303            103           Radio   \n",
       "2  7314  7314       324   test tim      303            104      Journalist   \n",
       "3  7315  7315       324   test tim      303            105         Channel   \n",
       "4  7316  7316       324   test tim      303            106           Media   \n",
       "\n",
       "                                 influencer_feedback  \\\n",
       "0  Bonjour, \\nle track surf sur les codes \"austra...   \n",
       "1  Bonjour, merci pour votre envoi. Le morceau n'...   \n",
       "2  Le morceau est à lui tout seul une succession ...   \n",
       "3  Très bonne pop aux airs de Tame Impala et Pond...   \n",
       "4  La production est assurément excellente, mais ...   \n",
       "\n",
       "                                            decision  score  \n",
       "0                     ['give feedback on your tune']    0.0  \n",
       "1                     ['give feedback on your tune']    0.0  \n",
       "2                     ['give feedback on your tune']    0.0  \n",
       "3  ['share it on social media', 'add it to a play...    1.0  \n",
       "4                     ['give feedback on your tune']    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "X = sub.drop(columns=['score', 'influencer_feedback', 'decision'])\n",
    "y = sub.score\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = pd.read_csv('./data/raw/band_content.csv')\n",
    "content = pd.read_csv('./data/raw/influencer_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sub[['id', 'track_id', 'band_id', 'influencer_id', 'influencer_kind', 'score']].merge(\n",
    "    band.drop(columns=['id', 'biography_fr', 'biography_en']),\n",
    "    how='left',\n",
    "    on='band_id',\n",
    ").merge(\n",
    "    content.drop(columns=['id', 'description_fr', 'description_en', 'preferences_fr', 'preferences_en']),\n",
    "    how='left',\n",
    "    on='influencer_id',\n",
    "    suffixes=('_band', '_influencer')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'track_id',\n",
       " 'band_id',\n",
       " 'influencer_id',\n",
       " 'influencer_kind',\n",
       " 'score',\n",
       " 'Acid house_band',\n",
       " 'African music_band',\n",
       " 'Alternative rock_band',\n",
       " 'Ambient_band',\n",
       " 'Blues_band',\n",
       " 'Bossa Nova_band',\n",
       " 'Chill-out_band',\n",
       " 'Classical Music_band',\n",
       " 'Coldwave_band',\n",
       " 'Country_band',\n",
       " 'Dance music_band',\n",
       " 'Dance-pop_band',\n",
       " 'Deep house_band',\n",
       " 'Disco_band',\n",
       " 'Dream Pop_band',\n",
       " 'Dub_band',\n",
       " 'Electro swing_band',\n",
       " 'Electronic rock_band',\n",
       " 'Electronica_band',\n",
       " 'Electropop_band',\n",
       " 'Experimental_band',\n",
       " 'Experimental Jazz_band',\n",
       " 'Experimental rock_band',\n",
       " 'Film Music_band',\n",
       " 'French house_band',\n",
       " 'Funk_band',\n",
       " 'Future house_band',\n",
       " 'Garage rock_band',\n",
       " 'Grime_band',\n",
       " 'Hard rock_band',\n",
       " 'Hip hop_band',\n",
       " 'House music_band',\n",
       " 'Indie folk_band',\n",
       " 'Indie pop_band',\n",
       " 'Indie rock_band',\n",
       " 'Instrumental_band',\n",
       " 'International Pop_band',\n",
       " 'Latin music_band',\n",
       " 'Lo-Fi_band',\n",
       " 'Metal_band',\n",
       " 'Minimal_band',\n",
       " 'Modern Jazz_band',\n",
       " 'New wave_band',\n",
       " 'Noise rock_band',\n",
       " 'Nouvelle Scène_band',\n",
       " 'Nu-disco_band',\n",
       " 'Pop rock_band',\n",
       " 'Pop soul_band',\n",
       " 'Post-punk_band',\n",
       " 'Post-rock_band',\n",
       " 'Progressive pop_band',\n",
       " 'Progressive rock_band',\n",
       " 'Psychedelic pop_band',\n",
       " 'Psychedelic rock_band',\n",
       " 'Punk_band',\n",
       " 'R&B_band',\n",
       " 'Rap_band',\n",
       " 'Rap français_band',\n",
       " 'Reggae_band',\n",
       " 'Rock and roll_band',\n",
       " 'Samba_band',\n",
       " 'Singer-songwriter_band',\n",
       " 'Soul_band',\n",
       " 'Surf rock_band',\n",
       " 'Synthpop_band',\n",
       " 'Synthwave_band',\n",
       " 'Techno_band',\n",
       " 'Traditional Music_band',\n",
       " 'Trap_band',\n",
       " 'Trip hop_band',\n",
       " 'Variété Française_band',\n",
       " 'Acid house_influencer',\n",
       " 'African music_influencer',\n",
       " 'Alternative rock_influencer',\n",
       " 'Ambient_influencer',\n",
       " 'Blues_influencer',\n",
       " 'Bossa Nova_influencer',\n",
       " 'Chill-out_influencer',\n",
       " 'Classical Music_influencer',\n",
       " 'Coldwave_influencer',\n",
       " 'Country_influencer',\n",
       " 'Dance music_influencer',\n",
       " 'Dance-pop_influencer',\n",
       " 'Deep house_influencer',\n",
       " 'Disco_influencer',\n",
       " 'Dream Pop_influencer',\n",
       " 'Dub_influencer',\n",
       " 'Electro swing_influencer',\n",
       " 'Electronic rock_influencer',\n",
       " 'Electronica_influencer',\n",
       " 'Electropop_influencer',\n",
       " 'Experimental_influencer',\n",
       " 'Experimental Jazz_influencer',\n",
       " 'Experimental rock_influencer',\n",
       " 'Film Music_influencer',\n",
       " 'French house_influencer',\n",
       " 'Funk_influencer',\n",
       " 'Future house_influencer',\n",
       " 'Garage rock_influencer',\n",
       " 'Grime_influencer',\n",
       " 'Hard rock_influencer',\n",
       " 'Hip hop_influencer',\n",
       " 'House music_influencer',\n",
       " 'Indie folk_influencer',\n",
       " 'Indie pop_influencer',\n",
       " 'Indie rock_influencer',\n",
       " 'Instrumental_influencer',\n",
       " 'International Pop_influencer',\n",
       " 'Latin music_influencer',\n",
       " 'Lo-Fi_influencer',\n",
       " 'Metal_influencer',\n",
       " 'Minimal_influencer',\n",
       " 'Modern Jazz_influencer',\n",
       " 'New wave_influencer',\n",
       " 'Noise rock_influencer',\n",
       " 'Nouvelle Scène_influencer',\n",
       " 'Nu-disco_influencer',\n",
       " 'Pop rock_influencer',\n",
       " 'Pop soul_influencer',\n",
       " 'Post-punk_influencer',\n",
       " 'Post-rock_influencer',\n",
       " 'Progressive pop_influencer',\n",
       " 'Progressive rock_influencer',\n",
       " 'Psychedelic pop_influencer',\n",
       " 'Psychedelic rock_influencer',\n",
       " 'Punk_influencer',\n",
       " 'R&B_influencer',\n",
       " 'Rap_influencer',\n",
       " 'Rap français_influencer',\n",
       " 'Reggae_influencer',\n",
       " 'Rock and roll_influencer',\n",
       " 'Samba_influencer',\n",
       " 'Singer-songwriter_influencer',\n",
       " 'Soul_influencer',\n",
       " 'Surf rock_influencer',\n",
       " 'Synthpop_influencer',\n",
       " 'Synthwave_influencer',\n",
       " 'Techno_influencer',\n",
       " 'Traditional Music_influencer',\n",
       " 'Trap_influencer',\n",
       " 'Trip hop_influencer',\n",
       " 'Variété Française_influencer']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media          35288\n",
       "Radio           9872\n",
       "Label           9155\n",
       "Playlist        8501\n",
       "Journalist      4268\n",
       "Channel         4150\n",
       "Booker          3405\n",
       "Mentor          2288\n",
       "Manager         2094\n",
       "Springboard     2087\n",
       "Publisher       1698\n",
       "Supervisor       572\n",
       "Event            328\n",
       "Name: influencer_kind, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.influencer_kind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['influencer_kind'] = le.fit_transform(dataset['influencer_kind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_band</th>\n",
       "      <th>African music_band</th>\n",
       "      <th>Alternative rock_band</th>\n",
       "      <th>Ambient_band</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_influencer</th>\n",
       "      <th>Soul_influencer</th>\n",
       "      <th>Surf rock_influencer</th>\n",
       "      <th>Synthpop_influencer</th>\n",
       "      <th>Synthwave_influencer</th>\n",
       "      <th>Techno_influencer</th>\n",
       "      <th>Traditional Music_influencer</th>\n",
       "      <th>Trap_influencer</th>\n",
       "      <th>Trip hop_influencer</th>\n",
       "      <th>Variété Française_influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_band  African music_band  Alternative rock_band  Ambient_band  \\\n",
       "0                0                   0                      0             0   \n",
       "1                0                   0                      0             0   \n",
       "2                0                   0                      0             0   \n",
       "3                0                   0                      0             0   \n",
       "4                0                   0                      0             0   \n",
       "\n",
       "   ...  Singer-songwriter_influencer  Soul_influencer  Surf rock_influencer  \\\n",
       "0  ...                             0                0                     0   \n",
       "1  ...                             0                0                     0   \n",
       "2  ...                             0                1                     0   \n",
       "3  ...                             0                0                     1   \n",
       "4  ...                             0                0                     1   \n",
       "\n",
       "   Synthpop_influencer  Synthwave_influencer  Techno_influencer  \\\n",
       "0                    0                     0                  1   \n",
       "1                    0                     0                  0   \n",
       "2                    0                     0                  0   \n",
       "3                    0                     0                  0   \n",
       "4                    0                     0                  0   \n",
       "\n",
       "   Traditional Music_influencer  Trap_influencer  Trip hop_influencer  \\\n",
       "0                             0                0                    1   \n",
       "1                             0                0                    0   \n",
       "2                             0                1                    0   \n",
       "3                             0                0                    0   \n",
       "4                             0                0                    0   \n",
       "\n",
       "   Variété Française_influencer  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_band': 'Variete Francaise_band', 'Variété Française_influencer': 'Variete Francaise_influencer'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose english vs french\n",
    "* remove stop words\n",
    "* tokenize\n",
    "* choose max_len\n",
    "* pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data = dataset.filter(regex='_influencer')\n",
    "b_data = dataset.filter(regex='_band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_influencer')]\n",
    "b_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_band')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=5, last_dense=20, dropout=0.2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense1\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense2\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46874/46874 [==============================] - 2s 43us/step - loss: 0.2356 - val_loss: 0.1667\n",
      "Epoch 2/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1518 - val_loss: 0.1449\n",
      "Epoch 3/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1356 - val_loss: 0.1347\n",
      "Epoch 4/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1276 - val_loss: 0.1331\n",
      "Epoch 5/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1219 - val_loss: 0.1313\n",
      "Epoch 6/10\n",
      "46874/46874 [==============================] - 2s 35us/step - loss: 0.1170 - val_loss: 0.1236\n",
      "Epoch 7/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1145 - val_loss: 0.1162\n",
      "Epoch 8/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1118 - val_loss: 0.1195\n",
      "Epoch 9/10\n",
      "46874/46874 [==============================] - 2s 34us/step - loss: 0.1100 - val_loss: 0.1174\n",
      "Epoch 10/10\n",
      "46874/46874 [==============================] - 2s 37us/step - loss: 0.1078 - val_loss: 0.1132\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 2s 45us/step - loss: 0.2301 - val_loss: 0.1641\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1490 - val_loss: 0.1500\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1347 - val_loss: 0.1383\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1278 - val_loss: 0.1321\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1230 - val_loss: 0.1268\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1191 - val_loss: 0.1254\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1163 - val_loss: 0.1239\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1141 - val_loss: 0.1219\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1121 - val_loss: 0.1170\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1100 - val_loss: 0.1183\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 2s 44us/step - loss: 0.2267 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1541 - val_loss: 0.1472\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1385 - val_loss: 0.1412\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 2s 34us/step - loss: 0.1305 - val_loss: 0.1312\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1239 - val_loss: 0.1324\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1204 - val_loss: 0.1294\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 2s 38us/step - loss: 0.1177 - val_loss: 0.1287\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 2s 38us/step - loss: 0.1151 - val_loss: 0.1219\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 2s 38us/step - loss: 0.1121 - val_loss: 0.1223\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 2s 37us/step - loss: 0.1103 - val_loss: 0.1197\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 2s 46us/step - loss: 0.2114 - val_loss: 0.1635\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1491 - val_loss: 0.1443\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1361 - val_loss: 0.1388\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1284 - val_loss: 0.1356\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1249 - val_loss: 0.1304\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1217 - val_loss: 0.1253\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1177 - val_loss: 0.1233\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 2s 37us/step - loss: 0.1148 - val_loss: 0.1233\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 2s 35us/step - loss: 0.1135 - val_loss: 0.1245\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1120 - val_loss: 0.1203\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/10\n",
      "46875/46875 [==============================] - 2s 46us/step - loss: 0.2110 - val_loss: 0.1598\n",
      "Epoch 2/10\n",
      "46875/46875 [==============================] - 2s 37us/step - loss: 0.1465 - val_loss: 0.1416\n",
      "Epoch 3/10\n",
      "46875/46875 [==============================] - 2s 38us/step - loss: 0.1330 - val_loss: 0.1348\n",
      "Epoch 4/10\n",
      "46875/46875 [==============================] - 2s 37us/step - loss: 0.1266 - val_loss: 0.1311\n",
      "Epoch 5/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1207 - val_loss: 0.1293\n",
      "Epoch 6/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1175 - val_loss: 0.1245\n",
      "Epoch 7/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1153 - val_loss: 0.1243\n",
      "Epoch 8/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1132 - val_loss: 0.1221\n",
      "Epoch 9/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1110 - val_loss: 0.1226\n",
      "Epoch 10/10\n",
      "46875/46875 [==============================] - 2s 36us/step - loss: 0.1099 - val_loss: 0.1179\n",
      "0.35810610043049085\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx]], y_valid), \n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx]]), y_test))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=10, last_dense=40, dropout=0.5):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='tanh', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='tanh', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='tanh', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='tanh', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense3\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_x</th>\n",
       "      <th>African music_x</th>\n",
       "      <th>Alternative rock_x</th>\n",
       "      <th>Ambient_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_y</th>\n",
       "      <th>Soul_y</th>\n",
       "      <th>Surf rock_y</th>\n",
       "      <th>Synthpop_y</th>\n",
       "      <th>Synthwave_y</th>\n",
       "      <th>Techno_y</th>\n",
       "      <th>Traditional Music_y</th>\n",
       "      <th>Trap_y</th>\n",
       "      <th>Trip hop_y</th>\n",
       "      <th>Variété Française_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  track_id  band_id  influencer_id  influencer_kind  score  \\\n",
       "0  7312       324      303            102                4    0.0   \n",
       "1  7313       324      303            103               10    0.0   \n",
       "2  7314       324      303            104                3    0.0   \n",
       "3  7315       324      303            105                1    1.0   \n",
       "4  7316       324      303            106                6    0.0   \n",
       "\n",
       "   Acid house_x  African music_x  Alternative rock_x  Ambient_x  ...  \\\n",
       "0             0                0                   0          0  ...   \n",
       "1             0                0                   0          0  ...   \n",
       "2             0                0                   0          0  ...   \n",
       "3             0                0                   0          0  ...   \n",
       "4             0                0                   0          0  ...   \n",
       "\n",
       "   Singer-songwriter_y  Soul_y  Surf rock_y  Synthpop_y  Synthwave_y  \\\n",
       "0                    0       0            0           0            0   \n",
       "1                    0       0            0           0            0   \n",
       "2                    0       1            0           0            0   \n",
       "3                    0       0            1           0            0   \n",
       "4                    0       0            1           0            0   \n",
       "\n",
       "   Techno_y  Traditional Music_y  Trap_y  Trip hop_y  Variété Française_y  \n",
       "0         1                    0       0           1                    0  \n",
       "1         0                    0       0           0                    0  \n",
       "2         0                    0       1           0                    1  \n",
       "3         0                    0       0           0                    0  \n",
       "4         0                    0       0           0                    0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/100\n",
      "46874/46874 [==============================] - 11s 233us/step - loss: 0.1455 - val_loss: 0.1210\n",
      "Epoch 2/100\n",
      "46874/46874 [==============================] - 8s 173us/step - loss: 0.1163 - val_loss: 0.1066\n",
      "Epoch 3/100\n",
      "46874/46874 [==============================] - 8s 181us/step - loss: 0.1088 - val_loss: 0.1011\n",
      "Epoch 4/100\n",
      "46874/46874 [==============================] - 8s 169us/step - loss: 0.1052 - val_loss: 0.0999\n",
      "Epoch 5/100\n",
      "46874/46874 [==============================] - 8s 167us/step - loss: 0.1034 - val_loss: 0.1031\n",
      "Epoch 6/100\n",
      "46874/46874 [==============================] - 8s 177us/step - loss: 0.1019 - val_loss: 0.0984\n",
      "Epoch 7/100\n",
      "46874/46874 [==============================] - 8s 176us/step - loss: 0.1009 - val_loss: 0.0963\n",
      "Epoch 8/100\n",
      "46874/46874 [==============================] - 8s 174us/step - loss: 0.1006 - val_loss: 0.0991\n",
      "Epoch 9/100\n",
      "46874/46874 [==============================] - 8s 169us/step - loss: 0.1000 - val_loss: 0.0957\n",
      "Epoch 10/100\n",
      "46874/46874 [==============================] - 8s 177us/step - loss: 0.0993 - val_loss: 0.0951\n",
      "Epoch 11/100\n",
      "46874/46874 [==============================] - 8s 168us/step - loss: 0.0989 - val_loss: 0.0936\n",
      "Epoch 12/100\n",
      "46874/46874 [==============================] - 8s 174us/step - loss: 0.0984 - val_loss: 0.0939\n",
      "Epoch 13/100\n",
      "46874/46874 [==============================] - 8s 173us/step - loss: 0.0982 - val_loss: 0.0945\n",
      "Epoch 14/100\n",
      "46874/46874 [==============================] - 9s 182us/step - loss: 0.0979 - val_loss: 0.0946\n",
      "Epoch 15/100\n",
      "46874/46874 [==============================] - 8s 172us/step - loss: 0.0975 - val_loss: 0.0929\n",
      "Epoch 16/100\n",
      "46874/46874 [==============================] - 8s 172us/step - loss: 0.0972 - val_loss: 0.0940\n",
      "Epoch 17/100\n",
      "46874/46874 [==============================] - 8s 166us/step - loss: 0.0971 - val_loss: 0.0933\n",
      "Epoch 18/100\n",
      "46874/46874 [==============================] - 8s 167us/step - loss: 0.0967 - val_loss: 0.0928\n",
      "Epoch 19/100\n",
      "46874/46874 [==============================] - 8s 174us/step - loss: 0.0964 - val_loss: 0.0924\n",
      "Epoch 20/100\n",
      "46874/46874 [==============================] - 8s 172us/step - loss: 0.0964 - val_loss: 0.0949\n",
      "Epoch 21/100\n",
      "46874/46874 [==============================] - 8s 174us/step - loss: 0.0962 - val_loss: 0.0924\n",
      "Epoch 22/100\n",
      "46874/46874 [==============================] - 8s 172us/step - loss: 0.0960 - val_loss: 0.0946\n",
      "Epoch 23/100\n",
      "46874/46874 [==============================] - 8s 171us/step - loss: 0.0957 - val_loss: 0.0918\n",
      "Epoch 24/100\n",
      "46874/46874 [==============================] - 8s 169us/step - loss: 0.0956 - val_loss: 0.0929\n",
      "Epoch 25/100\n",
      "46874/46874 [==============================] - 8s 170us/step - loss: 0.0953 - val_loss: 0.0916\n",
      "Epoch 26/100\n",
      "46874/46874 [==============================] - 8s 167us/step - loss: 0.0952 - val_loss: 0.0913\n",
      "Epoch 27/100\n",
      "46874/46874 [==============================] - 8s 165us/step - loss: 0.0951 - val_loss: 0.0915\n",
      "Epoch 28/100\n",
      "46874/46874 [==============================] - 8s 168us/step - loss: 0.0951 - val_loss: 0.0918\n",
      "Epoch 29/100\n",
      "46874/46874 [==============================] - 8s 167us/step - loss: 0.0948 - val_loss: 0.0912\n",
      "Epoch 30/100\n",
      "46874/46874 [==============================] - 8s 165us/step - loss: 0.0949 - val_loss: 0.0912\n",
      "Epoch 31/100\n",
      "46874/46874 [==============================] - 8s 166us/step - loss: 0.0948 - val_loss: 0.0914\n",
      "Epoch 32/100\n",
      "46874/46874 [==============================] - 8s 171us/step - loss: 0.0946 - val_loss: 0.0917\n",
      "Epoch 33/100\n",
      "46874/46874 [==============================] - 8s 165us/step - loss: 0.0945 - val_loss: 0.0925\n",
      "Epoch 34/100\n",
      "46874/46874 [==============================] - 8s 169us/step - loss: 0.0945 - val_loss: 0.0916\n",
      "Epoch 35/100\n",
      "46874/46874 [==============================] - 8s 165us/step - loss: 0.0944 - val_loss: 0.0927\n",
      "Epoch 36/100\n",
      "46874/46874 [==============================] - 8s 169us/step - loss: 0.0942 - val_loss: 0.0910\n",
      "Epoch 37/100\n",
      "46874/46874 [==============================] - 8s 162us/step - loss: 0.0942 - val_loss: 0.0922\n",
      "Epoch 38/100\n",
      "46874/46874 [==============================] - 8s 171us/step - loss: 0.0939 - val_loss: 0.0918\n",
      "Epoch 39/100\n",
      "46874/46874 [==============================] - 8s 168us/step - loss: 0.0937 - val_loss: 0.0905\n",
      "Epoch 40/100\n",
      "46874/46874 [==============================] - 8s 168us/step - loss: 0.0939 - val_loss: 0.0910\n",
      "Epoch 41/100\n",
      "46874/46874 [==============================] - 8s 176us/step - loss: 0.0938 - val_loss: 0.0917\n",
      "Epoch 42/100\n",
      "46874/46874 [==============================] - 8s 176us/step - loss: 0.0938 - val_loss: 0.0914\n",
      "Epoch 43/100\n",
      "46874/46874 [==============================] - 8s 176us/step - loss: 0.0935 - val_loss: 0.0917\n",
      "Epoch 44/100\n",
      "46874/46874 [==============================] - 8s 179us/step - loss: 0.0934 - val_loss: 0.0918\n",
      "Epoch 45/100\n",
      "46874/46874 [==============================] - 8s 178us/step - loss: 0.0936 - val_loss: 0.0908\n",
      "Epoch 46/100\n",
      "46874/46874 [==============================] - 8s 180us/step - loss: 0.0934 - val_loss: 0.0913\n",
      "Epoch 47/100\n",
      "46874/46874 [==============================] - 8s 176us/step - loss: 0.0934 - val_loss: 0.0907\n",
      "Epoch 48/100\n",
      "46874/46874 [==============================] - 8s 173us/step - loss: 0.0933 - val_loss: 0.0907\n",
      "Epoch 49/100\n",
      "46874/46874 [==============================] - 8s 172us/step - loss: 0.0931 - val_loss: 0.0911\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00049: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/100\n",
      "46875/46875 [==============================] - 11s 228us/step - loss: 0.1438 - val_loss: 0.1173\n",
      "Epoch 2/100\n",
      "46875/46875 [==============================] - 8s 170us/step - loss: 0.1168 - val_loss: 0.1095\n",
      "Epoch 3/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.1091 - val_loss: 0.1025\n",
      "Epoch 4/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.1057 - val_loss: 0.1056\n",
      "Epoch 5/100\n",
      "46875/46875 [==============================] - 8s 178us/step - loss: 0.1036 - val_loss: 0.0998\n",
      "Epoch 6/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.1021 - val_loss: 0.0980\n",
      "Epoch 7/100\n",
      "46875/46875 [==============================] - 8s 174us/step - loss: 0.1012 - val_loss: 0.0986\n",
      "Epoch 8/100\n",
      "46875/46875 [==============================] - 8s 172us/step - loss: 0.1006 - val_loss: 0.0969\n",
      "Epoch 9/100\n",
      "46875/46875 [==============================] - 8s 173us/step - loss: 0.0999 - val_loss: 0.0980\n",
      "Epoch 10/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.0997 - val_loss: 0.0964\n",
      "Epoch 11/100\n",
      "46875/46875 [==============================] - 9s 183us/step - loss: 0.0992 - val_loss: 0.0959\n",
      "Epoch 12/100\n",
      "46875/46875 [==============================] - 8s 167us/step - loss: 0.0989 - val_loss: 0.0965\n",
      "Epoch 13/100\n",
      "46875/46875 [==============================] - 8s 170us/step - loss: 0.0984 - val_loss: 0.0983\n",
      "Epoch 14/100\n",
      "46875/46875 [==============================] - 8s 161us/step - loss: 0.0983 - val_loss: 0.0953\n",
      "Epoch 15/100\n",
      "46875/46875 [==============================] - 8s 173us/step - loss: 0.0977 - val_loss: 0.0981\n",
      "Epoch 16/100\n",
      "46875/46875 [==============================] - 8s 180us/step - loss: 0.0980 - val_loss: 0.0971\n",
      "Epoch 17/100\n",
      "46875/46875 [==============================] - 8s 167us/step - loss: 0.0974 - val_loss: 0.0958\n",
      "Epoch 18/100\n",
      "46875/46875 [==============================] - 8s 174us/step - loss: 0.0973 - val_loss: 0.0950\n",
      "Epoch 19/100\n",
      "46875/46875 [==============================] - 8s 173us/step - loss: 0.0970 - val_loss: 0.0950\n",
      "Epoch 20/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0968 - val_loss: 0.0950\n",
      "Epoch 21/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0966 - val_loss: 0.0947\n",
      "Epoch 22/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.0967 - val_loss: 0.0942\n",
      "Epoch 23/100\n",
      "46875/46875 [==============================] - 8s 180us/step - loss: 0.0962 - val_loss: 0.0944\n",
      "Epoch 24/100\n",
      "46875/46875 [==============================] - 8s 170us/step - loss: 0.0963 - val_loss: 0.0941\n",
      "Epoch 25/100\n",
      "46875/46875 [==============================] - 8s 163us/step - loss: 0.0960 - val_loss: 0.0949\n",
      "Epoch 26/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.0963 - val_loss: 0.0940\n",
      "Epoch 27/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.0959 - val_loss: 0.0939\n",
      "Epoch 28/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.0956 - val_loss: 0.0946\n",
      "Epoch 29/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.0957 - val_loss: 0.0974\n",
      "Epoch 30/100\n",
      "46875/46875 [==============================] - 8s 173us/step - loss: 0.0954 - val_loss: 0.0947\n",
      "Epoch 31/100\n",
      "46875/46875 [==============================] - 8s 169us/step - loss: 0.0956 - val_loss: 0.0942\n",
      "Epoch 32/100\n",
      "46875/46875 [==============================] - 8s 168us/step - loss: 0.0953 - val_loss: 0.0939\n",
      "Epoch 33/100\n",
      "46875/46875 [==============================] - 8s 168us/step - loss: 0.0954 - val_loss: 0.0938\n",
      "Epoch 34/100\n",
      "46875/46875 [==============================] - 8s 168us/step - loss: 0.0950 - val_loss: 0.0937\n",
      "Epoch 35/100\n",
      "46875/46875 [==============================] - 8s 177us/step - loss: 0.0952 - val_loss: 0.0935\n",
      "Epoch 36/100\n",
      "46875/46875 [==============================] - 8s 175us/step - loss: 0.0950 - val_loss: 0.0941\n",
      "Epoch 37/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.0950 - val_loss: 0.0944\n",
      "Epoch 38/100\n",
      "46875/46875 [==============================] - 8s 171us/step - loss: 0.0950 - val_loss: 0.0947\n",
      "Epoch 39/100\n",
      "46875/46875 [==============================] - 8s 170us/step - loss: 0.0948 - val_loss: 0.0939\n",
      "Epoch 40/100\n",
      "46875/46875 [==============================] - 8s 169us/step - loss: 0.0948 - val_loss: 0.0941\n",
      "Epoch 41/100\n",
      "46875/46875 [==============================] - 8s 169us/step - loss: 0.0945 - val_loss: 0.0945\n",
      "Epoch 42/100\n",
      "46875/46875 [==============================] - 8s 170us/step - loss: 0.0946 - val_loss: 0.0940\n",
      "Epoch 43/100\n",
      "46875/46875 [==============================] - 8s 172us/step - loss: 0.0944 - val_loss: 0.0937\n",
      "Epoch 44/100\n",
      "46875/46875 [==============================] - 8s 162us/step - loss: 0.0944 - val_loss: 0.0936\n",
      "Epoch 45/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0946 - val_loss: 0.0945\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00045: early stopping\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/100\n",
      "46875/46875 [==============================] - 12s 258us/step - loss: 0.1437 - val_loss: 0.1182\n",
      "Epoch 2/100\n",
      "46875/46875 [==============================] - 8s 172us/step - loss: 0.1180 - val_loss: 0.1124\n",
      "Epoch 3/100\n",
      "46875/46875 [==============================] - 8s 169us/step - loss: 0.1110 - val_loss: 0.1067\n",
      "Epoch 4/100\n",
      "46875/46875 [==============================] - 8s 178us/step - loss: 0.1076 - val_loss: 0.1022\n",
      "Epoch 5/100\n",
      "46875/46875 [==============================] - 9s 194us/step - loss: 0.1052 - val_loss: 0.1038\n",
      "Epoch 6/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.1042 - val_loss: 0.1007\n",
      "Epoch 7/100\n",
      "46875/46875 [==============================] - 9s 189us/step - loss: 0.1032 - val_loss: 0.1008\n",
      "Epoch 8/100\n",
      "46875/46875 [==============================] - 9s 182us/step - loss: 0.1027 - val_loss: 0.0995\n",
      "Epoch 9/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.1022 - val_loss: 0.0999\n",
      "Epoch 10/100\n",
      "46875/46875 [==============================] - 9s 182us/step - loss: 0.1016 - val_loss: 0.0994\n",
      "Epoch 11/100\n",
      "46875/46875 [==============================] - 8s 180us/step - loss: 0.1015 - val_loss: 0.0981\n",
      "Epoch 12/100\n",
      "46875/46875 [==============================] - 8s 181us/step - loss: 0.1008 - val_loss: 0.0983\n",
      "Epoch 13/100\n",
      "46875/46875 [==============================] - 8s 178us/step - loss: 0.1006 - val_loss: 0.0990\n",
      "Epoch 14/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.1004 - val_loss: 0.0976\n",
      "Epoch 15/100\n",
      "46875/46875 [==============================] - 8s 180us/step - loss: 0.1001 - val_loss: 0.0976\n",
      "Epoch 16/100\n",
      "46875/46875 [==============================] - 9s 182us/step - loss: 0.0999 - val_loss: 0.0968\n",
      "Epoch 17/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.0995 - val_loss: 0.0987\n",
      "Epoch 18/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.0994 - val_loss: 0.0965\n",
      "Epoch 19/100\n",
      "46875/46875 [==============================] - 8s 175us/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 20/100\n",
      "46875/46875 [==============================] - 8s 175us/step - loss: 0.0990 - val_loss: 0.0967\n",
      "Epoch 21/100\n",
      "46875/46875 [==============================] - 8s 179us/step - loss: 0.0987 - val_loss: 0.0966\n",
      "Epoch 22/100\n",
      "46875/46875 [==============================] - 9s 193us/step - loss: 0.0985 - val_loss: 0.0963\n",
      "Epoch 23/100\n",
      "46875/46875 [==============================] - 9s 184us/step - loss: 0.0984 - val_loss: 0.0972\n",
      "Epoch 24/100\n",
      "46875/46875 [==============================] - 9s 183us/step - loss: 0.0983 - val_loss: 0.0966\n",
      "Epoch 25/100\n",
      "46875/46875 [==============================] - 9s 183us/step - loss: 0.0982 - val_loss: 0.0967\n",
      "Epoch 26/100\n",
      "46875/46875 [==============================] - 9s 192us/step - loss: 0.0980 - val_loss: 0.0967\n",
      "Epoch 27/100\n",
      "46875/46875 [==============================] - 8s 169us/step - loss: 0.0979 - val_loss: 0.0975\n",
      "Epoch 28/100\n",
      "46875/46875 [==============================] - 8s 167us/step - loss: 0.0978 - val_loss: 0.0958\n",
      "Epoch 29/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0976 - val_loss: 0.0959\n",
      "Epoch 30/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0975 - val_loss: 0.0964\n",
      "Epoch 31/100\n",
      "46875/46875 [==============================] - 8s 167us/step - loss: 0.0974 - val_loss: 0.0959\n",
      "Epoch 32/100\n",
      "46875/46875 [==============================] - 8s 165us/step - loss: 0.0973 - val_loss: 0.0962\n",
      "Epoch 33/100\n",
      "46875/46875 [==============================] - 8s 166us/step - loss: 0.0972 - val_loss: 0.0977\n",
      "Epoch 34/100\n",
      "46875/46875 [==============================] - 8s 167us/step - loss: 0.0970 - val_loss: 0.0956\n",
      "Epoch 35/100\n",
      "46784/46875 [============================>.] - ETA: 0s - loss: 0.0970"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 5]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 5]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 5]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check pipe\n",
    "* Add L2 reg\n",
    "* look for text embeddings\n",
    "* preprocess text\n",
    "* build archi\n",
    "* print archi\n",
    "* pretrained emb\n",
    "* tqdm notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content based : no interaction influencer/artist taken into account (no embedding for them)\n",
    "\n",
    "advantage : cold start allowed\n",
    "disadvantage : interesting info lossed\n",
    "\n",
    "==> hybrid recommender system\n",
    "\n",
    "label encoded influencer kind : in production, a category 'Other' can be created to account for potential kinds not present in current dataset.\n",
    "\n",
    "Grid search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groover",
   "language": "python",
   "name": "groover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
