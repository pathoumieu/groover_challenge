{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/raw/submission_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pk</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_info</th>\n",
       "      <th>band_id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>influencer_feedback</th>\n",
       "      <th>decision</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7312</td>\n",
       "      <td>7312</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>Label</td>\n",
       "      <td>Bonjour, \\nle track surf sur les codes \"austra...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7313</td>\n",
       "      <td>7313</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>103</td>\n",
       "      <td>Radio</td>\n",
       "      <td>Bonjour, merci pour votre envoi. Le morceau n'...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7314</td>\n",
       "      <td>7314</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>104</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Le morceau est à lui tout seul une succession ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7315</td>\n",
       "      <td>7315</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>105</td>\n",
       "      <td>Channel</td>\n",
       "      <td>Très bonne pop aux airs de Tame Impala et Pond...</td>\n",
       "      <td>['share it on social media', 'add it to a play...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7316</td>\n",
       "      <td>7316</td>\n",
       "      <td>324</td>\n",
       "      <td>test tim</td>\n",
       "      <td>303</td>\n",
       "      <td>106</td>\n",
       "      <td>Media</td>\n",
       "      <td>La production est assurément excellente, mais ...</td>\n",
       "      <td>['give feedback on your tune']</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    pk  track_id track_info  band_id  influencer_id influencer_kind  \\\n",
       "0  7312  7312       324   test tim      303            102           Label   \n",
       "1  7313  7313       324   test tim      303            103           Radio   \n",
       "2  7314  7314       324   test tim      303            104      Journalist   \n",
       "3  7315  7315       324   test tim      303            105         Channel   \n",
       "4  7316  7316       324   test tim      303            106           Media   \n",
       "\n",
       "                                 influencer_feedback  \\\n",
       "0  Bonjour, \\nle track surf sur les codes \"austra...   \n",
       "1  Bonjour, merci pour votre envoi. Le morceau n'...   \n",
       "2  Le morceau est à lui tout seul une succession ...   \n",
       "3  Très bonne pop aux airs de Tame Impala et Pond...   \n",
       "4  La production est assurément excellente, mais ...   \n",
       "\n",
       "                                            decision  score  \n",
       "0                     ['give feedback on your tune']    0.0  \n",
       "1                     ['give feedback on your tune']    0.0  \n",
       "2                     ['give feedback on your tune']    0.0  \n",
       "3  ['share it on social media', 'add it to a play...    1.0  \n",
       "4                     ['give feedback on your tune']    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "X = sub.drop(columns=['score', 'influencer_feedback', 'decision'])\n",
    "y = sub.score\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = pd.read_csv('./data/raw/band_content.csv')\n",
    "content = pd.read_csv('./data/raw/influencer_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>description_fr</th>\n",
       "      <th>description_en</th>\n",
       "      <th>preferences_fr</th>\n",
       "      <th>preferences_en</th>\n",
       "      <th>Acid house</th>\n",
       "      <th>African music</th>\n",
       "      <th>Alternative rock</th>\n",
       "      <th>Ambient</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter</th>\n",
       "      <th>Soul</th>\n",
       "      <th>Surf rock</th>\n",
       "      <th>Synthpop</th>\n",
       "      <th>Synthwave</th>\n",
       "      <th>Techno</th>\n",
       "      <th>Traditional Music</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Trip hop</th>\n",
       "      <th>Variété Française</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Musique Comtemporaine et Jazz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>HIGHLIFE is a music publishing company + Indep...</td>\n",
       "      <td>HIGHLIFE Recordings has a wide open philosophy...</td>\n",
       "      <td>Déjà de la maturité</td>\n",
       "      <td>Already mature and original</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>Nectar est une émission radio musicale et hebd...</td>\n",
       "      <td>Nectar is a weekly music radio program about f...</td>\n",
       "      <td>Folk</td>\n",
       "      <td>Folk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>Ecrit pour Konbini et Noisey (Vice). Défricheu...</td>\n",
       "      <td>Writes for Konbini and Noisey (Vice). Rap, Hip...</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  influencer_id                                     description_fr  \\\n",
       "0   96             96  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1   97             97  Underdog Records is a french alternative label...   \n",
       "2  102            102  HIGHLIFE is a music publishing company + Indep...   \n",
       "3  103            103  Nectar est une émission radio musicale et hebd...   \n",
       "4  104            104  Ecrit pour Konbini et Noisey (Vice). Défricheu...   \n",
       "\n",
       "                                      description_en  \\\n",
       "0  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1  Underdog Records is a french alternative label...   \n",
       "2  HIGHLIFE Recordings has a wide open philosophy...   \n",
       "3  Nectar is a weekly music radio program about f...   \n",
       "4  Writes for Konbini and Noisey (Vice). Rap, Hip...   \n",
       "\n",
       "                            preferences_fr  \\\n",
       "0            Musique Comtemporaine et Jazz   \n",
       "1  Folk, soul, blues, rock&roll, indie pop   \n",
       "2                      Déjà de la maturité   \n",
       "3                                     Folk   \n",
       "4                                      Rap   \n",
       "\n",
       "                            preferences_en  Acid house  African music  \\\n",
       "0                                      NaN           0              0   \n",
       "1  Folk, soul, blues, rock&roll, indie pop           0              0   \n",
       "2              Already mature and original           0              0   \n",
       "3                                     Folk           0              0   \n",
       "4                                      Rap           0              0   \n",
       "\n",
       "   Alternative rock  Ambient  ...  Singer-songwriter  Soul  Surf rock  \\\n",
       "0                 0        0  ...                  0     0          0   \n",
       "1                 0        0  ...                  1     1          0   \n",
       "2                 0        1  ...                  0     0          0   \n",
       "3                 0        0  ...                  0     0          0   \n",
       "4                 0        0  ...                  0     1          0   \n",
       "\n",
       "   Synthpop  Synthwave  Techno  Traditional Music  Trap  Trip hop  \\\n",
       "0         1          0       1                  0     0         0   \n",
       "1         0          0       0                  0     0         0   \n",
       "2         0          0       1                  0     0         1   \n",
       "3         0          0       0                  0     0         0   \n",
       "4         0          0       0                  0     1         0   \n",
       "\n",
       "   Variété Française  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "influencer_id          0\n",
       "description_fr       219\n",
       "description_en       241\n",
       "preferences_fr       311\n",
       "                    ... \n",
       "Techno                 0\n",
       "Traditional Music      0\n",
       "Trap                   0\n",
       "Trip hop               0\n",
       "Variété Française      0\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6161"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band.biography_fr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sub[['id', 'track_id', 'band_id', 'influencer_id', 'influencer_kind', 'score']].merge(\n",
    "    band.drop(columns=['id', 'biography_fr', 'biography_en']),\n",
    "    how='left',\n",
    "    on='band_id',\n",
    ").merge(\n",
    "    content.drop(columns=['id', 'description_fr', 'description_en', 'preferences_fr', 'preferences_fr']),\n",
    "    how='left',\n",
    "    on='influencer_id',\n",
    "    suffixes=('_band', '_influencer')\n",
    ").drop(columns=['id', 'track_id', 'band_id', 'influencer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_band</th>\n",
       "      <th>African music_band</th>\n",
       "      <th>Alternative rock_band</th>\n",
       "      <th>Ambient_band</th>\n",
       "      <th>Blues_band</th>\n",
       "      <th>Bossa Nova_band</th>\n",
       "      <th>Chill-out_band</th>\n",
       "      <th>Classical Music_band</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_influencer</th>\n",
       "      <th>Soul_influencer</th>\n",
       "      <th>Surf rock_influencer</th>\n",
       "      <th>Synthpop_influencer</th>\n",
       "      <th>Synthwave_influencer</th>\n",
       "      <th>Techno_influencer</th>\n",
       "      <th>Traditional Music_influencer</th>\n",
       "      <th>Trap_influencer</th>\n",
       "      <th>Trip hop_influencer</th>\n",
       "      <th>Variété Française_influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radio</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journalist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Channel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Media</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83701</th>\n",
       "      <td>Journalist</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83702</th>\n",
       "      <td>Manager</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83703</th>\n",
       "      <td>Label</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83704</th>\n",
       "      <td>Journalist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83705</th>\n",
       "      <td>Radio</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83706 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      influencer_kind  score  Acid house_band  African music_band  \\\n",
       "0               Label    0.0                0                   0   \n",
       "1               Radio    0.0                0                   0   \n",
       "2          Journalist    0.0                0                   0   \n",
       "3             Channel    1.0                0                   0   \n",
       "4               Media    0.0                0                   0   \n",
       "...               ...    ...              ...                 ...   \n",
       "83701      Journalist    1.0                0                   0   \n",
       "83702         Manager    0.0                0                   0   \n",
       "83703           Label    0.0                0                   0   \n",
       "83704      Journalist    0.0                0                   0   \n",
       "83705           Radio    0.0                0                   0   \n",
       "\n",
       "       Alternative rock_band  Ambient_band  Blues_band  Bossa Nova_band  \\\n",
       "0                          0             0           0                0   \n",
       "1                          0             0           0                0   \n",
       "2                          0             0           0                0   \n",
       "3                          0             0           0                0   \n",
       "4                          0             0           0                0   \n",
       "...                      ...           ...         ...              ...   \n",
       "83701                      0             0           0                0   \n",
       "83702                      0             0           0                0   \n",
       "83703                      0             0           0                0   \n",
       "83704                      0             0           0                0   \n",
       "83705                      0             0           1                0   \n",
       "\n",
       "       Chill-out_band  Classical Music_band  ...  \\\n",
       "0                   0                     0  ...   \n",
       "1                   0                     0  ...   \n",
       "2                   0                     0  ...   \n",
       "3                   0                     0  ...   \n",
       "4                   0                     0  ...   \n",
       "...               ...                   ...  ...   \n",
       "83701               0                     0  ...   \n",
       "83702               0                     0  ...   \n",
       "83703               0                     0  ...   \n",
       "83704               0                     0  ...   \n",
       "83705               0                     0  ...   \n",
       "\n",
       "       Singer-songwriter_influencer  Soul_influencer  Surf rock_influencer  \\\n",
       "0                                 0                0                     0   \n",
       "1                                 0                0                     0   \n",
       "2                                 0                1                     0   \n",
       "3                                 0                0                     1   \n",
       "4                                 0                0                     1   \n",
       "...                             ...              ...                   ...   \n",
       "83701                             0                0                     0   \n",
       "83702                             0                0                     0   \n",
       "83703                             0                0                     0   \n",
       "83704                             0                0                     0   \n",
       "83705                             1                1                     1   \n",
       "\n",
       "       Synthpop_influencer  Synthwave_influencer  Techno_influencer  \\\n",
       "0                        0                     0                  1   \n",
       "1                        0                     0                  0   \n",
       "2                        0                     0                  0   \n",
       "3                        0                     0                  0   \n",
       "4                        0                     0                  0   \n",
       "...                    ...                   ...                ...   \n",
       "83701                    0                     0                  0   \n",
       "83702                    0                     0                  1   \n",
       "83703                    0                     0                  1   \n",
       "83704                    0                     0                  0   \n",
       "83705                    1                     1                  1   \n",
       "\n",
       "       Traditional Music_influencer  Trap_influencer  Trip hop_influencer  \\\n",
       "0                                 0                0                    1   \n",
       "1                                 0                0                    0   \n",
       "2                                 0                1                    0   \n",
       "3                                 0                0                    0   \n",
       "4                                 0                0                    0   \n",
       "...                             ...              ...                  ...   \n",
       "83701                             0                1                    0   \n",
       "83702                             0                0                    0   \n",
       "83703                             0                0                    0   \n",
       "83704                             0                0                    0   \n",
       "83705                             0                1                    1   \n",
       "\n",
       "       Variété Française_influencer  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 1  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "...                             ...  \n",
       "83701                             1  \n",
       "83702                             0  \n",
       "83703                             0  \n",
       "83704                             0  \n",
       "83705                             1  \n",
       "\n",
       "[83706 rows x 145 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['influencer_kind'] = le.fit_transform(dataset['influencer_kind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencer_kind</th>\n",
       "      <th>score</th>\n",
       "      <th>Acid house_band</th>\n",
       "      <th>African music_band</th>\n",
       "      <th>Alternative rock_band</th>\n",
       "      <th>Ambient_band</th>\n",
       "      <th>Blues_band</th>\n",
       "      <th>Bossa Nova_band</th>\n",
       "      <th>Chill-out_band</th>\n",
       "      <th>Classical Music_band</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter_influencer</th>\n",
       "      <th>Soul_influencer</th>\n",
       "      <th>Surf rock_influencer</th>\n",
       "      <th>Synthpop_influencer</th>\n",
       "      <th>Synthwave_influencer</th>\n",
       "      <th>Techno_influencer</th>\n",
       "      <th>Traditional Music_influencer</th>\n",
       "      <th>Trap_influencer</th>\n",
       "      <th>Trip hop_influencer</th>\n",
       "      <th>Variété Française_influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   influencer_kind  score  Acid house_band  African music_band  \\\n",
       "0                4    0.0                0                   0   \n",
       "1               10    0.0                0                   0   \n",
       "2                3    0.0                0                   0   \n",
       "3                1    1.0                0                   0   \n",
       "4                6    0.0                0                   0   \n",
       "\n",
       "   Alternative rock_band  Ambient_band  Blues_band  Bossa Nova_band  \\\n",
       "0                      0             0           0                0   \n",
       "1                      0             0           0                0   \n",
       "2                      0             0           0                0   \n",
       "3                      0             0           0                0   \n",
       "4                      0             0           0                0   \n",
       "\n",
       "   Chill-out_band  Classical Music_band  ...  Singer-songwriter_influencer  \\\n",
       "0               0                     0  ...                             0   \n",
       "1               0                     0  ...                             0   \n",
       "2               0                     0  ...                             0   \n",
       "3               0                     0  ...                             0   \n",
       "4               0                     0  ...                             0   \n",
       "\n",
       "   Soul_influencer  Surf rock_influencer  Synthpop_influencer  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                1                     0                    0   \n",
       "3                0                     1                    0   \n",
       "4                0                     1                    0   \n",
       "\n",
       "   Synthwave_influencer  Techno_influencer  Traditional Music_influencer  \\\n",
       "0                     0                  1                             0   \n",
       "1                     0                  0                             0   \n",
       "2                     0                  0                             0   \n",
       "3                     0                  0                             0   \n",
       "4                     0                  0                             0   \n",
       "\n",
       "   Trap_influencer  Trip hop_influencer  Variété Française_influencer  \n",
       "0                0                    1                             0  \n",
       "1                0                    0                             0  \n",
       "2                1                    0                             1  \n",
       "3                0                    0                             0  \n",
       "4                0                    0                             0  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_band': 'Variete Francaise_band', 'Variété Française_influencer': 'Variete Francaise_influencer'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose english vs french\n",
    "* remove stop words\n",
    "* tokenize\n",
    "* choose max_len\n",
    "* pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = dataset.sample(frac=1.0)\n",
    "sample = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 27s, sys: 908 ms, total: 6min 28s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "series = sample.preferences_en.fillna('Unknown').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[vec.vector for vec in sequence]for sequence in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already mature and original'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.preferences_en.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(sequence) for sequence in sequences])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/groover/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83706, 31, 96)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>influencer_id</th>\n",
       "      <th>description_fr</th>\n",
       "      <th>description_en</th>\n",
       "      <th>preferences_fr</th>\n",
       "      <th>preferences_en</th>\n",
       "      <th>Acid house</th>\n",
       "      <th>African music</th>\n",
       "      <th>Alternative rock</th>\n",
       "      <th>Ambient</th>\n",
       "      <th>...</th>\n",
       "      <th>Singer-songwriter</th>\n",
       "      <th>Soul</th>\n",
       "      <th>Surf rock</th>\n",
       "      <th>Synthpop</th>\n",
       "      <th>Synthwave</th>\n",
       "      <th>Techno</th>\n",
       "      <th>Traditional Music</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Trip hop</th>\n",
       "      <th>Variété Française</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Ex-BSC NEWS, nouveau magazine culturel franc-t...</td>\n",
       "      <td>Musique Comtemporaine et Jazz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Underdog Records is a french alternative label...</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>Folk, soul, blues, rock&amp;roll, indie pop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>HIGHLIFE is a music publishing company + Indep...</td>\n",
       "      <td>HIGHLIFE Recordings has a wide open philosophy...</td>\n",
       "      <td>Déjà de la maturité</td>\n",
       "      <td>Already mature and original</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>Nectar est une émission radio musicale et hebd...</td>\n",
       "      <td>Nectar is a weekly music radio program about f...</td>\n",
       "      <td>Folk</td>\n",
       "      <td>Folk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>Ecrit pour Konbini et Noisey (Vice). Défricheu...</td>\n",
       "      <td>Writes for Konbini and Noisey (Vice). Rap, Hip...</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  influencer_id                                     description_fr  \\\n",
       "0   96             96  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1   97             97  Underdog Records is a french alternative label...   \n",
       "2  102            102  HIGHLIFE is a music publishing company + Indep...   \n",
       "3  103            103  Nectar est une émission radio musicale et hebd...   \n",
       "4  104            104  Ecrit pour Konbini et Noisey (Vice). Défricheu...   \n",
       "\n",
       "                                      description_en  \\\n",
       "0  Ex-BSC NEWS, nouveau magazine culturel franc-t...   \n",
       "1  Underdog Records is a french alternative label...   \n",
       "2  HIGHLIFE Recordings has a wide open philosophy...   \n",
       "3  Nectar is a weekly music radio program about f...   \n",
       "4  Writes for Konbini and Noisey (Vice). Rap, Hip...   \n",
       "\n",
       "                            preferences_fr  \\\n",
       "0            Musique Comtemporaine et Jazz   \n",
       "1  Folk, soul, blues, rock&roll, indie pop   \n",
       "2                      Déjà de la maturité   \n",
       "3                                     Folk   \n",
       "4                                      Rap   \n",
       "\n",
       "                            preferences_en  Acid house  African music  \\\n",
       "0                                      NaN           0              0   \n",
       "1  Folk, soul, blues, rock&roll, indie pop           0              0   \n",
       "2              Already mature and original           0              0   \n",
       "3                                     Folk           0              0   \n",
       "4                                      Rap           0              0   \n",
       "\n",
       "   Alternative rock  Ambient  ...  Singer-songwriter  Soul  Surf rock  \\\n",
       "0                 0        0  ...                  0     0          0   \n",
       "1                 0        0  ...                  1     1          0   \n",
       "2                 0        1  ...                  0     0          0   \n",
       "3                 0        0  ...                  0     0          0   \n",
       "4                 0        0  ...                  0     1          0   \n",
       "\n",
       "   Synthpop  Synthwave  Techno  Traditional Music  Trap  Trip hop  \\\n",
       "0         1          0       1                  0     0         0   \n",
       "1         0          0       0                  0     0         0   \n",
       "2         0          0       1                  0     0         1   \n",
       "3         0          0       0                  0     0         0   \n",
       "4         0          0       0                  0     1         0   \n",
       "\n",
       "   Variété Française  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.1 s, sys: 16 ms, total: 8.12 s\n",
      "Wall time: 8.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "series = content.description_en.fillna('Unknown').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[vec.vector for vec in sequence]for sequence in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already mature and original'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.preferences_en.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(sequence) for sequence in sequences])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat biography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 0 ns, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "series = band.biography_en.fillna('Unknown').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[vec.vector for vec in sequence]for sequence in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already mature and original'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.preferences_en.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(sequence) for sequence in sequences])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data = dataset.filter(regex='_influencer')\n",
    "b_data = dataset.filter(regex='_band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_influencer')]\n",
    "b_data_idx = [dataset.drop(columns='score').columns.get_loc(c) for c in dataset.filter(regex='_band')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_model(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=5, lstm=10, last_dense=20, dropout=0.2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='tanh', name=\"Influencer-Embedding\")(influencer_input)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Influencer preferences_en LSTM embedding\n",
    "    influencer_preferences_input = Input(shape=[31, 96], name=\"Influencer-Sequence-Input\")\n",
    "    sequence_emb = LSTM(lstm)(influencer_preferences_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, \n",
    "                                                Flatten(name='Flatten')(influencer_kind_emb),\n",
    "                                                sequence_emb])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='tanh', name=\"Band-Embedding\")(band_input)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense1\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense2\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input, influencer_preferences_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0, ..., 0, 1, 0],\n",
       "       [10, 0, 0, ..., 0, 0, 0],\n",
       "       [3, 0, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [3, 0, 0, ..., 0, 0, 0],\n",
       "       [10, 0, 0, ..., 1, 1, 1]], dtype=object)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int64'),\n",
       " dtype('float64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('O'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64')]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    dataset.drop(columns='score').rename(\n",
    "        {'Variété Française_band': 'Variete Francaise_band', 'Variété Française_influencer': 'Variete Francaise_influencer'},\n",
    "        axis=1\n",
    "    ).values,\n",
    "    dataset.score.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46874 samples, validate on 20090 samples\n",
      "Epoch 1/5\n",
      "46874/46874 [==============================] - 28s 597us/step - loss: 0.1260 - val_loss: 0.0977\n",
      "Epoch 2/5\n",
      "46874/46874 [==============================] - 26s 553us/step - loss: 0.0996 - val_loss: 0.0931\n",
      "Epoch 3/5\n",
      "46874/46874 [==============================] - 26s 554us/step - loss: 0.0964 - val_loss: 0.0917\n",
      "Epoch 4/5\n",
      "46874/46874 [==============================] - 26s 556us/step - loss: 0.0954 - val_loss: 0.0916\n",
      "Epoch 5/5\n",
      "46874/46874 [==============================] - 26s 554us/step - loss: 0.0947 - val_loss: 0.0925\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/5\n",
      "46875/46875 [==============================] - 28s 604us/step - loss: 0.1275 - val_loss: 0.1004\n",
      "Epoch 2/5\n",
      "46875/46875 [==============================] - 26s 562us/step - loss: 0.1024 - val_loss: 0.0994\n",
      "Epoch 3/5\n",
      "46875/46875 [==============================] - 26s 560us/step - loss: 0.0991 - val_loss: 0.0952\n",
      "Epoch 4/5\n",
      "46875/46875 [==============================] - 26s 560us/step - loss: 0.0974 - val_loss: 0.0952\n",
      "Epoch 5/5\n",
      "46875/46875 [==============================] - 26s 561us/step - loss: 0.0965 - val_loss: 0.0942\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/5\n",
      "46875/46875 [==============================] - 28s 604us/step - loss: 0.1305 - val_loss: 0.1062\n",
      "Epoch 2/5\n",
      "46875/46875 [==============================] - 26s 554us/step - loss: 0.1063 - val_loss: 0.1021\n",
      "Epoch 3/5\n",
      "46875/46875 [==============================] - 26s 554us/step - loss: 0.1027 - val_loss: 0.0992\n",
      "Epoch 4/5\n",
      "46875/46875 [==============================] - 26s 555us/step - loss: 0.1007 - val_loss: 0.0995\n",
      "Epoch 5/5\n",
      "46875/46875 [==============================] - 26s 559us/step - loss: 0.0999 - val_loss: 0.0995\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/5\n",
      "46875/46875 [==============================] - 28s 606us/step - loss: 0.1308 - val_loss: 0.1089\n",
      "Epoch 2/5\n",
      "46875/46875 [==============================] - 26s 555us/step - loss: 0.1071 - val_loss: 0.1008\n",
      "Epoch 3/5\n",
      "46875/46875 [==============================] - 26s 556us/step - loss: 0.1031 - val_loss: 0.0989\n",
      "Epoch 4/5\n",
      "46875/46875 [==============================] - 26s 555us/step - loss: 0.1011 - val_loss: 0.0986\n",
      "Epoch 5/5\n",
      "46875/46875 [==============================] - 26s 558us/step - loss: 0.1003 - val_loss: 0.0971\n",
      "Train on 46875 samples, validate on 20090 samples\n",
      "Epoch 1/5\n",
      "46875/46875 [==============================] - 29s 623us/step - loss: 0.1310 - val_loss: 0.1022\n",
      "Epoch 2/5\n",
      "46875/46875 [==============================] - 27s 578us/step - loss: 0.1039 - val_loss: 0.0993\n",
      "Epoch 3/5\n",
      "46875/46875 [==============================] - 26s 553us/step - loss: 0.1006 - val_loss: 0.0986\n",
      "Epoch 4/5\n",
      "46875/46875 [==============================] - 27s 570us/step - loss: 0.0992 - val_loss: 0.0978\n",
      "Epoch 5/5\n",
      "46875/46875 [==============================] - 26s 564us/step - loss: 0.0983 - val_loss: 0.0971\n",
      "0.3245228152861984\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    docs_train, docs_test = padded_docs[train_index], padded_docs[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    docs_train, docs_valid = docs_train[tridx], docs_train[vidx]\n",
    "    \n",
    "    model = build_hybrid_model()\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0], docs_train], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0], docs_valid], y_valid), \n",
    "              batch_size=64,\n",
    "              epochs=5,\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(model.predict([X_test[:, i_data_idx], \n",
    "                                                          X_test[:, b_data_idx],\n",
    "                                                          X_test[:, 0],\n",
    "                                                          docs_test]), y_test))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/10\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.1139 - val_loss: 0.0982\n",
      "Epoch 2/10\n",
      "60267/60267 [==============================] - 4s 66us/step - loss: 0.0999 - val_loss: 0.0960\n",
      "Epoch 3/10\n",
      "60267/60267 [==============================] - 4s 65us/step - loss: 0.0967 - val_loss: 0.0973\n",
      "Epoch 4/10\n",
      "60267/60267 [==============================] - 4s 66us/step - loss: 0.0950 - val_loss: 0.0942\n",
      "Epoch 5/10\n",
      "60267/60267 [==============================] - 4s 68us/step - loss: 0.0936 - val_loss: 0.0942\n",
      "Epoch 6/10\n",
      "60267/60267 [==============================] - 5s 75us/step - loss: 0.0925 - val_loss: 0.0945\n",
      "Epoch 7/10\n",
      "60267/60267 [==============================] - 4s 71us/step - loss: 0.0917 - val_loss: 0.0932\n",
      "Epoch 8/10\n",
      "60267/60267 [==============================] - 4s 67us/step - loss: 0.0910 - val_loss: 0.0921\n",
      "Epoch 9/10\n",
      "60267/60267 [==============================] - 4s 67us/step - loss: 0.0907 - val_loss: 0.0938\n",
      "Epoch 10/10\n",
      "60267/60267 [==============================] - 4s 68us/step - loss: 0.0904 - val_loss: 0.0919\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/10\n",
      "60268/60268 [==============================] - 9s 143us/step - loss: 0.1147 - val_loss: 0.1013\n",
      "Epoch 2/10\n",
      "60268/60268 [==============================] - 4s 67us/step - loss: 0.0998 - val_loss: 0.0998\n",
      "Epoch 3/10\n",
      "60268/60268 [==============================] - 4s 71us/step - loss: 0.0967 - val_loss: 0.0944\n",
      "Epoch 4/10\n",
      "60268/60268 [==============================] - 4s 68us/step - loss: 0.0950 - val_loss: 0.0962\n",
      "Epoch 5/10\n",
      "60268/60268 [==============================] - 5s 76us/step - loss: 0.0945 - val_loss: 0.0945\n",
      "Epoch 6/10\n",
      "60268/60268 [==============================] - 4s 70us/step - loss: 0.0933 - val_loss: 0.0945\n",
      "Epoch 7/10\n",
      "60268/60268 [==============================] - 4s 70us/step - loss: 0.0926 - val_loss: 0.0946\n",
      "Epoch 8/10\n",
      "60268/60268 [==============================] - 4s 68us/step - loss: 0.0916 - val_loss: 0.0954\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/10\n",
      "60268/60268 [==============================] - 8s 138us/step - loss: 0.1170 - val_loss: 0.1013\n",
      "Epoch 2/10\n",
      "60268/60268 [==============================] - 5s 75us/step - loss: 0.1019 - val_loss: 0.1001\n",
      "Epoch 3/10\n",
      "60268/60268 [==============================] - 4s 71us/step - loss: 0.0994 - val_loss: 0.0989\n",
      "Epoch 4/10\n",
      "60268/60268 [==============================] - 4s 70us/step - loss: 0.0974 - val_loss: 0.0961\n",
      "Epoch 5/10\n",
      "60268/60268 [==============================] - 4s 71us/step - loss: 0.0965 - val_loss: 0.0989\n",
      "Epoch 6/10\n",
      "60268/60268 [==============================] - 4s 64us/step - loss: 0.0957 - val_loss: 0.0953\n",
      "Epoch 7/10\n",
      "60268/60268 [==============================] - 4s 63us/step - loss: 0.0946 - val_loss: 0.0951\n",
      "Epoch 8/10\n",
      "60268/60268 [==============================] - 4s 62us/step - loss: 0.0943 - val_loss: 0.0950\n",
      "Epoch 9/10\n",
      "60268/60268 [==============================] - 4s 61us/step - loss: 0.0937 - val_loss: 0.0956\n",
      "Epoch 10/10\n",
      "60268/60268 [==============================] - 3s 57us/step - loss: 0.0934 - val_loss: 0.0950\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/10\n",
      "60268/60268 [==============================] - 8s 127us/step - loss: 0.1169 - val_loss: 0.1005\n",
      "Epoch 2/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.1026 - val_loss: 0.1004\n",
      "Epoch 3/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0998 - val_loss: 0.0965\n",
      "Epoch 4/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0976 - val_loss: 0.0971\n",
      "Epoch 5/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0969 - val_loss: 0.0962\n",
      "Epoch 6/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0958 - val_loss: 0.0961\n",
      "Epoch 7/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0948 - val_loss: 0.0965\n",
      "Epoch 8/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0944 - val_loss: 0.0945\n",
      "Epoch 9/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0941 - val_loss: 0.0949\n",
      "Epoch 10/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0933 - val_loss: 0.0951\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/10\n",
      "60268/60268 [==============================] - 8s 126us/step - loss: 0.1179 - val_loss: 0.1030\n",
      "Epoch 2/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.1013 - val_loss: 0.1023\n",
      "Epoch 3/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0986 - val_loss: 0.0976\n",
      "Epoch 4/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0969 - val_loss: 0.0969\n",
      "Epoch 5/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0958 - val_loss: 0.0959\n",
      "Epoch 6/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0955 - val_loss: 0.0958\n",
      "Epoch 7/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0946 - val_loss: 0.0958\n",
      "Epoch 8/10\n",
      "60268/60268 [==============================] - 4s 59us/step - loss: 0.0941 - val_loss: 0.0959\n",
      "Epoch 9/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0932 - val_loss: 0.0952\n",
      "Epoch 10/10\n",
      "60268/60268 [==============================] - 4s 58us/step - loss: 0.0929 - val_loss: 0.0955\n",
      "0.32747562200339536\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 0]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/5\n",
      "60267/60267 [==============================] - 22s 363us/step - loss: 0.1302 - val_loss: 0.1003\n",
      "Epoch 2/5\n",
      "60267/60267 [==============================] - 17s 288us/step - loss: 0.0992 - val_loss: 0.0940\n",
      "Epoch 3/5\n",
      "60267/60267 [==============================] - 17s 283us/step - loss: 0.0952 - val_loss: 0.0932\n",
      "Epoch 4/5\n",
      "60267/60267 [==============================] - 17s 280us/step - loss: 0.0934 - val_loss: 0.0930\n",
      "Epoch 5/5\n",
      "60267/60267 [==============================] - 16s 272us/step - loss: 0.0927 - val_loss: 0.0923\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/5\n",
      "60268/60268 [==============================] - 22s 362us/step - loss: 0.1288 - val_loss: 0.1030\n",
      "Epoch 2/5\n",
      "60268/60268 [==============================] - 17s 277us/step - loss: 0.1018 - val_loss: 0.0979\n",
      "Epoch 3/5\n",
      "60268/60268 [==============================] - 17s 289us/step - loss: 0.0981 - val_loss: 0.0973\n",
      "Epoch 4/5\n",
      "60268/60268 [==============================] - 17s 285us/step - loss: 0.0965 - val_loss: 0.0959\n",
      "Epoch 5/5\n",
      "60268/60268 [==============================] - 17s 285us/step - loss: 0.0955 - val_loss: 0.0975\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/5\n",
      "60268/60268 [==============================] - 23s 379us/step - loss: 0.1385 - val_loss: 0.1034\n",
      "Epoch 2/5\n",
      "60268/60268 [==============================] - 17s 290us/step - loss: 0.1050 - val_loss: 0.1011\n",
      "Epoch 3/5\n",
      "60268/60268 [==============================] - 18s 292us/step - loss: 0.1008 - val_loss: 0.0994\n",
      "Epoch 4/5\n",
      "60268/60268 [==============================] - 17s 280us/step - loss: 0.0995 - val_loss: 0.1064\n",
      "Epoch 5/5\n",
      "60268/60268 [==============================] - 17s 284us/step - loss: 0.0982 - val_loss: 0.0986\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/5\n",
      "60268/60268 [==============================] - 21s 342us/step - loss: 0.1287 - val_loss: 0.1033\n",
      "Epoch 2/5\n",
      "60268/60268 [==============================] - 17s 282us/step - loss: 0.1046 - val_loss: 0.1025\n",
      "Epoch 3/5\n",
      "60268/60268 [==============================] - 17s 281us/step - loss: 0.1011 - val_loss: 0.0993\n",
      "Epoch 4/5\n",
      "60268/60268 [==============================] - 18s 296us/step - loss: 0.0997 - val_loss: 0.1009\n",
      "Epoch 5/5\n",
      "60268/60268 [==============================] - 17s 290us/step - loss: 0.0987 - val_loss: 0.0982\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/5\n",
      "60268/60268 [==============================] - 23s 373us/step - loss: 0.1272 - val_loss: 0.1018\n",
      "Epoch 2/5\n",
      "60268/60268 [==============================] - 18s 291us/step - loss: 0.1030 - val_loss: 0.0983\n",
      "Epoch 3/5\n",
      "60268/60268 [==============================] - 18s 292us/step - loss: 0.0996 - val_loss: 0.0971\n",
      "Epoch 4/5\n",
      "60268/60268 [==============================] - 18s 296us/step - loss: 0.0984 - val_loss: 0.0975\n",
      "Epoch 5/5\n",
      "60268/60268 [==============================] - 17s 284us/step - loss: 0.0974 - val_loss: 0.0976\n",
      "0.3236429465753356\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    docs_train, docs_test = padded_docs[train_index], padded_docs[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    docs_train, docs_valid = docs_train[tridx], docs_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_hybrid_model()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0], docs_train], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0], docs_valid], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 0], docs_test]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=10, last_dense=40, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(last_dense, activation='relu', name=\"Dense1\")(influencer_embedding)\n",
    "    influencer_embedding = Dense(i_emb_dim-10, activation='relu', name=\"Influencer-Embedding\")(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, Flatten(name='Flatten')(influencer_kind_emb)])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(last_dense, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dense(b_emb_dim-10, activation='relu', name=\"Band-Embedding\")(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='relu', name=\"Dense0\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='relu', name=\"Dense3\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_model2(i_emb_dim=50, b_emb_dim=50, kind_emb_dim=4, lstm=16, last_dense=64, dropout=0.3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Influencer embedding\n",
    "    influencer_input = Input(shape=[i_data.shape[1]], name=\"Influencer-Input\")\n",
    "    influencer_embedding = Dense(i_emb_dim, activation='relu', name=\"Influencer-Embedding1\")(influencer_input)\n",
    "    influencer_embedding = Dense(i_emb_dim - 10, activation='relu', name=\"Dense0\")(influencer_embedding)\n",
    "    influencer_embedding = Dropout(rate=dropout)(influencer_embedding)\n",
    "    \n",
    "    # Influencer kind categorical embedding\n",
    "    influencer_kind_input = Input(shape=[1], name=\"Influencer-Kind-Input\")\n",
    "    influencer_kind_emb = Embedding(14, kind_emb_dim, name=\"Influencer-Kind-Embedding\")(influencer_kind_input)\n",
    "    \n",
    "    # Influencer preferences_en LSTM embedding\n",
    "    influencer_preferences_input = Input(shape=[31, 96], name=\"Influencer-Sequence-Input\")\n",
    "    sequence_emb = LSTM(lstm)(influencer_preferences_input)\n",
    "    sequence_emb = Dropout(rate=dropout)(sequence_emb)\n",
    "    \n",
    "    # Concatenate influencer emb with influencer kind emb to get full influencer emb\n",
    "    influencer_full_emb = Concatenate(axis=-1)([influencer_embedding, \n",
    "                                                Flatten(name='Flatten')(influencer_kind_emb),\n",
    "                                                sequence_emb])\n",
    "    \n",
    "    # Band embedding\n",
    "    band_input = Input(shape=[b_data.shape[1]], name=\"Band-Input\")\n",
    "    band_embedding = Dense(b_emb_dim, activation='relu', name=\"Band-Embedding1\")(band_input)\n",
    "    band_embedding = Dense(b_emb_dim - 10, activation='relu', name=\"Dense2\")(band_embedding)\n",
    "    band_embedding = Dropout(rate=dropout)(band_embedding)\n",
    "    \n",
    "    # Concatenate and create product\n",
    "    prod = Concatenate(name=\"Concat\", axis=-1)([influencer_full_emb, band_embedding])\n",
    "    prod2 = Dense(last_dense, activation='tanh', name=\"Dense1\")(prod)\n",
    "    dropout = Dropout(rate=dropout)(prod2)\n",
    "    \n",
    "    # Dropout\n",
    "    prod3 = Dense(1, activation='tanh', name=\"Dense3\")(dropout)\n",
    "    model = Model([influencer_input, band_input, influencer_kind_input, influencer_preferences_input], prod3)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53571 samples, validate on 13393 samples\n",
      "Epoch 1/100\n",
      "53571/53571 [==============================] - 73s 1ms/step - loss: 0.1179 - val_loss: 0.0966\n",
      "Epoch 2/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.1002 - val_loss: 0.0940\n",
      "Epoch 3/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0974 - val_loss: 0.0927\n",
      "Epoch 4/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0960 - val_loss: 0.0907\n",
      "Epoch 5/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0942 - val_loss: 0.0901\n",
      "Epoch 6/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0936 - val_loss: 0.0892\n",
      "Epoch 7/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0926 - val_loss: 0.0900\n",
      "Epoch 8/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0922 - val_loss: 0.0885\n",
      "Epoch 9/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0918 - val_loss: 0.0884\n",
      "Epoch 10/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0919 - val_loss: 0.0889\n",
      "Epoch 11/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0913 - val_loss: 0.0893\n",
      "Epoch 12/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0911 - val_loss: 0.0885\n",
      "Epoch 13/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0907 - val_loss: 0.0876\n",
      "Epoch 14/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0902 - val_loss: 0.0877\n",
      "Epoch 15/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0905 - val_loss: 0.0884\n",
      "Epoch 16/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0900 - val_loss: 0.0874\n",
      "Epoch 17/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0896 - val_loss: 0.0873\n",
      "Epoch 18/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0897 - val_loss: 0.0873\n",
      "Epoch 19/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0896 - val_loss: 0.0881\n",
      "Epoch 20/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0893 - val_loss: 0.0876\n",
      "Epoch 21/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0891 - val_loss: 0.0874\n",
      "Epoch 22/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0892 - val_loss: 0.0879\n",
      "Epoch 23/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0889 - val_loss: 0.0864\n",
      "Epoch 24/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0889 - val_loss: 0.0871\n",
      "Epoch 25/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0883 - val_loss: 0.0865\n",
      "Epoch 26/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0887 - val_loss: 0.0867\n",
      "Epoch 27/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0885 - val_loss: 0.0872\n",
      "Epoch 28/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0882 - val_loss: 0.0866\n",
      "Epoch 29/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0879 - val_loss: 0.0864\n",
      "Epoch 30/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0882 - val_loss: 0.0864\n",
      "Epoch 31/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0877 - val_loss: 0.0855\n",
      "Epoch 32/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0876 - val_loss: 0.0872\n",
      "Epoch 33/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0873 - val_loss: 0.0864\n",
      "Epoch 34/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0873 - val_loss: 0.0861\n",
      "Epoch 35/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0873 - val_loss: 0.0858\n",
      "Epoch 36/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0871 - val_loss: 0.0864\n",
      "Epoch 37/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0872 - val_loss: 0.0855\n",
      "Epoch 38/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0866 - val_loss: 0.0860\n",
      "Epoch 39/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0869 - val_loss: 0.0858\n",
      "Epoch 40/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0867 - val_loss: 0.0858\n",
      "Epoch 41/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0865 - val_loss: 0.0855\n",
      "Epoch 42/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0866 - val_loss: 0.0859\n",
      "Epoch 43/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0864 - val_loss: 0.0855\n",
      "Epoch 44/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0862 - val_loss: 0.0860\n",
      "Epoch 45/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0866 - val_loss: 0.0854\n",
      "Epoch 46/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0863 - val_loss: 0.0858\n",
      "Epoch 47/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0861 - val_loss: 0.0853\n",
      "Epoch 48/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0860 - val_loss: 0.0859\n",
      "Epoch 49/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0861 - val_loss: 0.0859\n",
      "Epoch 50/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 51/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0860 - val_loss: 0.0862\n",
      "Epoch 52/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0858 - val_loss: 0.0849\n",
      "Epoch 53/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0858 - val_loss: 0.0845\n",
      "Epoch 54/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0859 - val_loss: 0.0868\n",
      "Epoch 55/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0858 - val_loss: 0.0850\n",
      "Epoch 56/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0856 - val_loss: 0.0853\n",
      "Epoch 57/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0854 - val_loss: 0.0852\n",
      "Epoch 58/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0857 - val_loss: 0.0849\n",
      "Epoch 59/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0857 - val_loss: 0.0855\n",
      "Epoch 60/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0856 - val_loss: 0.0857\n",
      "Epoch 61/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0854 - val_loss: 0.0853\n",
      "Epoch 62/100\n",
      "53571/53571 [==============================] - 63s 1ms/step - loss: 0.0855 - val_loss: 0.0856\n",
      "Epoch 63/100\n",
      "53571/53571 [==============================] - 62s 1ms/step - loss: 0.0856 - val_loss: 0.0855\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00063: early stopping\n",
      "Train on 53572 samples, validate on 13393 samples\n",
      "Epoch 1/100\n",
      "53572/53572 [==============================] - 73s 1ms/step - loss: 0.1194 - val_loss: 0.0988\n",
      "Epoch 2/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.1017 - val_loss: 0.0961\n",
      "Epoch 3/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0994 - val_loss: 0.0953\n",
      "Epoch 4/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0984 - val_loss: 0.0932\n",
      "Epoch 5/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0967 - val_loss: 0.0927\n",
      "Epoch 6/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0961 - val_loss: 0.0927\n",
      "Epoch 7/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0951 - val_loss: 0.0924\n",
      "Epoch 8/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0947 - val_loss: 0.0926\n",
      "Epoch 9/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0946 - val_loss: 0.0926\n",
      "Epoch 10/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 11/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0939 - val_loss: 0.0917\n",
      "Epoch 12/100\n",
      "53572/53572 [==============================] - 64s 1ms/step - loss: 0.0936 - val_loss: 0.0919\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0926 - val_loss: 0.0909\n",
      "Epoch 14/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0928 - val_loss: 0.0908\n",
      "Epoch 15/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0922 - val_loss: 0.0906\n",
      "Epoch 16/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0919 - val_loss: 0.0908\n",
      "Epoch 17/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0918 - val_loss: 0.0919\n",
      "Epoch 18/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0918 - val_loss: 0.0903\n",
      "Epoch 19/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0914 - val_loss: 0.0907\n",
      "Epoch 20/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0910 - val_loss: 0.0908\n",
      "Epoch 21/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0910 - val_loss: 0.0900\n",
      "Epoch 22/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0907 - val_loss: 0.0916\n",
      "Epoch 23/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0910 - val_loss: 0.0895\n",
      "Epoch 24/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0909 - val_loss: 0.0901\n",
      "Epoch 25/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0904 - val_loss: 0.0896\n",
      "Epoch 26/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0904 - val_loss: 0.0900\n",
      "Epoch 27/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0905 - val_loss: 0.0899\n",
      "Epoch 28/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0903 - val_loss: 0.0893\n",
      "Epoch 29/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0900 - val_loss: 0.0889\n",
      "Epoch 30/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0901 - val_loss: 0.0891\n",
      "Epoch 31/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0898 - val_loss: 0.0898\n",
      "Epoch 32/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0898 - val_loss: 0.0893\n",
      "Epoch 33/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0898 - val_loss: 0.0901\n",
      "Epoch 34/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0894 - val_loss: 0.0892\n",
      "Epoch 35/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0891 - val_loss: 0.0901\n",
      "Epoch 36/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0891 - val_loss: 0.0891\n",
      "Epoch 37/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0890 - val_loss: 0.0892\n",
      "Epoch 38/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0890 - val_loss: 0.0892\n",
      "Epoch 39/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0886 - val_loss: 0.0893\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00039: early stopping\n",
      "Train on 53572 samples, validate on 13393 samples\n",
      "Epoch 1/100\n",
      "53572/53572 [==============================] - 72s 1ms/step - loss: 0.1275 - val_loss: 0.1005\n",
      "Epoch 2/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1057 - val_loss: 0.0991\n",
      "Epoch 3/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1022 - val_loss: 0.0974\n",
      "Epoch 4/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1011 - val_loss: 0.0961\n",
      "Epoch 5/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0998 - val_loss: 0.0952\n",
      "Epoch 6/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0987 - val_loss: 0.0951\n",
      "Epoch 7/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0983 - val_loss: 0.0952\n",
      "Epoch 8/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0977 - val_loss: 0.0937\n",
      "Epoch 9/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0973 - val_loss: 0.0942\n",
      "Epoch 10/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0967 - val_loss: 0.0939\n",
      "Epoch 11/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0961 - val_loss: 0.0952\n",
      "Epoch 12/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0959 - val_loss: 0.0944\n",
      "Epoch 13/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0958 - val_loss: 0.0932\n",
      "Epoch 14/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0959 - val_loss: 0.0961\n",
      "Epoch 15/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0957 - val_loss: 0.0934\n",
      "Epoch 16/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0949 - val_loss: 0.0940\n",
      "Epoch 17/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0948 - val_loss: 0.0936\n",
      "Epoch 18/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0946 - val_loss: 0.0930\n",
      "Epoch 19/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0946 - val_loss: 0.0934\n",
      "Epoch 20/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0944 - val_loss: 0.0920\n",
      "Epoch 21/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0940 - val_loss: 0.0934\n",
      "Epoch 22/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 23/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0940 - val_loss: 0.0925\n",
      "Epoch 24/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0935 - val_loss: 0.0927\n",
      "Epoch 25/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 26/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0925\n",
      "Epoch 27/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0920\n",
      "Epoch 28/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0924\n",
      "Epoch 29/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0932 - val_loss: 0.0926\n",
      "Epoch 30/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0931 - val_loss: 0.0925\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00030: early stopping\n",
      "Train on 53572 samples, validate on 13393 samples\n",
      "Epoch 1/100\n",
      "53572/53572 [==============================] - 72s 1ms/step - loss: 0.1237 - val_loss: 0.1026\n",
      "Epoch 2/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.1054 - val_loss: 0.0983\n",
      "Epoch 3/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.1029 - val_loss: 0.0964\n",
      "Epoch 4/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.1018 - val_loss: 0.0958\n",
      "Epoch 5/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.1005 - val_loss: 0.0961\n",
      "Epoch 6/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0998 - val_loss: 0.0969\n",
      "Epoch 7/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0988 - val_loss: 0.0966\n",
      "Epoch 8/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0985 - val_loss: 0.0968\n",
      "Epoch 9/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0983 - val_loss: 0.0946\n",
      "Epoch 10/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0979 - val_loss: 0.0949\n",
      "Epoch 11/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0971 - val_loss: 0.0952\n",
      "Epoch 12/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0971 - val_loss: 0.0945\n",
      "Epoch 13/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0964 - val_loss: 0.0932\n",
      "Epoch 14/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0966 - val_loss: 0.0940\n",
      "Epoch 15/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0962 - val_loss: 0.0938\n",
      "Epoch 16/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0961 - val_loss: 0.0941\n",
      "Epoch 17/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0962 - val_loss: 0.0933\n",
      "Epoch 18/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0955 - val_loss: 0.0927\n",
      "Epoch 19/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0958 - val_loss: 0.0934\n",
      "Epoch 20/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0951 - val_loss: 0.0931\n",
      "Epoch 21/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0951 - val_loss: 0.0948\n",
      "Epoch 22/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 23/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 24/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0947 - val_loss: 0.0933\n",
      "Epoch 25/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0946 - val_loss: 0.0930\n",
      "Epoch 26/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0940 - val_loss: 0.0923\n",
      "Epoch 27/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0941 - val_loss: 0.0920\n",
      "Epoch 28/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 29/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0941 - val_loss: 0.0920\n",
      "Epoch 30/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0934 - val_loss: 0.0933\n",
      "Epoch 31/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 32/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0930 - val_loss: 0.0924\n",
      "Epoch 33/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0930 - val_loss: 0.0927\n",
      "Epoch 34/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0930 - val_loss: 0.0931\n",
      "Epoch 35/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0929 - val_loss: 0.0921\n",
      "Epoch 36/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0926 - val_loss: 0.0929\n",
      "Epoch 37/100\n",
      "53572/53572 [==============================] - 63s 1ms/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00037: early stopping\n",
      "Train on 53572 samples, validate on 13393 samples\n",
      "Epoch 1/100\n",
      "53572/53572 [==============================] - 72s 1ms/step - loss: 0.1225 - val_loss: 0.1030\n",
      "Epoch 2/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1042 - val_loss: 0.0970\n",
      "Epoch 3/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1017 - val_loss: 0.0984\n",
      "Epoch 4/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.1000 - val_loss: 0.0953\n",
      "Epoch 5/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0994 - val_loss: 0.0948\n",
      "Epoch 6/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0984 - val_loss: 0.0945\n",
      "Epoch 7/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0981 - val_loss: 0.0949\n",
      "Epoch 8/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0972 - val_loss: 0.0941\n",
      "Epoch 9/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0965 - val_loss: 0.0946\n",
      "Epoch 10/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0966 - val_loss: 0.0933\n",
      "Epoch 11/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0962 - val_loss: 0.0935\n",
      "Epoch 12/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0958 - val_loss: 0.0938\n",
      "Epoch 13/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0954 - val_loss: 0.0931\n",
      "Epoch 14/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0951 - val_loss: 0.0935\n",
      "Epoch 15/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0947 - val_loss: 0.0925\n",
      "Epoch 16/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0948 - val_loss: 0.0934\n",
      "Epoch 17/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0944 - val_loss: 0.0940\n",
      "Epoch 18/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 19/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0942 - val_loss: 0.0921\n",
      "Epoch 20/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0944 - val_loss: 0.0926\n",
      "Epoch 21/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0926\n",
      "Epoch 22/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0929\n",
      "Epoch 23/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0936 - val_loss: 0.0921\n",
      "Epoch 24/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0935 - val_loss: 0.0924\n",
      "Epoch 25/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 26/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0932 - val_loss: 0.0921\n",
      "Epoch 27/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0932 - val_loss: 0.0928\n",
      "Epoch 28/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0929 - val_loss: 0.0920\n",
      "Epoch 29/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0930 - val_loss: 0.0915\n",
      "Epoch 30/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0925 - val_loss: 0.0917\n",
      "Epoch 31/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0923 - val_loss: 0.0924\n",
      "Epoch 32/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0926 - val_loss: 0.0920\n",
      "Epoch 33/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 34/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0924 - val_loss: 0.0931\n",
      "Epoch 35/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0922 - val_loss: 0.0908\n",
      "Epoch 36/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0917 - val_loss: 0.0925\n",
      "Epoch 37/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0920 - val_loss: 0.0907\n",
      "Epoch 38/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0913 - val_loss: 0.0906\n",
      "Epoch 39/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0916 - val_loss: 0.0915\n",
      "Epoch 40/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0915 - val_loss: 0.0917\n",
      "Epoch 41/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0914 - val_loss: 0.0909\n",
      "Epoch 42/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0912 - val_loss: 0.0917\n",
      "Epoch 43/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0913 - val_loss: 0.0914\n",
      "Epoch 44/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0911 - val_loss: 0.0908\n",
      "Epoch 45/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0910 - val_loss: 0.0916\n",
      "Epoch 46/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0910 - val_loss: 0.0913\n",
      "Epoch 47/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0907 - val_loss: 0.0911\n",
      "Epoch 48/100\n",
      "53572/53572 [==============================] - 62s 1ms/step - loss: 0.0909 - val_loss: 0.0916\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00048: early stopping\n",
      "0.32478536307485323\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    docs_train, docs_test = padded_docs[train_index], padded_docs[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    docs_train, docs_valid = docs_train[tridx], docs_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_hybrid_model2(i_emb_dim=60, b_emb_dim=60, kind_emb_dim=8, lstm=8, last_dense=64, dropout=0.5)\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0], docs_train], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0], docs_valid], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 0], docs_test]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60267/60267 [==============================] - 40s 662us/step - loss: 0.1033 - val_loss: 0.0924\n",
      "Epoch 2/100\n",
      "60267/60267 [==============================] - 33s 542us/step - loss: 0.0921 - val_loss: 0.0898\n",
      "Epoch 3/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0902 - val_loss: 0.0910\n",
      "Epoch 4/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0893 - val_loss: 0.0886\n",
      "Epoch 5/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0886 - val_loss: 0.0900\n",
      "Epoch 6/100\n",
      "60267/60267 [==============================] - 33s 542us/step - loss: 0.0881 - val_loss: 0.0896\n",
      "Epoch 7/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0875 - val_loss: 0.0887\n",
      "Epoch 8/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0873 - val_loss: 0.0897\n",
      "Epoch 9/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0871 - val_loss: 0.0882\n",
      "Epoch 10/100\n",
      "60267/60267 [==============================] - 33s 545us/step - loss: 0.0869 - val_loss: 0.0889\n",
      "Epoch 11/100\n",
      "60267/60267 [==============================] - 33s 545us/step - loss: 0.0865 - val_loss: 0.0883\n",
      "Epoch 12/100\n",
      "60267/60267 [==============================] - 33s 546us/step - loss: 0.0862 - val_loss: 0.0880\n",
      "Epoch 13/100\n",
      "60267/60267 [==============================] - 33s 546us/step - loss: 0.0862 - val_loss: 0.0888\n",
      "Epoch 14/100\n",
      "60267/60267 [==============================] - 33s 546us/step - loss: 0.0861 - val_loss: 0.0883\n",
      "Epoch 15/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0859 - val_loss: 0.0898\n",
      "Epoch 16/100\n",
      "60267/60267 [==============================] - 33s 546us/step - loss: 0.0858 - val_loss: 0.0889\n",
      "Epoch 17/100\n",
      "60267/60267 [==============================] - 33s 546us/step - loss: 0.0856 - val_loss: 0.0879\n",
      "Epoch 18/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0853 - val_loss: 0.0877\n",
      "Epoch 19/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0854 - val_loss: 0.0878\n",
      "Epoch 20/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0852 - val_loss: 0.0883\n",
      "Epoch 21/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0852 - val_loss: 0.0875\n",
      "Epoch 22/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0850 - val_loss: 0.0870\n",
      "Epoch 23/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0848 - val_loss: 0.0874\n",
      "Epoch 24/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0851 - val_loss: 0.0872\n",
      "Epoch 25/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0848 - val_loss: 0.0869\n",
      "Epoch 26/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0846 - val_loss: 0.0877\n",
      "Epoch 27/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0845 - val_loss: 0.0876\n",
      "Epoch 28/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0845 - val_loss: 0.0870\n",
      "Epoch 29/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0844 - val_loss: 0.0874\n",
      "Epoch 30/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0842 - val_loss: 0.0866\n",
      "Epoch 31/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0841 - val_loss: 0.0859\n",
      "Epoch 32/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0840 - val_loss: 0.0868\n",
      "Epoch 33/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0841 - val_loss: 0.0866\n",
      "Epoch 34/100\n",
      "60267/60267 [==============================] - 33s 550us/step - loss: 0.0839 - val_loss: 0.0868\n",
      "Epoch 35/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0839 - val_loss: 0.0866\n",
      "Epoch 36/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0837 - val_loss: 0.0861\n",
      "Epoch 37/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0835 - val_loss: 0.0862\n",
      "Epoch 38/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0834 - val_loss: 0.0871\n",
      "Epoch 39/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0830 - val_loss: 0.0864\n",
      "Epoch 40/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0830 - val_loss: 0.0870\n",
      "Epoch 41/100\n",
      "60267/60267 [==============================] - 33s 550us/step - loss: 0.0830 - val_loss: 0.0859\n",
      "Epoch 42/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0826 - val_loss: 0.0858\n",
      "Epoch 43/100\n",
      "60267/60267 [==============================] - 33s 550us/step - loss: 0.0827 - val_loss: 0.0856\n",
      "Epoch 44/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0825 - val_loss: 0.0863\n",
      "Epoch 45/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0824 - val_loss: 0.0862\n",
      "Epoch 46/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0820 - val_loss: 0.0856\n",
      "Epoch 47/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0820 - val_loss: 0.0859\n",
      "Epoch 48/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0819 - val_loss: 0.0856\n",
      "Epoch 49/100\n",
      "60267/60267 [==============================] - 33s 547us/step - loss: 0.0816 - val_loss: 0.0857\n",
      "Epoch 50/100\n",
      "60267/60267 [==============================] - 33s 549us/step - loss: 0.0817 - val_loss: 0.0854\n",
      "Epoch 51/100\n",
      "60267/60267 [==============================] - 33s 548us/step - loss: 0.0814 - val_loss: 0.0849\n",
      "Epoch 52/100\n",
      "60267/60267 [==============================] - 33s 550us/step - loss: 0.0816 - val_loss: 0.0854\n",
      "Epoch 53/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0812 - val_loss: 0.0852\n",
      "Epoch 54/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0811 - val_loss: 0.0861\n",
      "Epoch 55/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0810 - val_loss: 0.0856\n",
      "Epoch 56/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 57/100\n",
      "60267/60267 [==============================] - 33s 545us/step - loss: 0.0809 - val_loss: 0.0856\n",
      "Epoch 58/100\n",
      "60267/60267 [==============================] - 33s 545us/step - loss: 0.0809 - val_loss: 0.0852\n",
      "Epoch 59/100\n",
      "60267/60267 [==============================] - 33s 543us/step - loss: 0.0807 - val_loss: 0.0855\n",
      "Epoch 60/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0807 - val_loss: 0.0852\n",
      "Epoch 61/100\n",
      "60267/60267 [==============================] - 33s 544us/step - loss: 0.0807 - val_loss: 0.0856\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00061: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 40s 663us/step - loss: 0.1076 - val_loss: 0.0955\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0928 - val_loss: 0.0924\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0915 - val_loss: 0.0926\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0903 - val_loss: 0.0912\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0899 - val_loss: 0.0918\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0895 - val_loss: 0.0926\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0893 - val_loss: 0.0913\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0888 - val_loss: 0.0905\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0883 - val_loss: 0.0898\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0882 - val_loss: 0.0903\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0878 - val_loss: 0.0896\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0877 - val_loss: 0.0892\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0876 - val_loss: 0.0893\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 33s 540us/step - loss: 0.0873 - val_loss: 0.0891\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0872 - val_loss: 0.0901\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0870 - val_loss: 0.0899\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0869 - val_loss: 0.0896\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 33s 543us/step - loss: 0.0870 - val_loss: 0.0899\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0869 - val_loss: 0.0901\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 33s 543us/step - loss: 0.0867 - val_loss: 0.0891\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0867 - val_loss: 0.0888\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0865 - val_loss: 0.0890\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0865 - val_loss: 0.0890\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0865 - val_loss: 0.0893\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0864 - val_loss: 0.0889\n",
      "Epoch 28/100\n",
      "60268/60268 [==============================] - 33s 541us/step - loss: 0.0862 - val_loss: 0.0900\n",
      "Epoch 29/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0862 - val_loss: 0.0889\n",
      "Epoch 30/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0861 - val_loss: 0.0891\n",
      "Epoch 31/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0860 - val_loss: 0.0891\n",
      "Epoch 32/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0860 - val_loss: 0.0892\n",
      "Epoch 33/100\n",
      "60268/60268 [==============================] - 33s 542us/step - loss: 0.0859 - val_loss: 0.0890\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00033: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 40s 666us/step - loss: 0.1113 - val_loss: 0.0968\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0973 - val_loss: 0.0957\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0950 - val_loss: 0.0948\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0943 - val_loss: 0.0941\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0933 - val_loss: 0.0943\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0924 - val_loss: 0.0933\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0921 - val_loss: 0.0935\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0919 - val_loss: 0.0925\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0914 - val_loss: 0.0932\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0914 - val_loss: 0.0919\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0909 - val_loss: 0.0928\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0909 - val_loss: 0.0929\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0906 - val_loss: 0.0938\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0905 - val_loss: 0.0929\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0904 - val_loss: 0.0923\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0903 - val_loss: 0.0928\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0903 - val_loss: 0.0926\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 33s 545us/step - loss: 0.0901 - val_loss: 0.0924\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0899 - val_loss: 0.0922\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 33s 544us/step - loss: 0.0898 - val_loss: 0.0925\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00021: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 40s 670us/step - loss: 0.1122 - val_loss: 0.1017\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.1003 - val_loss: 0.0948\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0961 - val_loss: 0.0939\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0947 - val_loss: 0.0944\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0937 - val_loss: 0.0933\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0934 - val_loss: 0.0929\n",
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0927 - val_loss: 0.0928\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0925 - val_loss: 0.0933\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0921 - val_loss: 0.0934\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0921 - val_loss: 0.0926\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0919 - val_loss: 0.0918\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0915 - val_loss: 0.0924\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0913 - val_loss: 0.0923\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0911 - val_loss: 0.0915\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0910 - val_loss: 0.0931\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 33s 546us/step - loss: 0.0908 - val_loss: 0.0916\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0907 - val_loss: 0.0928\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0909 - val_loss: 0.0921\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0905 - val_loss: 0.0918\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0907 - val_loss: 0.0916\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0904 - val_loss: 0.0922\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0904 - val_loss: 0.0921\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0903 - val_loss: 0.0922\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0902 - val_loss: 0.0916\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00024: early stopping\n",
      "Train on 60268 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60268/60268 [==============================] - 41s 676us/step - loss: 0.1092 - val_loss: 0.1003\n",
      "Epoch 2/100\n",
      "60268/60268 [==============================] - 33s 550us/step - loss: 0.0973 - val_loss: 0.0956\n",
      "Epoch 3/100\n",
      "60268/60268 [==============================] - 33s 551us/step - loss: 0.0949 - val_loss: 0.0949\n",
      "Epoch 4/100\n",
      "60268/60268 [==============================] - 33s 550us/step - loss: 0.0940 - val_loss: 0.0934\n",
      "Epoch 5/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0931 - val_loss: 0.0933\n",
      "Epoch 6/100\n",
      "60268/60268 [==============================] - 33s 550us/step - loss: 0.0925 - val_loss: 0.0933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0924 - val_loss: 0.0919\n",
      "Epoch 8/100\n",
      "60268/60268 [==============================] - 33s 547us/step - loss: 0.0917 - val_loss: 0.0933\n",
      "Epoch 9/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0915 - val_loss: 0.0928\n",
      "Epoch 10/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0916 - val_loss: 0.0923\n",
      "Epoch 11/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0911 - val_loss: 0.0927\n",
      "Epoch 12/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0910 - val_loss: 0.0918\n",
      "Epoch 13/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0909 - val_loss: 0.0915\n",
      "Epoch 14/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0907 - val_loss: 0.0929\n",
      "Epoch 15/100\n",
      "60268/60268 [==============================] - 33s 549us/step - loss: 0.0905 - val_loss: 0.0917\n",
      "Epoch 16/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0905 - val_loss: 0.0917\n",
      "Epoch 17/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0904 - val_loss: 0.0913\n",
      "Epoch 18/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0903 - val_loss: 0.0912\n",
      "Epoch 19/100\n",
      "60268/60268 [==============================] - 33s 548us/step - loss: 0.0902 - val_loss: 0.0913\n",
      "Epoch 20/100\n",
      "60268/60268 [==============================] - 34s 571us/step - loss: 0.0901 - val_loss: 0.0913\n",
      "Epoch 21/100\n",
      "60268/60268 [==============================] - 34s 567us/step - loss: 0.0899 - val_loss: 0.0914\n",
      "Epoch 22/100\n",
      "60268/60268 [==============================] - 34s 572us/step - loss: 0.0899 - val_loss: 0.0915\n",
      "Epoch 23/100\n",
      "60268/60268 [==============================] - 34s 566us/step - loss: 0.0899 - val_loss: 0.0928\n",
      "Epoch 24/100\n",
      "60268/60268 [==============================] - 34s 568us/step - loss: 0.0898 - val_loss: 0.0915\n",
      "Epoch 25/100\n",
      "60268/60268 [==============================] - 34s 562us/step - loss: 0.0897 - val_loss: 0.0916\n",
      "Epoch 26/100\n",
      "60268/60268 [==============================] - 33s 555us/step - loss: 0.0898 - val_loss: 0.0913\n",
      "Epoch 27/100\n",
      "60268/60268 [==============================] - 33s 556us/step - loss: 0.0896 - val_loss: 0.0914\n",
      "Epoch 28/100\n",
      "60268/60268 [==============================] - 33s 556us/step - loss: 0.0895 - val_loss: 0.0909\n",
      "Epoch 29/100\n",
      "60268/60268 [==============================] - 36s 602us/step - loss: 0.0894 - val_loss: 0.0920\n",
      "Epoch 30/100\n",
      "60268/60268 [==============================] - 36s 598us/step - loss: 0.0894 - val_loss: 0.0912\n",
      "Epoch 31/100\n",
      "60268/60268 [==============================] - 36s 605us/step - loss: 0.0893 - val_loss: 0.0910\n",
      "Epoch 32/100\n",
      "60268/60268 [==============================] - 35s 580us/step - loss: 0.0893 - val_loss: 0.0915\n",
      "Epoch 33/100\n",
      "60268/60268 [==============================] - 34s 560us/step - loss: 0.0892 - val_loss: 0.0909\n",
      "Epoch 34/100\n",
      "60268/60268 [==============================] - 34s 560us/step - loss: 0.0891 - val_loss: 0.0913\n",
      "Epoch 35/100\n",
      "60268/60268 [==============================] - 35s 573us/step - loss: 0.0889 - val_loss: 0.0908\n",
      "Epoch 36/100\n",
      "60268/60268 [==============================] - 34s 562us/step - loss: 0.0888 - val_loss: 0.0905\n",
      "Epoch 37/100\n",
      "60268/60268 [==============================] - 34s 558us/step - loss: 0.0886 - val_loss: 0.0909\n",
      "Epoch 38/100\n",
      "60268/60268 [==============================] - 35s 582us/step - loss: 0.0887 - val_loss: 0.0904\n",
      "Epoch 39/100\n",
      "60268/60268 [==============================] - 35s 574us/step - loss: 0.0884 - val_loss: 0.0910\n",
      "Epoch 40/100\n",
      "60268/60268 [==============================] - 35s 581us/step - loss: 0.0882 - val_loss: 0.0906\n",
      "Epoch 41/100\n",
      "60268/60268 [==============================] - 34s 558us/step - loss: 0.0881 - val_loss: 0.0908\n",
      "Epoch 42/100\n",
      "60268/60268 [==============================] - 34s 558us/step - loss: 0.0879 - val_loss: 0.0898\n",
      "Epoch 43/100\n",
      "60268/60268 [==============================] - 34s 558us/step - loss: 0.0878 - val_loss: 0.0900\n",
      "Epoch 44/100\n",
      "60268/60268 [==============================] - 34s 559us/step - loss: 0.0875 - val_loss: 0.0894\n",
      "Epoch 45/100\n",
      "60268/60268 [==============================] - 34s 559us/step - loss: 0.0873 - val_loss: 0.0898\n",
      "Epoch 46/100\n",
      "60268/60268 [==============================] - 33s 552us/step - loss: 0.0873 - val_loss: 0.0900\n",
      "Epoch 47/100\n",
      "60268/60268 [==============================] - 34s 561us/step - loss: 0.0869 - val_loss: 0.0913\n",
      "Epoch 48/100\n",
      "60268/60268 [==============================] - 35s 576us/step - loss: 0.0869 - val_loss: 0.0908\n",
      "Epoch 49/100\n",
      "60268/60268 [==============================] - 34s 567us/step - loss: 0.0871 - val_loss: 0.0905\n",
      "Epoch 50/100\n",
      "60268/60268 [==============================] - 35s 572us/step - loss: 0.0867 - val_loss: 0.0899\n",
      "Epoch 51/100\n",
      "60268/60268 [==============================] - 34s 561us/step - loss: 0.0867 - val_loss: 0.0898\n",
      "Epoch 52/100\n",
      "60268/60268 [==============================] - 34s 558us/step - loss: 0.0865 - val_loss: 0.0898\n",
      "Epoch 53/100\n",
      "60268/60268 [==============================] - 34s 559us/step - loss: 0.0862 - val_loss: 0.0902\n",
      "Epoch 54/100\n",
      "60268/60268 [==============================] - 34s 559us/step - loss: 0.0862 - val_loss: 0.0896\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00054: early stopping\n",
      "0.32737252168938963\n"
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    docs_train, docs_test = padded_docs[train_index], padded_docs[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    docs_train, docs_valid = docs_train[tridx], docs_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_hybrid_model2()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0], docs_train], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0], docs_valid], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 0], docs_test]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60267 samples, validate on 6697 samples\n",
      "Epoch 1/100\n",
      "60267/60267 [==============================] - 15s 247us/step - loss: 0.1113 - val_loss: 0.1007\n",
      "Epoch 2/100\n",
      "60267/60267 [==============================] - 8s 130us/step - loss: 0.0989 - val_loss: 0.0977\n",
      "Epoch 3/100\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.0963 - val_loss: 0.0952\n",
      "Epoch 4/100\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.0946 - val_loss: 0.0933\n",
      "Epoch 5/100\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.0933 - val_loss: 0.0934\n",
      "Epoch 6/100\n",
      "60267/60267 [==============================] - 8s 133us/step - loss: 0.0926 - val_loss: 0.0928\n",
      "Epoch 7/100\n",
      "60267/60267 [==============================] - 8s 134us/step - loss: 0.0917 - val_loss: 0.0919\n",
      "Epoch 8/100\n",
      "60267/60267 [==============================] - 8s 125us/step - loss: 0.0913 - val_loss: 0.0929\n",
      "Epoch 9/100\n",
      "60267/60267 [==============================] - 8s 127us/step - loss: 0.0906 - val_loss: 0.0916\n",
      "Epoch 10/100\n",
      "60267/60267 [==============================] - 8s 127us/step - loss: 0.0899 - val_loss: 0.0930\n",
      "Epoch 11/100\n",
      "60267/60267 [==============================] - 8s 129us/step - loss: 0.0896 - val_loss: 0.0921\n",
      "Epoch 12/100\n",
      "60267/60267 [==============================] - 8s 129us/step - loss: 0.0891 - val_loss: 0.0915\n",
      "Epoch 13/100\n",
      "60267/60267 [==============================] - 8s 132us/step - loss: 0.0889 - val_loss: 0.0928\n",
      "Epoch 14/100\n",
      "60267/60267 [==============================] - 8s 132us/step - loss: 0.0882 - val_loss: 0.0919\n",
      "Epoch 15/100\n",
      "60267/60267 [==============================] - 8s 130us/step - loss: 0.0878 - val_loss: 0.0915\n",
      "Epoch 16/100\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.0878 - val_loss: 0.0919\n",
      "Epoch 17/100\n",
      "60267/60267 [==============================] - 8s 128us/step - loss: 0.0875 - val_loss: 0.0924\n",
      "Epoch 18/100\n",
      "60267/60267 [==============================] - 8s 129us/step - loss: 0.0869 - val_loss: 0.0927\n",
      "Epoch 19/100\n",
      "60267/60267 [==============================] - 8s 131us/step - loss: 0.0869 - val_loss: 0.0920\n",
      "Epoch 20/100\n",
      "26944/60267 [============>.................] - ETA: 4s - loss: 0.0855"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-0ceb93e2ce05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     nn_score += np.sqrt(mean_squared_error(\n",
      "\u001b[0;32m~/.virtualenvs/groover/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/groover/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/groover/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/groover/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/groover/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_score = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_3()\n",
    "    \n",
    "    # Early stoppnig callback\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit([X_train[:, i_data_idx], X_train[:, b_data_idx], X_train[:, 0]], y_train,\n",
    "              validation_data=([X_valid[:, i_data_idx], X_valid[:, b_data_idx], X_valid[:, 0]], y_valid), \n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[es],\n",
    "              verbose=1)\n",
    "    \n",
    "    nn_score += np.sqrt(mean_squared_error(\n",
    "        model.predict([X_test[:, i_data_idx], X_test[:, b_data_idx], X_test[:, 0]]), y_test\n",
    "    ))\n",
    "\n",
    "nn_score /= N_FOLDS\n",
    "\n",
    "print(nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83706, 144)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 'Indie, emerging', 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, 72, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.089253\n",
      "[200]\tvalid_0's l2: 0.0889512\n",
      "[300]\tvalid_0's l2: 0.08903\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's l2: 0.0889244\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.092336\n",
      "[200]\tvalid_0's l2: 0.0922979\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l2: 0.0922423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.0935227\n",
      "[200]\tvalid_0's l2: 0.0931942\n",
      "[300]\tvalid_0's l2: 0.0931966\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l2: 0.0931803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.094163\n",
      "[200]\tvalid_0's l2: 0.0938801\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l2: 0.0938587\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.0951689\n",
      "[200]\tvalid_0's l2: 0.0950135\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's l2: 0.0949667\n",
      "0.32319608629266383\n"
     ]
    }
   ],
   "source": [
    "lgbm_score =  0.0\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, (y * 100).astype(int)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    tridx, vidx = next(sss.split(X_train, (y_train * 100).astype(int)))\n",
    "    X_train, X_valid = X_train[tridx], X_train[vidx]\n",
    "    y_train, y_valid = y_train[tridx], y_train[vidx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(\n",
    "        num_leaves=2**9,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        n_estimators=10000,\n",
    "        silent=False\n",
    "    )\n",
    "    lgbm.fit(X_train, y_train, eval_set=(X_valid, y_valid), \n",
    "             eval_metric='mse', early_stopping_rounds=100,\n",
    "             verbose=100)\n",
    "    lgbm_score += np.sqrt(mean_squared_error(lgbm.predict(X_test), y_test))\n",
    "\n",
    "lgbm_score /= N_FOLDS\n",
    "\n",
    "print(lgbm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check pipe\n",
    "* Add L2 reg\n",
    "* look for text embeddings\n",
    "* preprocess text\n",
    "* build archi\n",
    "* print archi\n",
    "* pretrained emb\n",
    "* tqdm notebook\n",
    "\n",
    "also:\n",
    "* Visualize embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English chosen because in french description, mix of english and french"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content based : no interaction influencer/artist taken into account (no embedding for them)\n",
    "\n",
    "advantage : cold start allowed\n",
    "disadvantage : interesting info lossed\n",
    "\n",
    "==> hybrid recommender system\n",
    "\n",
    "label encoded influencer kind : in production, a category 'Other' can be created to account for potential kinds not present in current dataset.\n",
    "\n",
    "Grid search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groover",
   "language": "python",
   "name": "groover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
